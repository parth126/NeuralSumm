{
    "abstract_sentences": {
        "1": "The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework for 282 languages that exist in Wikipedia.", 
        "2": "Given a document in any of these languages, our framework is able to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to an English Knowledge Base (KB) if it is linkable.", 
        "3": "We achieve this goal by performing a series of new KB mining methods: generating \u201csilver-standard\u201d annotations by transferring annotations from English to other languages through crosslingual links and KB properties, refining annotations through self-training and topic selection, deriving language-specific morphology features from anchor links, and mining word translation pairs from crosslingual links.", 
        "4": "Both name tagging and linking results for 282 languages are promising on Wikipedia data and on-Wikipedia data.", 
        "5": "All the data sets, resources and systems for 282 languages are made publicly available as a new benchmark 1."
    }, 
    "body_sentences": {
        "1": "  Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 1946\u20131958 Vancouver, Canada, July 30 - August 4, 2017. c\u00a92017 Association for Computational Linguistics\nhttps://doi.org/10.18653/v1/P17-1178\nThe ambitious goal of this work is to develop a cross-lingual name tagging and linking framework for 282 languages that exist in Wikipedia.", 
        "2": "Given a document in any of these languages, our framework is able to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to an English Knowledge Base (KB) if it is linkable.", 
        "3": "We achieve this goal by performing a series of new KB mining methods: generating \u201csilver-standard\u201d annotations by transferring annotations from English to other languages through crosslingual links and KB properties, refining annotations through self-training and topic selection, deriving language-specific morphology features from anchor links, and mining word translation pairs from crosslingual links.", 
        "4": "Both name tagging and linking results for 282 languages are promising on Wikipedia data and on-Wikipedia data.", 
        "5": "All the data sets, resources and systems for 282 languages are made publicly available as a new benchmark 1.", 
        "6": "1 Introduction  Information provided in languages which people can understand saves lives in crises.", 
        "7": "For example, language barrier was one of the main difficulties faced by humanitarian workers responding to the Ebola crisis in 2014.", 
        "8": "We propose to break language barriers by extracting information (e.g., entities) from a massive variety of languages and ground the information into an existing knowledge base which is accessible to a user in his/her own\n1http://nlp.cs.rpi.edu/wikiann\nlanguage (e.g., a reporter from the World Health Organization who speaks English only).", 
        "9": "Wikipedia is a massively multi-lingual resource that currently hosts 295 languages and contains naturally annotated markups 2 and rich informational structures through crowd-sourcing for 35 million articles in 3 billion words.", 
        "10": "Name mentions in Wikipedia are often labeled as anchor links to their corresponding referent pages.", 
        "11": "Each entry in Wikipedia is also mapped to external knowledge bases such as DBpedia3, YAGO (Mahdisoltani et al., 2015) and Freebase (Bollacker et al., 2008) that contain rich properties.", 
        "12": "Figure 1 shows an example of Wikipedia markups and KB properties.", 
        "13": "We leverage these markups for develop-\n\u2724Wikipedia Article: Mao Zedong (d. 26 Aral\u0131k 1893 - \u00f6.", 
        "14": "9 Eyl\u00fcl 1976), \u00c7inli devrimci ve siyaset\u00e7i.", 
        "15": "\u00c7in Kom\u00fcnist Partisinin (\u00c7KP) ve \u00c7in Halk Cumhuriyetinin kurucusu.", 
        "16": "\u2724Wikipedia Markup: [[Mao Zedong]] (d. [[26 Aral\u0131k]] [[1893]] - \u00f6.", 
        "17": "[[9 Eyl\u00fcl]] [[1976]]), \u00c7inli devrimci ve siyaset\u00e7i.", 
        "18": "[[\u00c7in Kom\u00fcnist Partisi]]nin (\u00c7KP) ve [[\u00c7in Halk Cumhuriyeti]]nin kurucusu.", 
        "19": "(Mao Zedong (December 26, 1893 - September 9, 1976) is a Chinese revolutionary and politician.", 
        "20": "The founder of the Chinese Communist Party (CCP) and the People's Republic of China.)", 
        "21": "ing a language universal framework to automatically extract name mentions from documents in\n2https://en.wikipedia.org/wiki/Help:Wiki markup 3http://wiki.dbpedia.org\n1946\n282 languages, and link them to an English KB (Wikipedia in this work).", 
        "22": "The major challenges and our new solutions are summarized as follows.", 
        "23": "Creating \u201cSilver-standard\u201d through crosslingual entity transfer.", 
        "24": "The first step is to classify English Wikipedia entries into certain entity types and then propagate these labels to other languages.", 
        "25": "We exploit the English Abstract Meaning Representation (AMR) corpus (Banarescu et al., 2013) which includes both name tagging and linking annotations for fine-grained entity types to train an automatic classifier.", 
        "26": "Furthermore, we exploit each entry\u2019s properties in DBpedia as features and thus eliminate the need of language-specific features and resources such as part-of-speech tagging as in previous work (Section 2.2).", 
        "27": "Refine annotations through self-training.", 
        "28": "The initial annotations obtained from above are too incomplete and inconsistent.", 
        "29": "Previous work used name string match to propagate labels.", 
        "30": "In contrast, we apply self-training to label other mentions without links in Wikipedia articles even if they have different surface forms from the linked mentions (Section 2.4).", 
        "31": "Customize annotations through cross-lingual topic transfer.", 
        "32": "For the first time, we propose to customize name annotations for specific downstream applications.", 
        "33": "Again, we use a cross-lingual knowledge transfer strategy to leverage the widely available English corpora to choose entities with specific Wikipedia topic categories (Section 2.5).", 
        "34": "Derive morphology analysis from Wikipedia markups.", 
        "35": "Another unique challenge for morphologically rich languages is to segment each token into its stemming form and affixes.", 
        "36": "Previous methods relied on either high-cost supervised learning (Roth et al., 2008; Mahmoudi et al., 2013; Ahlberg et al., 2015), or low-quality unsupervised learning (Gro\u0308nroos et al., 2014; Ruokolainen et al., 2016).", 
        "37": "We exploit Wikipedia markups to automatically learn affixes as language-specific features (Section 2.3).", 
        "38": "Mine word translations from cross-lingual links.", 
        "39": "Name translation is a crucial step to generate candidate entities in cross-lingual entity linking.", 
        "40": "Only a small percentage of names can be directly translated by matching against cross-lingual Wikipedia title pairs.", 
        "41": "Based on the observation that Wikipedia titles within any language tend to follow a consistent style and format, we propose an effective method to derive word translation\npairs from these titles based on automatic alignment (Section 3.2).", 
        "42": "2 Name Tagging    2.1 Overview  Our first step is to generate \u201csilver-standard\u201d name annotations from Wikipedia markups and train a universal name tagger.", 
        "43": "Figure 2 shows our overall procedure and the following subsections will elaborate each component.", 
        "44": "2.2 Initial Annotation Generation  We start by assigning an entity type or \u201cother\u201d to each English Wikipedia entry.", 
        "45": "We utilize the AMR corpus where each entity name mention is manually labeled as one of 139 types\nand linked to Wikipedia if it\u2019s linkable.", 
        "46": "In total we obtain 2,756 entity mentions, along with their AMR entity types, Wikipedia titles, YAGO entity types and DBpedia properties.", 
        "47": "For each pair of AMR entity type ta and YAGO entity type ty, we compute the Pointwise Mutual Information (PMI) (Ward Church and Hanks, 1990) of mapping ta to ty across all mentions in the AMR corpus.", 
        "48": "Therefore, each name mention is also assigned a list of YAGO entity types, ranked by their PMI scores with AMR types.", 
        "49": "In this way, our framework produces three levels of entity typing schemas with different granularity: 4 main types (Person (PER), Organization (ORG), Geo-political Entity (GPE), Location (LOC)), 139 types in AMR, and 9,154 types in YAGO.", 
        "50": "Then we leverage an entity\u2019s properties in DBpedia as features for assigning types.", 
        "51": "For example, an entity with a birth date is likely to be a person, while an entity with a population property is likely to be a geo-political entity.", 
        "52": "Using all DBpedia entity properties as features (60,231 in total), we train Maximum Entropy models to assign types with three levels of granularity to all English Wikipedia pages.", 
        "53": "In total we obtained 10 million English pages labeled as entities of interest.", 
        "54": "Nothman et al.", 
        "55": "(2013) manually annotated 4,853 English Wikipedia pages with 6 coarsegrained types (Person, Organization, Location, Other, Non-Entity, Disambiguation Page).", 
        "56": "Using this data set for training and testing, we achieved 96.0% F-score on this initial step, slightly better than their results (94.6% F-score).", 
        "57": "Next, we propagate the label of each English Wikipedia page to all entity mentions in all languages in the entire Wikipedia through monolingual redirect links and cross-lingual links.", 
        "58": "2.3 Learning Model and KB Derived Features  We use a typical neural network architecture that consists of Bi-directional Long Short-Term Memory and Conditional Random Fields (CRFs) network (Lample et al., 2016) as our underlying learning model for the name tagger for each language.", 
        "59": "In the following we will describe how we acquire linguistic features.", 
        "60": "When a Wikipedia user tries to link an entity mention in a sentence to an existing page, she/he will mark the title (the entity\u2019s canonical form, without affixes) within the mention\nusing brackets \u201c[[]]\u201d, from which we can naturally derive a word\u2019s stem and affixes for free.", 
        "61": "For example, from the Wikipedia markups of the following Turkish sentence: \u201cK\u0131ta Fransas\u0131, gu\u0308neyde [[Akdeniz]]den kuzeyde\n[[Mans\u0327 Denizi]] ve [[Kuzey Denizi]]ne,\ndog\u0306uda [[Ren Nehri]]nden bat\u0131da [[Atlas\nOkyanusu]]na kadar yay\u0131lan topraklarda yer al\u0131r.", 
        "62": "(Metropolitan France extends from the Mediterranean Sea to the English Channel and the North Sea, and from the Rhine to the Atlantic Ocean.", 
        "63": ")\u201d, we can learn the following suffixes: \u201cden\u201d, \u201cne\u201d, \u201cnden\u201d and \u201cna\u201d.", 
        "64": "We use such affix lists to perform basic word stemming, and use them as additional features to determine name boundary and type.", 
        "65": "For example, \u201cden\u201d is a noun suffix which indicates ablative case in Turkish.", 
        "66": "[[Akdeniz]]den means \u201cfrom Mediterranean Sea\u201d.", 
        "67": "Note that this approach can only perform morphology analysis for words whose stem forms and affixes are directly concatenated.", 
        "68": "2.4 Self-Training to Enrich and Refine Labels  The name annotations acquired from the above procedure are far from complete to compete with manually labeled gold-standard data.", 
        "69": "For example, if a name mention appears multiple times in a Wikipedia article, only the first mention is labeled with an anchor link.", 
        "70": "We apply self-training to propagate and refine the labels.", 
        "71": "We first train an initial name tagger using seeds selected from the labeled data.", 
        "72": "We adopt an idea from (Guo et al., 2014) which computes Normalized Pointwise Mutual Information (NPMI) (Bouma, 2009) between a tag and a token:\n4For languages that don\u2019t have word segmentation, we consider each character as a token, and use character embeddings only.", 
        "73": "NPMI(tag, token) = ln p(tag,token)p(tag)p(token)\n\u2212 ln p(tag, token) (1)\nThen we select the sentences in which all annotations satisfy NPMI(tag, token) > \u03c4 as seeds 5.", 
        "74": "For all Wikipedia articles in a language, we cluster the unlabeled sentences into n clusters 6 by collecting sentences with low cross-entropy into the same cluster.", 
        "75": "Then we apply the initial tagger to the first unlabeled cluster, select the automatically labeled sentences with high confidence, add them back into the training data, and then re-train the tagger.", 
        "76": "This procedure is repeated n times until we scan through all unlabeled data.", 
        "77": "2.5 Final Training Data Selection for Populous Languages  For some populous languages that have many millions of pages in Wikipedia, we obtain many sentences from self-training.", 
        "78": "In some emergent settings such as natural disasters it\u2019s important to train a system rapidly.", 
        "79": "Therefore we develop the following effective methods to rank and select high-quality annotated sentences.", 
        "80": "Commonness: we prefer sentences that include common entities appearing frequently in Wikipedia.", 
        "81": "We rank names by their frequency and dynamically set the frequency threshold to select a list of common names.", 
        "82": "We first initialize the name frequency threshold S to 40.", 
        "83": "If the number of the sentences is more than a desired size D for training 7, we set the threshold S = S + 5, otherwise S = S \u2212 5.", 
        "84": "We iteratively run the selection algorithm until the size of the training set reaches D for a certain S.\nTopical Relatedness: Various criteria should be adopted for different scenarios.", 
        "85": "Our previous work on event extraction (Li et al., 2011) found that by carefully select 1/3 topically related training documents for a test set, we can achieve the same performance as a model trained from the entire training set.", 
        "86": "Using an emergent disaster setting as a use case, we prefer sentences that include entities related to disaster related topics.", 
        "87": "We run an English name tagger (Manning et al., 2014) and entity linker (Pan et al., 2015) on the Leidos corpus released by the DARPA LORELEI\n5\u03c4 = 0 in our experiment.", 
        "88": "6n = 20 in our experiment.", 
        "89": "7D = 30,000 in our experiment.", 
        "90": "program 8.", 
        "91": "The Leidos corpus consists of documents related to various disaster topics.", 
        "92": "Based on the linked Wikipedia pages, we rank the frequency of Wikipedia categories and select the top 1% categories (4,035 in total) for our experiments.", 
        "93": "Some top-ranked topic labels include \u201cInternational medical and health organizations\u201d, \u201cHuman rights organizations\u201d, \u201cInternational development agencies\u201d, \u201cWestern Asian countries\u201d, \u201cSoutheast African countries\u201dand \u201cPeople in public health\u201d.", 
        "94": "Then we select the annotated sentences including names (e.g., \u201cWorld Health Organization\u201d) in all languages labeled with these topic labels to train the final model.", 
        "95": "3 Cross-lingual Entity Linking    3.1 Overview  After we extract names from test documents in a source language, we translate them into English by automatically mined word translation pairs (Section 3.2), and then link translated English mentions to an external English KB (Section 3.3).", 
        "96": "The overall linking process is illustrated in Figure 3.", 
        "97": "3.2 Name Translation  The cross-lingual Wikipedia title pairs, generated through crowd-sourcing, generally follow a consistent style and format in each language.", 
        "98": "From Table 2 we can see that the order of modifier and head word keeps consistent in Turkish and English titles.", 
        "99": "8http://www.darpa.mil/program/low-resource-languagesfor-emergent-incidents\nFor each name mention, we generate all possible combinations of continuous tokens.", 
        "100": "For example, no Wikipedia titles contain the Turkish name \u201cPekin Teknoloji Enstitu\u0308su\u0308 (Beijing Institute of Technology)\u201d.", 
        "101": "We generate the following 6 combinations: \u201cPekin\u201d, \u201cTeknoloji\u201d, \u201cEnstitu\u0308su\u0308\u201d, \u201cPekin Teknoloji\u201d, \u201cTeknoloji Enstitu\u0308su\u0308\u201d and \u201cPekin Teknoloji Enstitu\u0308su\u0308\u201d, and then extract all cross-lingual Wikipedia title pairs containing each combination.", 
        "102": "Finally we run GIZA++ (Josef Och and Ney, 2003) to extract word for word translations from these title pairs, as shown in Table 2.", 
        "103": "3.3 Entity Linking  Given a set of tagged name mentions M = {m1,m2, ...,mn}, we first obtain their English translations T = {t1, t2, ..., tn} using the approach described above.", 
        "104": "Then we apply an unsupervised collective inference approach to link T\nto the KB, similar to our previous work (Pan et al., 2015).", 
        "105": "The only difference is that we construct knowledge networks (KNs) g(ti) for T based on their co-occurrence within a context window 9 instead of their AMR relations, because AMR parsing is not available for foreign languages.", 
        "106": "For each translated name mention ti, an initial list of candidate entities E(ti) = {e1, e2, ..., ek} is generated based on a surface form dictionary mined from KB properties (e.g., redirects, names, aliases).", 
        "107": "If no surface form can be matched then we determine the mention as unlinkable.", 
        "108": "Then we construct KNs g(ej) for each entity candidate ej in ti\u2019s entity candidate list E(ti).", 
        "109": "We compute the similarity between g(ti) and g(ej) based on three measures: salience, similarity and coherence, and select the candidate entity with the highest score.", 
        "110": "4 Experiments    4.1 Performance on Wikipedia Data  We first conduct an evaluation using Wikipedia data as \u201csilver-standard\u201d.", 
        "111": "For each language, we use 70% of the selected sentences for training and 30% for testing.", 
        "112": "For entity linking, we don\u2019t have ground truth for unlinkable mentions, so we only compute linking accuracy for linkable name mentions.", 
        "113": "Table 3 presents the overall performance for three coarse-grained entity types: PER, ORG and GPE/LOC, sorted by the number of name mentions.", 
        "114": "Figure 4 and Figure 5 summarize the performance, with some example languages marked for various ranges of data size.", 
        "115": "Not surprisingly, name tagging performs better for languages with more training mentions.", 
        "116": "The\n9In our experiments, we use the previous four and next four name mentions as a context window.", 
        "117": "F-score is generally higher than 80% when there are more than 10K mentions, and it significantly drops when there are less than 250 mentions.", 
        "118": "The languages with low name tagging performance can be categorized into three types: (1) the number of mentions is less than 2K, such as AtlanticCongo (Wolof), Berber (Kabyle), Chadic (Hausa), Oceanic (Fijian), Hellenic (Greek), Igboid (Igbo), Mande (Bambara), Kartvelian (Georgian, Mingrelian), Timor-Babar (Tetum), Tupian (Guarani) and Iroquoian (Cherokee) language groups; Precision is generally higher than recall for most of these languages, because the small number of linked mentions is not enough to cover a wide variety of entities.", 
        "119": "(2) there is no space between words, including Chinese, Thai and Japanese; (3) they are not written in latin script, such as the Dravidian group (Tamil, Telugu, Kannada, Malayalam).", 
        "120": "The training instances for various entity types are quite imbalanced for some languages.", 
        "121": "For example, Latin data includes 11% PER names, 84% GPE/LOC names and 5% ORG names.", 
        "122": "As a result, the performance of ORG is the lowest, while GPE and LOC achieve higher than 75% F-scores for most languages.", 
        "123": "The linking accuracy is higher than 80% for most languages.", 
        "124": "Also note that since we don\u2019t have perfect annotations on Wikipedia data for any language, these results can be used to estimate how predictable our \u201csilver-standard\u201d data is, but they are not directly comparable to traditional name tagging results measured against goldstandard data annotated by human.", 
        "125": "10The mapping to language names can be found at http://nlp.cs.rpi.edu/wikiann/mapping  4.2 Performance on Non-Wikipedia Data  In order to have more direct comparison with state-of-the-art name taggers trained from human annotated gold-standard data, we conduct experiments on non-Wikipedia data in 9 languages for which we have human annotated ground truths from the DARPA LORELEI program.", 
        "126": "Table 4 shows the data statistics.", 
        "127": "The documents are from news sources and discussion fora.", 
        "128": "For fair comparison, we use the same learning method and feature set as described in Section 2.3 to train the models using gold-standard data.", 
        "129": "Therefore the results of our models trained from gold-standard data are slightly different from some previous work such as (Tsai et al., 2016), mainly due to different learning algorithms and different features sets.", 
        "130": "For example, the gazetteers we used are different from those in (Tsai et al., 2016), and we did not use brown clusters as additional features.", 
        "131": "The name tagging results on LORELEI data set are presented in Table 5.", 
        "132": "We can see that our approach advances state-of-the-art languageindependent methods (Zhang et al., 2016a; Tsai et al., 2016) on the same data sets for most languages, and achieves 6.5% - 17.6% lower F-scores than the models trained from manually annotated gold-standard documents that include thousands of name mentions.", 
        "133": "To fill in this gap, we would need to exploit more linguistic resources.", 
        "134": "Mayfield et al.", 
        "135": "(2011) constructed a crosslingual entity linking collection for 21 languages, which covers ground truth for the largest number of languages to date.", 
        "136": "Therefore we compare our approach with theirs that uses a supervised name transliteration model (McNamee et al., 2011).", 
        "137": "The entity linking results on non-NIL mentions are presented in Table 6.", 
        "138": "We can see that except Romanian, our approach outperforms or achieves comparable accuracy as their method on all languages, without using any additional resources or tools such as name transliteration.", 
        "139": "4.3 Analysis  Impact of KB-derived Morphological Features We measured the impact of our affix lists derived from Wikipedia markups on two morphologicallyrich languages: Turkish and Uzbek.", 
        "140": "The morphol-\n11McNamee et al.", 
        "141": "(2011) did not develop a model for Chinese even though Chinese data set was included in the collection.", 
        "142": "ogy features contributed 11.1% and 7.1% absolute name tagging F-score gains to Turkish and Uzbek LORELEI data sets respectively.", 
        "143": "Impact of Self-Training Using Turkish as a case study, the learning curves of self-training on Wikipedia and non-Wikipedia\ntest sets are shown in Figure 6.", 
        "144": "We can see that self-training provides significant improvement for both Wikipedia (6% absolute gain) and non-Wikipedia test data (12% absolute gain).", 
        "145": "As expected the learning curve on Wikipedia data is more smooth and converges more slowly than that of non-Wikipedia data.", 
        "146": "This indicates that when the training data is incomplete and noisy, the model can benefit from self-training through iterative label correction and propagation.", 
        "147": "Impact of Topical Relatedness We also found that the topical relatedness measure proposed in Section 2.5 not only significantly reduces the size of training data and thus speeds up the training process for many languages, but also consistently improves the quality.", 
        "148": "For example, the Turkish name tagger trained from the entire data set without topic selection yields 49.7% Fscore on LORELEI data set, and the performance is improved to 51.5% after topic selection.", 
        "149": "5 Related Work  Wikipedia markup based silver standard generation: Our work was mainly inspired from previous work that leveraged Wikipedia markups to train name taggers (Nothman et al., 2008; Dakka and Cucerzan, 2008; Mika et al., 2008; Ringland et al., 2009; Alotaibi and Lee, 2012; Nothman et al., 2013; Althobaiti et al., 2014).", 
        "150": "Most of these previous methods manually classified many English Wikipedia entries into pre-defined entity types.", 
        "151": "In contrast, our approach doesn\u2019t need any manual annotations or language-specific features, while generates both coarse-grained and fine-grained types.", 
        "152": "Many fine-grained entity typing approaches (Fleischman and Hovy, 2002; Giuliano,\n2009; Ekbal et al., 2010; Ling and Weld, 2012; Yosef et al., 2012; Nakashole et al., 2013; Gillick et al., 2014; Yogatama et al., 2015; Del Corro et al., 2015) also created annotations based on Wikipedia anchor links.", 
        "153": "Our framework performs both name identification and typing and takes advantage of richer structures in the KBs.", 
        "154": "Previous work on Arabic name tagging (Althobaiti et al., 2014) extracted entity titles as a gazetteer for stemming, and thus it cannot handle unknown names.", 
        "155": "We developed a new method to derive generalizable affixes for morphologically rich language based on Wikipedia markups.", 
        "156": "Wikipedia as background features for IE: Wikipedia pages have been used as additional features to improve various Information Extraction (IE) tasks, including name tagging (Kazama and Torisawa, 2007), coreference resolution (Paolo Ponzetto and Strube, 2006), relation extraction (Chan and Roth, 2010) and event extraction (Hogue et al., 2014).", 
        "157": "Other automatic name annotation generation methods have been proposed, including KB driven distant supervision (An et al., 2003; Mintz et al., 2009; Ren et al., 2015) and cross-lingual projection (Li et al., 2012; Kim et al., 2012; Che et al., 2013; Wang et al., 2013; Wang and Manning, 2014; Zhang et al., 2016b).", 
        "158": "Multi-lingual name tagging: Some recent research (Zhang et al., 2016a; Littell et al., 2016; Tsai et al., 2016) under the DARPA LORELEI program focused on developing name tagging techniques for low-resource languages.", 
        "159": "These approaches require English annotations for projection (Tsai et al., 2016), some input from a native speaker, either through manual annotations (Littell et al., 2016), or a linguistic survey (Zhang et al., 2016a).", 
        "160": "Without using any manual annotations, our name taggers outperform previous methods on the same data sets for many languages.", 
        "161": "Multi-lingual entity linking: NIST TAC-KBP Tri-lingual entity linking (Ji et al., 2016) focused on three languages: English, Chinese and Spanish.", 
        "162": "(McNamee et al., 2011) extended it to 21 languages.", 
        "163": "But their methods required labeled data and name transliteration.", 
        "164": "We share the same goal as (Sil and Florian, 2016) to extend cross-lingual entity linking to all languages in Wikipedia.", 
        "165": "They exploited Wikipedia links to train a supervised linker.", 
        "166": "We mine reliable word translations from cross-lingual Wikipedia titles, which enables us\nto adopt unsupervised English entity linking techniques such as (Pan et al., 2015) to directly link translated English name mentions to English KB.", 
        "167": "Efforts to save annotation cost for name tagging: Some previous work including (Ji and Grishman, 2006; Richman and Schone, 2008; Althobaiti et al., 2013) exploited semi-supervised methods to save annotation cost.", 
        "168": "We observed that self-training can provide further gains when the training data contains certain amount of noise.", 
        "169": "6 Conclusions and Future Work  We developed a simple yet effective framework that can extract names from 282 languages and link them to an English KB.", 
        "170": "This framework follows a fully automatic training and testing pipeline, without the needs of any manual annotations or knowledge from native speakers.", 
        "171": "We evaluated our framework on both Wikipedia articles and external formal and informal texts and obtained promising results.", 
        "172": "To the best of our knowledge, our multilingual name tagging and linking framework is applied to the largest number of languages.", 
        "173": "We release the following resources for each of these 282 languages: \u201csilver-standard\u201d name tagging and linking annotations with multiple levels of granularity, morphology analyzer if it\u2019s a morphologically-rich language, and an endto-end name tagging and linking system.", 
        "174": "In this work, we treat all languages independently when training their corresponding name taggers.", 
        "175": "In the future, we will explore the topological structure of related languages and exploit cross-lingual knowledge transfer to enhance the quality of extraction and linking.", 
        "176": "The general idea of deriving noisy annotations from KB properties can also be extended to other IE tasks such as relation extraction.", 
        "177": "Acknowledgments  This work was supported by the U.S. DARPA LORELEI Program No.", 
        "178": "HR0011-15-C-0115, ARL/ARO MURI W911NF-10-1-0533, DARPA DEFT No.", 
        "179": "FA8750-13-2-0041 and FA8750-13-20045, and NSF CAREER No.", 
        "180": "IIS-1523198.", 
        "181": "The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the U.S. Government.", 
        "182": "The U.S. Government is authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notation here on."
    }, 
    "document_id": "P17-1178.pdf.json"
}
