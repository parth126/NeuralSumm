{
    "abstract_sentences": {
        "1": "Traditional Entity Linking (EL) technologies rely on rich structures and properties in the target knowledge base (KB).", 
        "2": "However, in many applications, the KB may be as simple and sparse as lists of names of the same type (e.g., lists of products).", 
        "3": "We call it as List-only Entity Linking problem.", 
        "4": "Fortunately, some mentions may have more cues for linking, which can be used as seed mentions to bridge other mentions and the uninformative entities.", 
        "5": "In this work, we select the most linkable mentions as seed mentions and disambiguate other mentions by comparing them with the seed mentions rather than directly with the entities.", 
        "6": "Our experiments on linking mentions to seven automatically mined lists show promising results and demonstrate the effectiveness of our approach.1"
    }, 
    "body_sentences": {
        "1": "  Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 536\u2013541 Vancouver, Canada, July 30 - August 4, 2017. c\u00a92017 Association for Computational Linguistics\nhttps://doi.org/10.18653/v1/P17-2085  1 Introduction  Traditional Entity Linking (EL) methods usually rely on rich structures and properties in the target knowledge base (KB).", 
        "2": "These methods may not be effective in applications where detailed descriptions and properties of target entities are absent in the KB.", 
        "3": "Consider the following situations:\nDisaster Response and Recovery.", 
        "4": "When a disaster strikes, people rush to the web and post tweets about the damage and casualties.", 
        "5": "Performing EL to extract key information, such as devastated towns and donor agencies, can help us monitor the situation and coordinate rescue and recovery efforts.", 
        "6": "Although many involved entities are\n\u2217Part of this work was done when the first author was on an internship at Microsoft Research Asia.", 
        "7": "1The data set is available at: http://nlp.cs.rpi.edu/data/ link-only-entity-linking.html\nnot well-known and usually absent in general KBs, we may be able to acquire lists of these entities from the local government as the target KB.", 
        "8": "Voice of the Customer.", 
        "9": "EL also plays an important role in mining customer opinions from data generated on social platforms and ecommerce websites, thereby helping companies better understand the needs and expectations of their customers.", 
        "10": "However, the target products are often not covered by general KBs.", 
        "11": "For example, (Cao et al., 2015) tested 32 names of General Motors car models and only found 4 in Wikipedia.", 
        "12": "Although some companies may choose to maintain a comprehensive product KB, it will be much more practical and less costly to provide only lists of product names.", 
        "13": "Under such circumstances, we need the ability to perform EL to ad-hoc name lists instead of a comprehensive KB, namely List-only Entity Linking.", 
        "14": "Take Figure 1 as an example.", 
        "15": "For a human reader, it is not difficult to figure out the referent entities of mentions in each document based on\n536\nclues such as \u201cbasketball\u201d and \u201cLDA\u201d, whereas we will not be able to make such inference without the knowledge of the target entities.", 
        "16": "However, even if we lack the minimal knowledge (e.g., Jordan is a country), we are more confident to link mentions in d1, d4, and d5 because they co-occur with other entities in the same list.", 
        "17": "We consider such mentions that we are confident to link as seed mentions, and use them to construct contextual and non-contextual information of the target entities to enhance entity disambiguation.", 
        "18": "Therefore, in this work, we propose to tackle the problem of List-only Entity Linking through seed mentions.", 
        "19": "We automatically identify seed mentions for each list using a two-step method based on the occurrence of entities and similarity between mentions.", 
        "20": "After that, in the entity disambiguation phase, we utilize the selected mentions as a bridge between uninformative entities and other mentions.", 
        "21": "Specifically, we comparing features of a non-seed mention to those of seed mentions of its entity candidates to determine which entity it should be linked to.", 
        "22": "2 Problem Definition  Given a mention m and the entity e that it refers to, we call e the referent entity of m and m the referential mention of e. In Figure 1, for example, Michael Jordan1 is the referent entity of \u201cJordan\u201d in document d6, while \u201cJordan\u201d in document d2 is an non-referential mention for Michael Jordan1.", 
        "23": "As Figure 1 shows, in the setting of Listonly Entity Linking, there are a set of manually or automatically generated entity lists E = {E1, E2, ..., El} and a set of documents D = {d1, d2, ..., dn}.", 
        "24": "Entities in the same list are homogeneous and share some common properties.", 
        "25": "In our experiment, each document di contains a mention mi to link.", 
        "26": "Our goal is to link mi to its referent entity ei,j \u2208 Ej or returns NIL if it is unlinkable to any entities.", 
        "27": "3 Approach  Our framework has two modules, entity candidate retrieval and entity disambiguation as Figure 2 shows.", 
        "28": "For a mention \u201cJordan,\u201d we retrieve two candidate entities, Michael Jordan1 and Michael Jordan2, from the entity lists.", 
        "29": "Next, we select a set of seed mentions for each entity from all documents.", 
        "30": "To determine the referent en-\ntity of \u201cJordan\u201d, we compare it with seed mentions of each candidate instead of the entity itself.", 
        "31": "3.1 Entity Candidate Retrieval  For each mention mi, we first locate a set of entity candidates Ci = {ei,j |ei,j \u2208 Ej} that it possibly refers to.", 
        "32": "A mention and its referent entity may have different surface forms (e.g., \u201cBMW\u201d and Bayerische Motoren Werke).", 
        "33": "For this reason, we design a set of matching rules to improve the recall as shown in Table 1.", 
        "34": "3.2 Entity Disambiguation  Next, we proceed to score each candidate ei,j and determine which one mi should be linked to.", 
        "35": "However, we have no knowledge of the target entities except for names and thus can\u2019t directly compare mi with them.", 
        "36": "Rather, we propose to bridge the gap between mentions and entities through seed mentions.", 
        "37": "We illustrate the idea in Figure 3.", 
        "38": "University of Pennsylvania is retrieved as an entity candidate for mentions \u201cUniversity of Pennsylvania\u201d, \u201cPenn\u201d, and \u201cPennsylvania.\u201d We are more confident to link \u201cUniversity of Pennsylvania\u201d in dI and \u201cPenn\u201d in dII to University of Pennsylvania because other entities in the University list, such as \u201cHarvard\u201d and \u201cMIT,\u201d also appear in the same document.", 
        "39": "Thus, we select mentions in dI and dII as seed mentions.", 
        "40": "From dI and dII , we can extract both contextual features (e.g., \u201cacademic\u201d and \u201cresearch\u201d) and non-contextual features (e.g., the entity type is ORG).", 
        "41": "After that, we compare mentions in other documents with the seeds.", 
        "42": "We link \u201cPenn\u201d in dIII to University of Pennsylvania because its entity type and context are consistent with the seeds.", 
        "43": "\u201cPennsylvania\u201d in dIV , however, is not linked because it is recognized as a location.", 
        "44": "To capture richer contextual information and minimize the effect of noise, we select more than one seed mention using a two-step approach as follows.", 
        "45": "1.", 
        "46": "Subset Selection.", 
        "47": "We assume that if multiple names in the same list co-occur within a docu-\nment, they are all likely to be referential mentions of this list, such as \u201cMichael Jordan\u201d and \u201cLeBron James\u201d in d1.", 
        "48": "Hence, to identify seed mentions of list Ej , we first narrow the scope down to a subset D(n)j of documents containing more than n mentions matching names in Ej .", 
        "49": "We gradually increase the n until \u03b8\u2212size \u2264 |D (n) j | \u2264 \u03b8+size.", 
        "50": "\u03b8\u2212size and \u03b8+size are set to 50 and 300 in our experiments.", 
        "51": "2.", 
        "52": "Clustering.", 
        "53": "We expect most mentions in the selected subset are referential of list Ej , while in fact the subset is likely to contain a small number of non-referential mentions.", 
        "54": "We need to eliminate them from the subset, otherwise they will introduce misleading features differing from the real seed mentions, hence hurting the performance of entity disambiguation.", 
        "55": "To separate referential and non-referential mentions in the selected subset, we make two assumptions: (1) Most mentions in the subset are referential, and (2) Referential mentions should be similar to each other while dissimilar from non-referential ones.", 
        "56": "Due to the lack of annotated data, we approach this problem by performing clustering, which works in an unsupervised fashion.", 
        "57": "Specifically, we represent features (described later in this section) of each mention as a vector and measure the distance between two mentions using cosine distance.", 
        "58": "After that, we run the K-means++ algorithm on the subset to separate referential and non-referential mentions, and pick mentions in the largest cluster as seed mentions.", 
        "59": "To determine the referent entity of mention mi, we calculate the confidence score of linking mi to ei,j \u2208 Ej using the average cosine similarity between mi and seed mentions of list Ej :\nc(mi, ei,j) = 1\n|Sj |\n|Sj |\u2211\np=1\nsim(mi,ms),ms \u2208 Sj\nwhere Sj is the seed set of Ej .", 
        "60": "Lastly, we link mi to the candidate with the highest confidence score.", 
        "61": "In this work, we use the following features.", 
        "62": "Entity Type.", 
        "63": "The entity type of a mention can be inferred from the text and used for disambiguation.", 
        "64": "For example, if most seed mentions for the University list are recognized as ORG, while \u201cHarvard\u201d in the sentence \u201cHarvard was born and raised in Southwark, Surrey, England\u201d is tagged as PER, it is unlikely to refer to Harvard University.", 
        "65": "Textual Context.", 
        "66": "We also assume that referential mentions of the same entity should share\nsimilar local contexts.", 
        "67": "We represent textual context using the average embedding of words within a window around the mention.", 
        "68": "Punctuation.", 
        "69": "Punctuations preceding or following a mention may help resolve ambiguity.", 
        "70": "For example, \u201cMA\u201d preceded by a comma is possible to refer to a state, since states are usually the last component of an address, such as \u201cBoston, MA\u201d.", 
        "71": "4 Experiments    4.1 Data set  In our experiment, the construction of data set consists of two steps: collecting name lists from NeedleSeek2 (Shi et al., 2010) and extracting documents from Wikipedia.", 
        "72": "NeedleSeek is a project aiming to mine semantic concepts from tera-scale data (ClueWeb09) and classify them into a wide range of semantic categories.", 
        "73": "For example, \u201cKFC\u201d is mined as a concept in the restaurant category, along with key sentences and attributes, such as employee number and founder.", 
        "74": "To obtain target name lists, we select 7 semantic categories (see Table 2) generated by NeedleSeek as target domains, and take the top concepts in each category as target entities.", 
        "75": "We manually map each name to its pertinent Wikipedia page as a target entity (e.g., Starbucks \u2192 enwiki:Starbucks3).", 
        "76": "Thus, we collect lists containing 139 target entities in total.", 
        "77": "Note that category names are only for result presentation purpose and not taken as input to our model.", 
        "78": "Next, we derive a data set from Wikipedia articles through wikilinks4, which are links to pages within English Wikipedia.", 
        "79": "For example, a wikilink [[Harvard University|Harvard]] appears as \u201cHarvard\u201d in text and links to the page enwiki:Harvard_University.", 
        "80": "Thus, we can consider \u201cHarvard\u201d as a name mention and\n2http://needleseek.msra.cn 3enwiki: is short for https://en.wikipedia.org/wiki/ 4https://en.wikipedia.org/wiki/Help:Link\nenwiki:Harvard_University as its referent entity.", 
        "81": "Consider the following sentences: \u2217 ... then left toattend graduate school on a scholarship at [[Harvard University|Harvard University]]... \u2217 On October 6, 2012, [[Allison Harvard|Harvard]] made an appearance in an episode of...\nBecause enwiki:Harvard_University is in the University list, the first mention will be considered as referential, whereas the second one is non-referential.", 
        "82": "We also apply matching rules in Table 1 to obtain more non-referential mentions.", 
        "83": "After that, we extract sentences around wikilinks as a document.", 
        "84": "From Table 3, we can see that referential entities overwhelm non-referential ones in the extracted corpus.", 
        "85": "In order to evaluate our model fairly, we perform downsampling to balance referential and non-referential mentions, otherwise we can achieve high scores even if we link all mention to the target entities.", 
        "86": "In the balanced data set, there are 11, 065 unique entities.", 
        "87": "4.2 Entity Linking Results  As Table 4 demonstrates, our method shows promising results (87.0 F1 score) on the balanced data set.", 
        "88": "Nevertheless, we notice the low linking precisions for entities in the Character and State lists, which are caused by different reasons.", 
        "89": "For the Character list, mentions do not suffice to select\nhigh-quality seeds, whereas for the State list, features of referential and non-referential mentions are usually similar.", 
        "90": "Consider the following sentence: \u2217 She witnessed his fatal shooting when they were together in the President\u2019s Box at Ford\u2019s Theatre on Tenth Street in\nWashington.", 
        "91": "The mention \u201cWashington\u201d refers to \u201cWashington, D.C.\u201d, which has the same entity type, LOCATION, as our target entity \u201cWashington (state)\u201d.", 
        "92": "In addition, we see no obvious textual clue that indicates whether it refers to the State of Washington or not.", 
        "93": "Traditional EL approaches usually disambiguate such mentions through collective inference.", 
        "94": "They link \u201cFord\u2019s Theatre\u201d and \u201cWashington\u201d to the KB simultaneously.", 
        "95": "Since there exists an explicit relation between \u201cFord\u2019s Theatre\u201d and \u201cWashington, D.C.\u201d, these two entities receive high confidence scores and thus are determined as the referents.", 
        "96": "Unfortunately, we cannot employ the knowledge-rich approach in the List-only Entity Linking scenario.", 
        "97": "5 Related Work  In this paper, we define and study the List-only Entity Linking problem based on previous studies on Target Entity Disambiguation (Wang et al., 2012; Cao et al., 2015).", 
        "98": "The key difference is that they target at the disambiguation of a single list of entities, whereas we focus on entity linking to an arbitrary number of lists.", 
        "99": "Another similar problem is Named Entity Disambiguation with Linkless Knowledge Bases (LNED) (Li et al., 2016).", 
        "100": "It assumes that entities are isolated in the \u201clinkless\u201d KB, while each entity still has a description.", 
        "101": "Our idea of selecting seed mentions based on co-occurrence is similar to collective inference.", 
        "102": "Most state-of-the-art EL methods utilize collective inference to link a set of coherent mentions simultaneously by selecting the most coherent set of entity candidates on the KB side (Pan et al., 2015; Huang et al., 2014; Cheng and Roth, 2013; Cassidy et al., 2012; Xu et al., 2012).", 
        "103": "In this work, without explicit relations between entities in different lists, we only take the cooccurrence of mentions in the same list into consideration.", 
        "104": "Therefore, our method is unable to benefit from the co-occurrence of John Lennon and Give Peace a Chance although they are actually strongly connected.", 
        "105": "6 Conclusions and Future Work  In this paper, we proposed a novel framework to tackle the problem of List-only Entity Linking.", 
        "106": "The core of this framework is selecting seed mentions for each entity list to bridge the gap between mentions and non-informative target entities.", 
        "107": "Our results show this EL framework works well for this task.", 
        "108": "At present, in the seed selection step, we simply consider all co-occurring mentions of entities in the same list.", 
        "109": "In the future, we will employ more precise approaches to choose co-occurring mentions and mine relations between entities in separate lists to improve seed selection and entity disambiguation.", 
        "110": "Acknowledgments  This work was supported by the DARPA DEFT No.FA8750-13-2-0041, U.S. DARPA LORELEI Program No.", 
        "111": "HR0011-15-C-0115, U.S. ARL NSCTA No.", 
        "112": "W911NF-09-2-0053, and NSF IIS1523198.", 
        "113": "The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the U.S. Government.", 
        "114": "The U.S. Government is authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notation here on."
    }, 
    "document_id": "P17-2085.pdf.json"
}
