{
    "abstract_sentences": {
        "1": "How fake news goes viral via social media?", 
        "2": "How does its propagation pattern differ from real stories?", 
        "3": "In this paper, we attempt to address the problem of identifying rumors, i.e., fake information, out of microblog posts based on their propagation structure.", 
        "4": "We firstly model microblog posts diffusion with propagation trees, which provide valuable clues on how an original message is transmitted and developed over time.", 
        "5": "We then propose a kernel-based method called Propagation Tree Kernel, which captures high-order patterns differentiating different types of rumors by evaluating the similarities between their propagation tree structures.", 
        "6": "Experimental results on two real-world datasets demonstrate that the proposed kernel-based approach can detect rumors more quickly and accurately than state-ofthe-art rumor detection models."
    }, 
    "body_sentences": {
        "1": "  Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 708\u2013717 Vancouver, Canada, July 30 - August 4, 2017. c\u00a92017 Association for Computational Linguistics\nhttps://doi.org/10.18653/v1/P17-1066  1 Introduction  On November 9th, 2016, Eric Tucker, a grassroots user who had just about 40 followers on Twitter, tweeted his unverified observations about paid protesters being bused to attend anti-Trump demonstration in Austin, Texas.", 
        "2": "The tweet, which was proved false later, was shared over 16 thousand times on Twitter and 350 thousand times on Facebook within a couple of days, fueling a nation-wide conspiracy theory1.", 
        "3": "The diffusion of the story is illustrated as Figure 1 which gives the key spreading points of the story along the time line.", 
        "4": "We can see that after the initial post, the tweet\n1https://www.nytimes.com/2016/11/20/ business/media/how-fake-news-spreads.", 
        "5": "html\nwas shared or promoted by some influential online communities and users (including Trump himself), resulting in its wide spread.", 
        "6": "A widely accepted definition of rumor is \u201cunverified and instrumentally relevant information statements in circulation\u201d (DiFonzo and Bordia, 2007).", 
        "7": "This unverified information may eventually turn out to be true, or partly or entirely false.", 
        "8": "In today\u2019s ever-connected world, rumors can arise and spread at lightening speed thanks to social media platforms, which could not only be wrong, but be misleading and dangerous to the public society.", 
        "9": "Therefore, it is crucial to track and debunk such rumors in timely manner.", 
        "10": "Journalists and fact-checking websites such as snopes.com have made efforts to track and detect rumors.", 
        "11": "However, such endeavor is manual, thus prone to poor coverage and low speed.", 
        "12": "Feature-based methods (Castillo et al., 2011; Yang et al., 2012; Ma et al., 2015) achieved certain success by employing large feature sets crafted from message contents, user profiles and holistic statistics of diffusion patterns (e.g., number of retweets, propagation time, etc.).", 
        "13": "But such an approach was over simplified as they ignored the dynamics of rumor propagation.", 
        "14": "Existing studies considering propagation characteristics mainly focused on the temporal features (Kwon et al., 2013, 2017) rather than the structure of propagation.", 
        "15": "So, can the propagation structure make any difference for differentiating rumors from nonrumors?", 
        "16": "Recent studies showed that rumor spreaders are persons who want to get attention and popularity (Sunstein, 2014).", 
        "17": "However, popular users who get more attention on Twitter (e.g., with more followers) are actually less likely to spread rumor in a sense that the high audience size might hinder a user from participating in propagating unverified information (Kwon et al., 2017).", 
        "18": "Intuitively, for \u201csuccessful\u201d rumors being propagated as widely\n708\nas popular real news, initial spreaders (typically lack of popularity) must attract certain amount of broadcasting power, e.g., attention of influential users or communities that have a lot of audiences joining in promoting the propagation.", 
        "19": "We refer to this as a constrained mode propagation, relative to the open mode propagation of normal messages that everyone is open to share.", 
        "20": "Such different modes of propagation may imply some distinct propagation structures between rumors and nonrumors and even among different types of rumors.", 
        "21": "Due to the complex nature of information diffusion, explicitly defining discriminant features based on propagation structure is difficult and biased.", 
        "22": "Figure 2 exemplifies the propagation structures of two Twitter posts, a rumor and a nonrumor, initiated by two users shown as the root nodes (in green color).", 
        "23": "The information flows here illustrate that the rumorous tweet is first posted by a low-impact user, then some popular users joining in who boost the spreading, but the non-rumorous tweet is initially posted by a popular user and directly spread by many general users; contentbased signal like various users\u2019 stance (Zhao et al., 2015) and edge-based signal such as relative influence (Kwon et al., 2017) can also suggest the different nature of source tweets.", 
        "24": "Many of such implicit distinctions throughout message propagation are hard to hand craft specifically using flat summary of statistics as previous work did.", 
        "25": "In addition, unlike representation learning for plain text, learning for representation of structures such as networks is not well studied in general.", 
        "26": "Therefore, traditional and latest text-based models (Castillo\net al., 2011; Ma et al., 2015, 2016) cannot be applied easily on such complex, dynamic structures.", 
        "27": "To capture high-order propagation patterns for rumor detection, we firstly represent the propagation of each source tweet with a propagation tree which is formed by harvesting user\u2019s interactions to one another triggered by the source tweet.", 
        "28": "Then, we propose a kernel-based data-driven method called Propagation Tree Kernel (PTK) to generate relevant features (i.e., subtrees) automatically for estimating the similarity between two propagation trees.", 
        "29": "Unlike traditional tree kernel (Moschitti, 2006; Zhang et al., 2008) for modeling syntactic structure based on parse tree, our propagation tree consists of nodes corresponding to microblog\nposts, each represented as a continuous vector, and edges representing the direction of propagation and providing the context to individual posts.", 
        "30": "The basic idea is to find and capture the salient substructures in the propagation trees indicative of rumors.", 
        "31": "We also extend PTK into a context-enriched PTK (cPTK) to enhance the model by considering different propagation paths from source tweet to the roots of subtrees, which capture the context of transmission.", 
        "32": "Extensive experiments on two real-world Twitter datasets show that the proposed methods outperform state-of-the-art rumor detection models with large margin.", 
        "33": "Moreover, most existing approaches regard rumor detection as a binary classification problem, which predicts a candidate hypothesis as rumor or not.", 
        "34": "Since a rumor often begins as unverified and later turns out to be confirmed as true or false, or remains unverified (Zubiaga et al., 2016), here we consider a set of more practical, finer-grained classes: false rumor, true rumor, unverified rumor, and non-rumor, which becomes an even more challenging problem.", 
        "35": "2 Related Work  Tracking misinformation or debunking rumors has been a hot research topic in multiple disciplines (DiFonzo and Bordia, 2007; Morris et al., 2012; Rosnow, 1991).", 
        "36": "Castillo et al.", 
        "37": "(2011) studied information credibility on Twitter using a wide range of hand-crafted features.", 
        "38": "Following that, various features corresponding to message contents, user profiles and statistics of propagation patterns were proposed in many studies (Yang et al., 2012; Wu et al., 2015; Sun et al., 2013; Liu et al., 2015).", 
        "39": "Zhao et al.", 
        "40": "(2015) focused on early rumor detection by using regular expressions for finding questing and denying tweets as the key for debunking rumor.", 
        "41": "All such approaches are over simplistic because they ignore the dynamic propagation patterns given the rich structures of social media data.", 
        "42": "Some studies focus on finding temporal patterns for understanding rumor diffusion.", 
        "43": "Kown et al.", 
        "44": "(2013; 2017) introduced a time-series fitting model based on the temporal properties of tweet volume.", 
        "45": "Ma et al.", 
        "46": "(2015) extended the model using time series to capture the variation of features over time.", 
        "47": "Friggeri et al.", 
        "48": "(2014) and Hannak et al.", 
        "49": "(2014) studied the structure of misinformation cascades by analyzing comments linking to\nrumor debunking websites.", 
        "50": "More recently, Ma et al.", 
        "51": "(2016) used recurrent neural networks to learn the representations of rumor signals from tweet text at different times.", 
        "52": "Our work will consider temporal, structural and linguistic signals in a unified framework based on propagation tree kernel.", 
        "53": "Most previous work formulated the task as classification at event level where an event is comprised of a number of source tweets, each being associated with a group of retweets and replies.", 
        "54": "Here we focus on classifying a given source tweet regarding a claim which is a finer-grained task.", 
        "55": "Similar setting was also considered in (Wu et al., 2015; Qazvinian et al., 2011).", 
        "56": "Kernel methods are designed to evaluate the similarity between two objects, and tree kernel specifically addresses structured data which has been successfully applied for modeling syntactic information in many natural language tasks such as syntactic parsing (Collins and Duffy, 2001), question-answering (Moschitti, 2006), semantic analysis (Moschitti, 2004), relation extraction (Zhang et al., 2008) and machine translation (Sun et al., 2010).", 
        "57": "These kernels are not suitable for modeling the social media propagation structures because the nodes are not given as discrete values like part-of-speech tags, but are represented as high dimensional real-valued vectors.", 
        "58": "Our proposed method is a substantial extension of tree kernel for modeling such structures.", 
        "59": "3 Representation of Tweets Propagation  On microblogging platforms, the follower/friend relationship embeds shared interests among the users.", 
        "60": "Once a user has posted a tweet, all his followers will receive the tweet.", 
        "61": "Furthermore, Twitter allows a user to retweet or comment another user\u2019s post, so that the information could reach beyond the network of the original creator.", 
        "62": "We model the propagation of each source tweet as a tree structure T (r) = \u3008V,E\u3009, where r is the source tweet as well as the root of the tree, V refers to a set of nodes each representing a responsive post (i.e., retweet or reply) of a user at a certain time to the source tweet r which initiates the circulation, and E is a set of directed edges corresponding to the response relation among the nodes in V .", 
        "63": "If there exists a directed edge from vi to vj , it means vj is a direct response to vi.", 
        "64": "More specifically, each node v \u2208 V is represented as a tuple v = (uv, cv, tv), which provides\nthe following information: uv is the creator of the post, cv represents the text content of the post, and tv is the time lag between the source tweet r and v. In our case, uv contains attributes of the user such as # of followers/friends, verification status, # of history posts, etc., cv is a vector of binary features based on uni-grams and/or bi-grams representing the post\u2019s content.", 
        "65": "4 Propagation Tree Kernel Modeling  In this section, we describe our rumor detection model based on propagation trees using kernel method called Propagation Tree Kernel (PTK).", 
        "66": "Our task is, given a propagation tree T (r) of a source tweet r, to predict the label of r.  4.1 Background of Tree Kernel  Before presenting our proposed algorithm, we briefly present the traditional tree kernel, which our PTK model is based on.", 
        "67": "Tree kernel was designed to compute the syntactic and semantic similarity between two natural language sentences by implicitly counting the number of common subtrees between their corresponding parse trees.", 
        "68": "Given a syntactic parse tree, each node with its children is associated with a grammar production rule.", 
        "69": "Figure 3 illustrates the syntactic parse tree of \u201ccut a tree\u201d and its subtrees.", 
        "70": "A subtree is defined as any subgraph which has more than one nodes, with the restriction that entire (not partial) rule productions must be included.", 
        "71": "For example, the fragment [NP [D a]] is excluded because it contains only part of the production NP\u2192 D N (Collins and Duffy, 2001).", 
        "72": "Following Collins and Duffy (2001), given two parse trees T1 and T2, the kernel function K(T1, T2) is defined as:\n\u2211\nvi\u2208V1\n\u2211\nvj\u2208V2 \u2206(vi, vj) (1)\nwhere V1 and V2 are the sets of all nodes respectively in T1 and T2, and each node is associated with a production rule, and \u2206(vi, vj) evaluates the common subtrees rooted at vi and vj .", 
        "73": "\u2206(vi, vj) can be computed using the following recursive procedure (Collins and Duffy, 2001):\n1) if the production rules at vi and vj are different, then \u2206(vi, vj) = 0;\n2) else if the production rules at vi and vj are same, and vi and vj have only leaf children\n(i.e., they are pre-terminal symbols), then \u2206(vi, vj) = \u03bb;\n3) else \u2206(vi, vj) = \u03bb \u220fmin(nc(vi),nc(vj))\nk=1 (1 + \u2206(ch(vi, k), ch(vj , k))).", 
        "74": "where nc(v) is the number of children of node v, ch(v, k) is the k-th child of node v, and \u03bb (0 < \u03bb \u2264 1) is a decay factor.", 
        "75": "\u03bb = 1 yields the number of common subtrees; \u03bb < 1 down weighs the contribution of larger subtrees to make the kernel value less variable with respect to subtree size.", 
        "76": "4.2 Our PTK Model  To classify propagation trees, we can calculate the similarity between the trees, which is supposed to reflect the distinction of different types of rumors and non-rumors based on structural, linguistic and temporal properties.", 
        "77": "However, existing tree kernels cannot be readily applied on propagation trees because 1) unlike parse tree where the node is represented by enumerable nominal value (e.g., part-of-speech tag), the propagation tree node is given as a vector of continuous numerical values representing the basic properties of the node; 2) the similarity of two parse trees is based on the count of common subtrees, for which the commonality of subtrees is evaluated by checking if the same production rules and the same children are associated with the nodes in two subtrees being compared, whereas in our context the similarity function should be defined softly since hardly two nodes from different propagation trees are same.", 
        "78": "With the representation of propagation tree, we first define a function f to evaluate the similarity between two nodes vi and vj (we simplify the node representation for instance vi = (ui, ci, ti)) as the following:\nf(vi, vj) = e \u2212t (\u03b1E(ui, uj) + (1\u2212 \u03b1)J (ci, cj))\nwhere t = |ti \u2212 tj | is the absolute difference between the time lags of vi and vj , E and J are\nuser-based similarity and content-based similarity, respectively, and \u03b1 is the trade-off parameter.", 
        "79": "The intuition of using exponential function of t to scale down the similarity is to capture the discriminant signals or patterns at the different stages of propagation.", 
        "80": "For example, a questioning message posted very early may signal a false rumor while the same posted far later from initial post may indicate the rumor is still unverified, despite that the two messages are semantically similar.", 
        "81": "The user-based similarity is defined as an Euclidean distance E(ui, uj) = ||ui \u2212 uj ||2, where ui and uj are the user vectors of node vi and vj and || \u2022 ||2 is the 2-norm of a vector.", 
        "82": "Here E is used to capture the characteristics of users participating in spreading rumors as discriminant signals, throughout the entire stage of propagation.", 
        "83": "Contentwise, we use Jaccard coefficient to measure the similarity of post content:\nJ (ci, cj) = |Ngram(ci) \u2229Ngram(cj)| |Ngram(ci) \u222aNgram(cj)|\nwhere ci and cj are the sets of content words in two nodes.", 
        "84": "For n-grams here, we adopt both uni-grams and bi-grams.", 
        "85": "It can capture cue terms e.g., \u2018false\u2019, \u2018debunk\u2019, \u2018not true\u2019, etc.", 
        "86": "commonly occurring in rumors but not in non-rumors.", 
        "87": "Given two propagation trees T1 = \u3008V1, E1\u3009 and T2 = \u3008V2, E2\u3009, PTK aims to compute the similarity between T1 and T2 iteratively based on enumerating all pairs of most similar subtrees.", 
        "88": "First, for each node vi \u2208 V1, we obtain v\u2032i \u2208 V2, the most similar node of vi from V2:\nv\u2032i = arg max vj\u2208V2 f(vi, vj)\nSimilarly, for each vj \u2208 V2, we obtain v\u2032j \u2208 V1:\nv\u2032j = arg max vi\u2208V1 f(vi, vj)\nThen, the propagation tree kernel KP (T1, T2) is defined as:\n\u2211\nvi\u2208V1 \u039b(vi, v\n\u2032 i) +\n\u2211\nvj\u2208V2 \u039b(v\u2032j , vj) (2)\nwhere \u039b(v, v\u2032) evaluates the similarity of two subtrees rooted at v and v\u2032, which is computed recursively as follows:\n1) if v or v\u2032 are leaf nodes, then \u039b(v, v\u2032) = f(v, v\u2032);\n2) else \u039b(v, v\u2032) = f(v, v\u2032) \u220fmin(nc(v),nc(v\u2032)) k=1 (1 +\n\u039b(ch(v, k), ch(v\u2032, k)))\nNote that unlike traditional tree kernel, in PTK the node similarity f \u2208 [0, 1] is used for softly counting similar subtrees instead of common subtrees.", 
        "89": "Also, \u03bb in tree kernel is not needed as subtree size is not an issue here thanks to node similarity f .", 
        "90": "PTK aims to capture discriminant patterns from propagation trees inclusive of user, content and temporal traits, which is inspired by prior analyses on rumors spreading, e.g., user information can be a strong clue in the initial broadcast, content features are important throughout entire propagation periods, and structural and temporal patterns help for longitudinal diffusion (Zubiaga et al., 2016; Kwon et al., 2017).", 
        "91": "4.3 Context-Sensitive Extension of PTK  One defect of PTK is that it ignores the clues outside the subtrees, e.g., how the information propagates from source post to the current subtree.", 
        "92": "Intuitively, propagation paths provide further clue for determining the truthfulness of information since they embed the route and context of how the propagation happens.", 
        "93": "Therefore, we propose contextsensitive PTK (cPTK) by considering the propagation paths from the root of the tree to the roots of subtrees, which shares similar intuition with the context-sensitive tree kernel (Zhou et al., 2007).", 
        "94": "For a propagation tree node v \u2208 T (r), let Lrv be the length (i.e., # of nodes) of the propagation path from root r to v, and v[x] be the x-th ancestor of v on the path starting from v (0 \u2264 x < Lrv, v[0] = v, v[Lrv \u2212 1] = r).", 
        "95": "cPTK evaluates the similarity between two trees T1(r1) and T2(r2) as follows:\n\u2211\nvi\u2208V1\nL r1 vi \u22121\u2211\nx=0\n\u039bx(vi, v \u2032 i) +\n\u2211\nvj\u2208V2\nL r2 vj \u22121\u2211\nx=0\n\u039bx(v \u2032 j , vj)\n(3) where \u039bx(v, v\u2032) measures the similarity of subtrees rooted at v[x] and v\u2032[x] for context-sensitive evaluation, which is computed as follows:\n1) if x > 0, \u039bx(v, v\u2032) = f(v[x], v\u2032[x]), where v[x] and v\u2032[x] are the x-th ancestor nodes of v and v\u2032 on the respective propagation path.", 
        "96": "2) else \u039bx(v, v\u2032) = \u039b(v, v\u2032), namely PTK.", 
        "97": "Clearly, PTK is a special case of cPTK when x = 0 (see equation 3).", 
        "98": "cPTK evaluates the oc-\ncurrence of both context-free (without considering ancestors on propagation paths) and contextsensitive cases.", 
        "99": "4.4 Rumor Detection via Kernel Learning  The advantage of kernel-based method is that we can avoid painstakingly engineering the features.", 
        "100": "This is possible because the kernel function can explore an implicit feature space when calculating the similarity between two objects (Culotta and Sorensen, 2004).", 
        "101": "We incorporate the proposed tree kernel functions, i.e., PTK (equation 2) or cPTK (equation 3), into a supervised learning framework, for which we utilize a kernel-based SVM classifier.", 
        "102": "We treat each tree as an instance, and its similarity values with all training instances as feature space.", 
        "103": "Therefore, the kernel matrix of training set is m \u00d7 m and that of test set is n\u00d7m where m and n are the sizes of training and test sets, respectively.", 
        "104": "For our multi-class task, we perform a one-vsall classification for each label and then assign the one with the highest likelihood among the four, i.e., non-rumor, false rumor, true rumor or unverified rumor.", 
        "105": "We choose this method due to interpretability of results, similar to recent work on occupational class classification (Preotiuc-Pietro et al., 2015; Lukasik et al., 2015).", 
        "106": "5 Experiments and Results    5.1 Data Sets  To our knowledge, there is no public large dataset available for classifying propagation trees, where we need a good number of source tweets, more accurately, the tree roots together with the corresponding propagation structure, to be appropriately annotated with ground truth.", 
        "107": "We constructed our datasets based on a couple of reference datasets, namely Twitter15 (Liu et al., 2015) and Twitter16 (Ma et al., 2016).", 
        "108": "The original datasets were released and used for binary classification of rumor and non-rumor with respect to given events that contain their relevant tweets.", 
        "109": "First, we extracted the popular source tweets2 that are highly retweeted or replied.", 
        "110": "We then collected all the propagation threads (i.e., retweets and replies) for these source tweets.", 
        "111": "Because Twitter API cannot retrieve the retweets or replies, we gathered the retweet users for a given tweet from\n2Though unpopular tweets could be false, we ignore them as they do not draw much attention and are hardly impactful\nTwrench3 and crawled the replies through Twitter\u2019s web interface.", 
        "112": "Finally, we annotated the source tweets by referring to the labels of the events they are from.", 
        "113": "We first turned the label of each event in Twitter15 and Twitter16 from binary to quaternary according to the veracity tag of the article in rumor debunking websites (e.g., snopes.com, Emergent.info, etc).", 
        "114": "Then we labeled the source tweets by following these rules: 1) Source tweets from unverified rumor events or non-rumor events are labeled the same as the corresponding event\u2019s label; 2) For a source tweet in false rumor event, we flip over the label and assign true to the source tweet if it expresses denial type of stance; otherwise, the label is assigned as false; 3) The analogous flip-over/nochange rule applies to the source tweets from true rumor events.", 
        "115": "We make the datasets produced publicly accessible4.", 
        "116": "Table 1 gives statistics on the resulting datasets.", 
        "117": "5.2 Experimental Setup  We compare our kernel-based method against the following baselines:\nSVM-TS: A linear SVM classification model that uses time-series to model the variation of a set of hand-crafted features (Ma et al., 2015).", 
        "118": "DTR: A Decision-Tree-based Ranking method to identify trending rumors (Zhao et al., 2015), which searches for enquiry phrases and clusters disputed factual claims, and ranked the clustered results based on statistical features.", 
        "119": "DTC and SVM-RBF: The Twitter information credibility model using Decision Tree Classifier (Castillo et al., 2011) and the SVM-based\n3https://twren.ch 4https://www.dropbox.com/s/\n7ewzdrbelpmrnxu/rumdetect2017.zip?dl=0\nmodel with RBF kernel (Yang et al., 2012), respectively, both using hand-crafted features based on the overall statistics of the posts.", 
        "120": "RFC: The Random Forest Classifier proposed by Kwon et al.", 
        "121": "(2017) using three parameters to fit the temporal properties and an extensive set of hand-crafted features related to the user, linguistic and structure characteristics.", 
        "122": "GRU: The RNN-based rumor detection model proposed by Ma et al.", 
        "123": "(2016) with gated recurrent unit for representation learning of high-level features from relevant posts over time.", 
        "124": "BOW: A naive baseline we worked by representing the text in each tree using bag-of-words and building the rumor classifier with linear SVM.", 
        "125": "Our models: PTK and cPTK are our full PTK and cPTK models, respectively; PTK- and cPTKare the setting of only using content while ignoring user properties.", 
        "126": "We implemented DTC and RFC with Weka5, SVM models with LibSVM6 and GRU with Theano7.", 
        "127": "We held out 10% of the trees in each dataset for model tuning, and for the rest of the trees, we performed 3-fold cross-validation.", 
        "128": "We used accuracy, F1 measure as evaluation metrics.", 
        "129": "5.3 Experimental Results  Table 2 shows that our proposed methods outperform all the baselines on both datasets.", 
        "130": "Among all baselines, GRU performs the best, which learns the low-dimensional representation of responsive tweets by capturing the textual and temporal information.", 
        "131": "This indicates the effectiveness of complex signals indicative of rumors beyond cue words or phrases (e.g., \u201cwhat?\u201d, \u201creally?\u201d, \u201cnot sure\u201d, etc.).", 
        "132": "This also justifies the good performance of BOW even though it only uses uni-grams for representation.", 
        "133": "Although DTR uses a set of regular expressions, we found only 19.59% and 22.21% tweets in our datasets containing these expressions.", 
        "134": "That is why the results of DTR are not satisfactory.", 
        "135": "SVM-TS and RFC are comparable because both of them utilize an extensive set of features especially focusing on temporal traits.", 
        "136": "But none of the models can directly incorporate structured propagation patterns for deep similarity compar-\n5http://www.cs.waikato.ac.nz/ml/weka/ 6https://www.csie.ntu.edu.tw/\u02dccjlin/\nlibsvm/ 7http://deeplearning.net/software/ theano/\nison between propagation trees.", 
        "137": "SVM-RBF, although using a non-linear kernel, is based on traditional hand-crafted features instead of the structural kernel like ours.", 
        "138": "So, they performed obviously worse than our approach.", 
        "139": "Representation learning methods like GRU cannot easily utilize complex structural information for learning important features from our networked data.", 
        "140": "In contrast, our models can capture complex propagation patterns from structured data rich of linguistic, user and temporal signals.", 
        "141": "Therefore, the superiority of our models is clear: PTK- which only uses text is already better than GRU, demonstrating the importance of propagation structures.", 
        "142": "PTK that combines text and user yields better results on both datasets, implying that both properties are complementary and PTK integrating flat and structured information is obviously more effective.", 
        "143": "It is also observed that cPTK outperforms PTK except for non-rumor class.", 
        "144": "This suggests the context-sensitive modeling based on PTK is effective for different types of rumors, but for non-\nrumors, it seems that considering context of propagation path is not always helpful.", 
        "145": "This might be due to the generally weak signals originated from node properties on the paths during non-rumor\u2019s diffusion since user distribution patterns in nonrumors do not seem as obvious as in rumors.", 
        "146": "This is not an issue in cPTK- since user information is not considered at all.", 
        "147": "Over all classes, cPTK achieves the highest accuracies on both datasets.", 
        "148": "Furthermore, we observe that all the baseline methods perform much better on non-rumors than on rumors.", 
        "149": "This is because the features of existing methods were defined for a binary (rumor vs. non-rumor) classification problem.", 
        "150": "So, they do not perform well for finer-grained classes.", 
        "151": "Our ap-\nproach can differentiate various classes much better by deep, detailed comparison of different patterns based on propagation structure.", 
        "152": "5.4 Early Detection Performance  Detecting rumors at an early stage of propagation is very important so that preventive measures could be taken as quickly as possible.", 
        "153": "In early detection task, all the posts after a detection deadline are invisible during test.", 
        "154": "The earlier the deadline, the less propagation information can be available.", 
        "155": "Figure 4 shows the performances of our PTK and cPTK models versus RFC (the best system based on feature engineering), GRU (the best system based on RNN) and DTR (an early-detection-\nspecific algorithm) against various deadlines.", 
        "156": "In the first few hours, our approach demonstrates superior early detection performance than other models.", 
        "157": "Particularly, cPTK achieve 75% accuracy on Twitter15 and 73% on Twitter16 within 24 hours, that is much faster than other models.", 
        "158": "Our analysis shows that rumors typically demonstrate more complex propagation substructures especially at early stage.", 
        "159": "Figure 5 shows a detected subtree of a false rumor spread in its first few hours, where influential users are somehow captured to boost its propagation and the information flows among the users with an obvious unpopular-to-popular-to-unpopular trend in terms of user popularity, but such pattern was not witnessed in non-rumors in early stage.", 
        "160": "Many textual signals (underlined) can also be observed in that early period.", 
        "161": "Our method can learn such structures and patterns naturally, but it is difficult to know and hand-craft them in feature engineering.", 
        "162": "6 Conclusion and Future Work  We propose a novel approach for detecting rumors in microblog posts based on kernel learning method using propagation trees.", 
        "163": "A propagation tree encodes the spread of a hypothesis (i.e., a source tweet) with complex structured patterns and flat information regarding content, user and time associated with the tree nodes.", 
        "164": "Enlightened by tree kernel techniques, our kernel method learns discriminant clues for identifying rumors of finer-grained levels by directly measuring the similarity among propagation trees via kernel functions.", 
        "165": "Experiments on two Twitter datasets show that our approach outperforms stateof-the-art baselines with large margin for both general and early rumor detection tasks.", 
        "166": "Since kernel-based approach covers more structural information than feature-based methods, it allows kernel to further incorporate information from a high dimensional space for possibly better discrimination.", 
        "167": "In the future, we will focus on improving the rumor detection task by exploring network representation learning framework.", 
        "168": "Moreover, we plan to investigate unsupervised models considering massive unlabeled rumorous data from social media.", 
        "169": "Acknowledgment  This work is partly supported by General Research Fund of Hong Kong (14232816).", 
        "170": "We would like\nto thank anonymous reviewers for the insightful comments."
    }, 
    "document_id": "P17-1066.pdf.json"
}
