{
    "abstract_sentences": {
        "1": "Automatic political preference prediction from social media posts has to date proven successful only in distinguishing between publicly declared liberals and conservatives in the US.", 
        "2": "This study examines users\u2019 political ideology using a sevenpoint scale which enables us to identify politically moderate and neutral users \u2013 groups which are of particular interest to political scientists and pollsters.", 
        "3": "Using a novel data set with political ideology labels self-reported through surveys, our goal is two-fold: a) to characterize the political groups of users through language use on Twitter; b) to build a fine-grained model that predicts political ideology of unseen users.", 
        "4": "Our results identify differences in both political leaning and engagement and the extent to which each group tweets using political keywords.", 
        "5": "Finally, we demonstrate how to improve ideology prediction accuracy by exploiting the relationships between the user groups."
    }, 
    "body_sentences": {
        "1": "  Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 729\u2013740 Vancouver, Canada, July 30 - August 4, 2017. c\u00a92017 Association for Computational Linguistics\nhttps://doi.org/10.18653/v1/P17-1068\nAutomatic political preference prediction from social media posts has to date proven successful only in distinguishing between publicly declared liberals and conservatives in the US.", 
        "2": "This study examines users\u2019 political ideology using a sevenpoint scale which enables us to identify politically moderate and neutral users \u2013 groups which are of particular interest to political scientists and pollsters.", 
        "3": "Using a novel data set with political ideology labels self-reported through surveys, our goal is two-fold: a) to characterize the political groups of users through language use on Twitter; b) to build a fine-grained model that predicts political ideology of unseen users.", 
        "4": "Our results identify differences in both political leaning and engagement and the extent to which each group tweets using political keywords.", 
        "5": "Finally, we demonstrate how to improve ideology prediction accuracy by exploiting the relationships between the user groups.", 
        "6": "1 Introduction  Social media is used by people to share their opinions and views.", 
        "7": "Unsurprisingly, an important part of the population shares opinions and news related to politics or causes they support, thus offering strong cues about their political preferences and ideologies.", 
        "8": "In addition, political membership is also predictable purely from one\u2019s interests or demographics \u2014 it is much more likely for a religious person to be conservative or for a younger person to lean liberal (Ellis and Stimson, 2012).", 
        "9": "\u2217 Work carried out during a research visit at the University of Pennsylvania\nUser trait prediction from text is based on the assumption that language use reflects a user\u2019s demographics, psychological states or preferences.", 
        "10": "Applications include prediction of age (Rao et al., 2010; Flekova et al., 2016b), gender (Burger et al., 2011; Sap et al., 2014), personality (Schwartz et al., 2013; Preot\u0327iuc-Pietro et al., 2016), socioeconomic status (Preot\u0327iuc-Pietro et al., 2015a,b; Liu et al., 2016c), popularity (Lampos et al., 2014) or location (Cheng et al., 2010).", 
        "11": "Research on predicting political orientation has focused on methodological improvements (Pennacchiotti and Popescu, 2011) and used data sets with publicly stated dichotomous political orientation labels due to their easy accessibility (Sylwester and Purver, 2015).", 
        "12": "However, these data sets are not representative samples of the entire population (Cohen and Ruths, 2013) and do not accurately reflect the variety of political attitudes and engagement (Kam et al., 2007).", 
        "13": "For example, we expect users who state their political affiliation in their profile description, tweet with partisan hashtags or appear in public party lists to use social media as a means of popularizing and supporting their political beliefs (BarberASa, 2015).", 
        "14": "Many users may choose not to publicly post about their political preference for various social goals or perhaps this preference may not be strong or representative enough to be disclosed online.", 
        "15": "Dichotomous political preference also ignores users who do not have a political ideology.", 
        "16": "All of these types of users are very important for researchers aiming to understand group preferences, traits or moral values (Lewis and Reiley, 2014; Hersh, 2015).", 
        "17": "The most common political ideology spectrum in the US is the conservative \u2013 liberal (Ellis and Stimson, 2012).", 
        "18": "We collect a novel data set of Twitter users mapped to this seven-point spectrum which allows us to:\n729\n1.", 
        "19": "Uncover the differences in language use between ideological groups; 2.", 
        "20": "Develop a user-level political ideology prediction algorithm that classifies all levels of engagement and leverages the structure in the political ideology spectrum.", 
        "21": "First, using a broad range of language features\nincluding unigrams, word clusters and emotions, we study the linguistic differences between the two ideologically extreme groups, the two ideologically moderate groups and between both extremes and moderates in order to provide insight into the content they post on Twitter.", 
        "22": "In addition, we examine the extent to which the ideological groups in our data set post about politics and compare it to a data set obtained similarly to previous work.", 
        "23": "In prediction experiments, we show how accurately we can distinguish between opposing ideological groups in various scenarios and that previous binary political orientation prediction has been oversimplified.", 
        "24": "Then, we measure the extent to which we can predict the two dimensions of political leaning and engagement.", 
        "25": "Finally, we build an ideology classifier in a multi-task learning setup that leverages the relationships between groups.1  2 Related Work  Automatically inferring user traits from their online footprints is a prolific topic of research, enabled by the increasing availability of user generated data and advances in machine learning.", 
        "26": "Beyond its research oriented goals, user profiling has important industry applications in online marketing, personalization or large-scale audience profiling.", 
        "27": "To this end, researchers have used a wide range of types of online footprints, including video (Subramanian et al., 2013), audio (Alam and Riccardi, 2014), text (Preot\u0327iuc-Pietro et al., 2015a), profile images (Liu et al., 2016a), social data (Van Der Heide et al., 2012; Hall et al., 2014), social networks (Perozzi and Skiena, 2015; Rout et al., 2013), payment data (Wang et al., 2016) and endorsements (Kosinski et al., 2013).", 
        "28": "Political orientation prediction has been studied in two related, albeit crucially different scenarios, as also identified in (Zafar et al., 2016).", 
        "29": "First, researchers aimed to identify and quantify orientation of words (Monroe et al., 2008), hashtags (Weber et al., 2013) or documents (Iyyer et al., 2014),\n1Data is available at http://www.preotiuc.ro\nor to detect bias (Yano et al., 2010) or impartiality (Zafar et al., 2016) at a document level.", 
        "30": "Our study belongs to the second category, where political orientation is inferred at a user-level.", 
        "31": "All previous studies study labeling US conservatives vs. liberals using either text (Rao et al., 2010), social network connections (Zamal et al., 2012), platform-specific features (Conover et al., 2011) or a combination of these (Pennacchiotti and Popescu, 2011; Volkova et al., 2014), with very high reported accuracies of up to 94.9% (Conover et al., 2011).", 
        "32": "However, all previous work on predicting userlevel political preferences are limited to a binary prediction between liberal/democrat and conservative/republican, disregarding any nuances in political ideology.", 
        "33": "In addition, as the focus of the studies is more on the methodological or interpretation aspects of the problem, another downside is that the user labels were obtained in simple, albeit biased ways.", 
        "34": "These include users who explicitly state their political orientation on user lists of party supporters (Zamal et al., 2012; Pennacchiotti and Popescu, 2011), supporting partisan causes (Rao et al., 2010), by following political figures (Volkova et al., 2014) or party accounts (Sylwester and Purver, 2015) or that retweet partisan hashtags (Conover et al., 2011).", 
        "35": "As also identified in (Cohen and Ruths, 2013) and further confirmed later in this study, these data sets are biased: most people do not clearly state their political preference online \u2013 fewer than 5% according to Priante et al.", 
        "36": "(2016) \u2013 and those that state their preference are very likely to be political activists.", 
        "37": "Cohen and Ruths (2013) demonstrated that predictive accuracy of classifiers is significantly lower when confronted with users that do not explicitly mention their political orientation.", 
        "38": "Despite this, their study is limited because in their hardest classification task, they use crowdsourced political orientation labels, which may not correspond to reality and suffer from biases (Flekova et al., 2016a; Carpenter et al., 2016).", 
        "39": "Further, they still only look at predicting binary political orientation.", 
        "40": "To date, no other research on this topic has taken into account these findings.", 
        "41": "3 Data Set  The main data set used in this study consists of 3,938 users recruited through the Qualtrics platform (D1).", 
        "42": "Each participant was compensated\nwith 3 USD for 15 minutes of their time.", 
        "43": "All participants first answered the same demographic questions (including political ideology), then were directed to one of four sets of psychological questionnaires unrelated to the political ideology question.", 
        "44": "They were asked to self-report their political ideology on a seven point scale: Very conservative (1), Conservative (2), Moderately conservative (3), Moderate (4), Moderately liberal (5), Liberal (6), Very liberal (7).", 
        "45": "In addition, participants had the option of choosing Apathetic and Other, which have ambiguous fits on the conservative \u2013 liberal spectrum and were removed from our analysis (399 users).", 
        "46": "We also asked participants to self-report their gender (2322 female, 1205 male, 12 other) and age.", 
        "47": "Participants were all from the US in order to limit the impact of cultural and political factors.", 
        "48": "The political ideology distribution in our sample is presented in Figure 1.", 
        "49": "We asked users their Twitter handle and downloaded their most recent 3,200 tweets, leading to a total of 4,833,133 tweets.", 
        "50": "Before adding users to our 3,938 user data set, we performed the following checks to ensure that the Twitter handle was the user\u2019s own: 1) after compensation, users were if they were truthful in reporting their handle and if not, we removed their data from analysis; 2) we manually examined all handles marked as verified by Twitter or that had over 2000 followers and eliminated them if they were celebrities or corporate/news accounts, as these were unlikely the users who participated in the survey.", 
        "51": "This study received approval from the Institutional Review Board (IRB) of the University of Pennsylvania.", 
        "52": "In addition, to facilitate comparison to previous work, we also use a data set of 13,651 users with overt political orientation (D2).", 
        "53": "We selected popular political figures unambiguously associated with US liberal politics (@SenSanders,\n@JoeBiden, @CoryBooker, @JohnKerry) or US conservative politics (@marcorubio, @tedcruz, @RandPaul, @RealBenCarson).", 
        "54": "Liberals in our set (Nl = 7417) had to follow on Twitter all of the liberal political figures and none of the conservative figures.", 
        "55": "Likewise, conservative users (Nc = 6234) had to follow all of the conservative figures and no liberal figures.", 
        "56": "We downloaded up to 3,200 of each user\u2019s most recent tweets, leading to a total of 25,493,407 tweets.", 
        "57": "All tweets were downloaded around 10 August 2016.", 
        "58": "4 Features  In our analysis, we use a broad range of linguistic features described below.", 
        "59": "Unigrams We use the bag-of-words representation to reduce each user\u2019s posting history to a normalised frequency distribution over the vocabulary consisting of all words used by at least 10% of the users (6,060 words).", 
        "60": "LIWC Traditional psychological studies use a dictionary-based approach to representing text.", 
        "61": "The most popular method is based on Linguistic Inquiry and Word Count (LIWC) (Pennebaker et al., 2001), and automatically counts word frequencies for 64 different categories manually constructed based on psychological theory.", 
        "62": "These include different parts-of-speech, topical categories and emotions.", 
        "63": "Each user is thereby represented as a frequency distribution over these categories.", 
        "64": "Word2Vec Topics An alternative to LIWC is to use automatically generated word clusters i.e., groups of words that are semantically and/or syntactically similar.", 
        "65": "The clusters help reducing the feature space and provides additional interpretability.", 
        "66": "To create these groups of words, we use an automatic method that leverages word co-occurrence patterns in large corpora by making use of the distributional hypothesis: similar words tend to cooccur in similar contexts (Harris, 1954).", 
        "67": "Based on co-occurrence statistics, each word is represented as a low dimensional vector of numbers with words closer in this space being more similar (Deerwester et al., 1990).", 
        "68": "We use the method from (Preot\u0327iuc-Pietro et al., 2015a) to compute topics using word2vec similarity (Mikolov et al., 2013a,b) and spectral clustering (Shi and Malik, 2000; von Luxburg, 2007) of different sizes (from 30 to 2000).", 
        "69": "We have tried other alternatives to building clusters: using other word similarities to\ngenerate clusters \u2013 such as NPMI (Lampos et al., 2014) or GloVe (Pennington et al., 2014) as proposed in (Preot\u0327iuc-Pietro et al., 2015a) \u2013 or using standard topic modelling approached to create soft clusters of words e.g., Latent Dirichlet Allocation (Blei et al., 2003).", 
        "70": "For brevity, we present experiments with the best performing feature set containing 500 Word2Vec clusters.", 
        "71": "We aggregate all the words posted in a users\u2019 tweets and represent each user as a distribution of the fraction of words belonging to each cluster.", 
        "72": "Sentiment & Emotions We hypothesise that different political ideologies differ in the type and amount of emotions the users express through their posts.", 
        "73": "The most studied model of discrete emotions is the Ekman model (Ekman, 1992; Strapparava and Mihalcea, 2008; Strapparava et al., 2004) which posits the existence of six basic emotions: anger, disgust, fear, joy, sadness and surprise.", 
        "74": "We automatically quantify these emotions from our Twitter data set using a publicly available crowd-sourcing derived lexicon of words associated with any of the six emotions, as well as general positive and negative sentiment (Mohammad and Turney, 2010, 2013).", 
        "75": "Using these lexicons, we assign a predicted emotion to each message and then average across all users\u2019 posts to obtain user level emotion expression scores.", 
        "76": "Political Terms In order to select unigrams pertaining to politics, we assigned the most frequent 12,000 unigrams in our data set to three categories: \u2022 Political words: mentions of political terms\n(234); \u2022 Political NEs: mentions of politician proper\nnames out of the political terms (39); \u2022 Media NEs: mentions of political media\nsources and pundits out of the political terms (20).", 
        "77": "This coding was initially performed by a research assistant studying political science with good knowledge of US politics and were further filtered and checked by one of the authors.", 
        "78": "5 Analysis  First, we explore the relationships between language use and political ideological groups within each feature set and pairs of opposing user groups.", 
        "79": "To illustrate differences between ideological groups we compare the two political extremes (Very Conservative \u2013 Very Liberal) and the political moderates (Moderate Conservative \u2013 Moderate\nLiberal).", 
        "80": "We further compare outright moderates with a group combining the two political extremes to study if we can uncover differences in political engagement and extremity, regardless of the conservative\u2013liberal leaning.", 
        "81": "We use univariate partial linear correlations with age and gender as co-variates to factor out the influence of basic demographics.", 
        "82": "For example, in D1, users who reported themselves as very conservative are older and more likely males (\u00b5age = 35.1, pctmale = 44%) than the data average (\u00b5age = 31.2, pctmale = 35%).", 
        "83": "Additionally, prior to combining the two ideologically extreme groups, we sub-sampled the larger class (Very Liberal) to match the smaller class (Very Conservative) in age and gender.", 
        "84": "In the later prediction experiments, we do not perform matching, as this represents useful signal for classification (Ellis and Stimson, 2012).", 
        "85": "Results with unigrams are presented in Figure 2 and with the other features in Table 1.", 
        "86": "These are selected using standard statistical significance tests.", 
        "87": "5.1 Very Conservatives vs.", 
        "88": "Very Liberals  The comparison between the extreme categories reveals the largest number of significant differences.", 
        "89": "The unigrams and Word2Vec clusters specific to conservatives are dominated by religion specific terms (\u2018praying\u2019, \u2018god\u2019, W2V485, W2V-018, W2V-099, L-RELIG), confirming a well-documented relationship (Gelman, 2009) and words describing family relationships (\u2018uncle\u2019, \u2018son\u2019, L-FAMILY), another conservative value (Lakoff, 1997).", 
        "90": "The emphasis on religious terms among conservatives is consistent with the claim that many Americans associate \u2018conservative\u2019 with \u2018religious\u2019 (Ellis and Stimson, 2012).", 
        "91": "Extreme liberals show a tendency to use more adjectives (W2V-075, W2V-110), adverbs (L-ADVERB), conjunctions (L-CONJ) and comparisons (L-COMPARE) which indicate more nuanced and complex posts.", 
        "92": "Extreme conservatives post tweets higher in all positive emotions than liberals (L-POSEMO, Emot-Joy, EmotPositive), confirming a previously hypothesised relationship (Napier and Jost, 2008).", 
        "93": "However, extreme liberals are not associated with posting negative emotions either, only using words that reflect more anxiety (L-ANX), which is related to neuroticism in which the liberals are higher (Gerber et al., 2010).", 
        "94": "Political term analysis reveals the partisan terms\nemployed by both sides.", 
        "95": "For example, conservatives retweet or mention politicians such as Donald Trump or Ted Cruz, while liberals mention\nBarack Obama.", 
        "96": "Extreme conservatives also reference known partisan conservative media sources (@foxnews, @yahoonews) and hashtags (#pjnet,\n#tcot), while extreme liberals focus on issues (\u2018gay\u2019, \u2018racism\u2019, \u2018feminism\u2019, \u2018transgender\u2019).", 
        "97": "This perhaps reflects the desire for conservatives on Twitter to identify like-minded individuals, as extreme conservatives are a minority on the platform.", 
        "98": "Liberals, by contrast, use the platform to discuss and popularize their causes.", 
        "99": "5.2 Moderate Conservatives vs.", 
        "100": "Moderate Liberals  Comparing the two sides of moderate users reveals a slightly more nuanced view of the two ideologies.", 
        "101": "While moderate conservatives still make heavy use of religious terms and express positive emotions (Emot-Joy, L-DRIVES), they also use affiliative language (L-AFFILIATION) and plural pronouns (L-WE).", 
        "102": "Moderate liberals are identified by very different features compared to their more extreme counterparts.", 
        "103": "Most striking is the use of swear and sex words (L-SEXUAL, L-ANGER, W2V-316), also highlighted by Sylwester and Purver (2015).", 
        "104": "Two word clusters relating to British culture (W2V-458) and art (W2V373) reflect that liberals are more inclined towards arts (Dollinger, 2007).", 
        "105": "Statistically significant political terms are very few compared to the previous comparison, probably due to their lower overall usage, which we further investigate later.", 
        "106": "5.3 Moderates vs. Extremists  Our final comparison looks at outright moderates compared to the two extreme groups combined, as we hypothesise the existence of a difference in overall political engagement.", 
        "107": "Moderates are not characterized by many features besides a topic of casual words (W2V-098), indicating the heterogeneity of this group of users.", 
        "108": "However, regardless of their orientation, the ideological extremists stand out from moderates.", 
        "109": "They use words and word clusters related to political actors (W2V-309), issues (W2V-237) and laws (W2V296, W2V-288).", 
        "110": "LIWC analysis uncovers differences in article use (L-ARTICLE) or power words (L-POWER) specific of political tweets.", 
        "111": "The overall sentiment of these users is negative (Emot-Fear, Emot-Disgust, Emot-Sadness, L-DEATH) compared to moderates.", 
        "112": "This reveals \u2013 combined with the finding from the first comparison \u2013 that while extreme conservatives are overall more positive than liberals, both groups share negative expression.", 
        "113": "Political terms are almost all significantly correlated with the extreme ideological groups,\nconfirming the existence of a difference in political engagement which we study in detail next.", 
        "114": "5.4 Political Terms  Figure 3 presents the use of the three types of political terms across the 7 ideological groups in D1 and the two political groups from D2.", 
        "115": "We notice the following: \u2022 D2 has a huge skew towards political words,\nwith an average of more than three times more political terms across all three categories than our extreme classes from D1; \u2022 Within the groups in D1, we observe an almost\nperfectly symmetrical U-shape across all three types of political terms, confirming our hypothesis about political engagement; \u2022 The difference between 1\u20132/6\u20137 is larger than\n2\u20133/5\u20136.", 
        "116": "The extreme liberals and conservatives are disproportionately political, and have the potential to give Twitter\u2019s political discussions an unrepresentative, extremist hue (Fiorina, 1999).", 
        "117": "It is also possible, however, that characterizing one as an extreme liberal or conservative indicates as much about her level of political engagement as it does about her placement on a left-right scale (Converse, 1964; Broockman, 2016).", 
        "118": "6 Prediction  In this section we build predictive models of political ideology and compare them to data sets obtained using previous work.", 
        "119": "6.1 Cross-Group Prediction  First, we experiment with classifying between conservatives and liberals across various levels of political engagement in D1 and between the two polarized groups in D2.", 
        "120": "We use logistic regression classification to compare three setups in Table 2 with results measured with ROC AUC as the classes are slightly inbalanced: \u2022 10-fold cross-validation where training is per-\nformed on the same task as the testing (principal diagonal); \u2022 A train\u2013test setup where training is performed\non one task (presented in rows) and testing is performed on another (presented in columns); \u2022 A domain adaptation setup (results in brack-\nets) where on each of the 10 folds, the 9 training folds (presented in rows) are supplemented with all the data from a different task (presented in columns) using the EasyAdapt algorithm (Daume\u0301 III, 2007) as a proof on concept on the effects of using additional distantly supervised data.", 
        "121": "Data pooling lead to worse results than EasyAdapt.", 
        "122": "Each of the three tasks from D1 have a similar number of training samples, hence we do not expect that data set size has any effects in comparing the results across tasks.", 
        "123": "The results with both sets of features show that: \u2022 Prediction performance is much higher for D2\nthan for D1, with the more extreme groups in D1 being easier to predict than the moderate groups.", 
        "124": "This confirms that the very high accuracies reported by previous research are an artifact of user label collection and that on regular users, the expected accuracy is much lower (Cohen and Ruths, 2013).", 
        "125": "We further show that, as the level of political engagement decreases, the classification problem becomes even harder; \u2022 The model trained on D2 and Word2Vec word\nclusters performs significantly worse on D1 tasks even if the training data is over 10 times larger.", 
        "126": "When using political words, the D2 trained classifier performs relatively well on all tasks from D1; \u2022 Overall, using political words as features per-\nforms better than Word2Vec clusters in the binary classification tasks; \u2022 Domain adaptation helps in the majority of\ncases, leading to improvements of up to .03 in AUC (predicting 2v6 supplemented with 3v5 data).", 
        "127": "6.2 Political Leaning and Engagement Prediction  Political leaning (Conservative \u2013 Liberal, excluding the Moderate group) can be considered an ordinal variable and the prediction problem framed as one of regression.", 
        "128": "In addition to the political leaning prediction, based on analysis and previous prediction results, we hypothesize the existence of a separate dimension of political engagement regardless of the partisan side.", 
        "129": "Thus, we merge users from classes 3\u20135, 2\u20136, 1\u20137 and create a variable with four values, where the lowest value is represented by moderate users (4) and the highest value is represented by either very conservative (1) or very liberal (7) users.", 
        "130": "We use a linear regression algorithm with an Elastic Net regularizer (Zou and Hastie, 2005) as implemented in ScikitLearn (Pedregosa et al., 2011).", 
        "131": "To evaluate our results, we split our data into 10 stratified folds and performed crossvalidation on one held-out fold at a time.", 
        "132": "For all our methods we tune the parameters of our models on a separate validation fold.", 
        "133": "The overall performance is assessed using Pearson correlation between the set of predicted values and the userreported score.", 
        "134": "Results are presented in Table 3.", 
        "135": "The same patterns hold when evaluating the results with Root Mean Squared Error (RMSE).", 
        "136": "The results show that both dimensions can be predicted well above chance, with political leaning being easier to predict than engagement.", 
        "137": "Word2Vec clusters obtain the highest predictive accuracy for political leaning, even though they did not perform as well in the previous classification tasks.", 
        "138": "For political engagement, political terms and Word2Vec clusters obtain similar predictive accuracy.", 
        "139": "This result is expected based on the results from Figure 3, which showed how political term usage varies across groups, and how it is especially dependent on political engagement.", 
        "140": "While political terms are very effective at distinguishing between two opposing political groups, they can not discriminate as well between levels of engagement within the same ideological orientation.", 
        "141": "Combining all classifiers\u2019 predictions in a linear ensemble obtains best results when compared to each individual category.", 
        "142": "6.3 Encoding Class Structure  In our previous experiments, we uncovered that certain relationships exist between the seven groups.", 
        "143": "For example, extreme conservatives and liberals both demonstrate strong political engagement.", 
        "144": "Therefore, this class structure can be exploited to improve classification performance.", 
        "145": "To this end, we deploy the sparse graph regularized approach (Argyriou et al., 2007; Zhou et al., 2011) to encode the structure of the seven classes as a graph regularizer in a logistic regression framework.", 
        "146": "In particular, we employed a multi-task learning paradigm, where each task is a one-vs-all classification.", 
        "147": "Multi-task learning (MTL) is a learning paradigm that jointly learns multiple related\ntasks and can achieve better generalization performance than learning each task individually, especially when presented with insufficient training samples (Liu et al., 2015, 2016b,d).", 
        "148": "The group structure is encoded into a matrix R which codes the groups which are considered similar.", 
        "149": "The objective of the sparse graph regularized multi-task learning problem is:\nmin W,c\n\u03c4\u2211\nt=1\nN\u2211\ni=1\nlog(1 + exp(\u2212Yt,i(WTi,tXt,i + ct)))\n+ \u03b3\u2016WR\u20162F + \u03bb\u2016W\u20161,\nwhere \u03c4 is the number of tasks, |N | the number of samples, X the feature matrix, Y the outcome matrix, Wi,t and ct is the model for task t and R is the structure matrix.", 
        "150": "We define three R matrices: (1) codes that groups with similar political engagement are similar (i.e.", 
        "151": "1\u20137, 2\u20136, 3\u20135); (2) codes that groups from each ideological side are similar (i.e.", 
        "152": "1\u20132, 1\u20133, 2\u20133, 5\u20136, 5\u20137, 6\u20137); (3) learnt from the data.", 
        "153": "Results are presented in Table 4.", 
        "154": "Regular logistic regression performs slightly better than the majority class baseline, which demonstrates that the 7- class classification is a very hard problem although most miss-classifications are within one ideology point.", 
        "155": "The graph regularization (GR) improves the classification performance over logistic regression (LR) in all cases, with political leaning based matrix (GR\u2013Leaning) obtaining 2% in accuracy higher than the political engagement one (GR\u2013 Engagement) and the learnt matrix (GR\u2013Learnt) obtaining best results.", 
        "156": "7 Conclusions  This study analyzed user-level political ideology through Twitter posts.", 
        "157": "In contrast to previous work, we made use of a novel data set where finegrained user political ideology labels are obtained through surveys as opposed to binary self-reports.", 
        "158": "We showed that users in our data set are far less\nlikely to post about politics and real-world finegrained political ideology prediction is harder and more nuanced than previously reported.", 
        "159": "We analyzed language differences between the ideological groups and uncovered a dimension of political engagement separate from political leaning.", 
        "160": "Our work has implications for pollsters or marketers, who are most interested to identify and persuade moderate users.", 
        "161": "With respect to political conclusions, researchers commonly conceptualize ideology as a single, left-right dimension similar to what we observe in the U.S. Congress (Ansolabehere et al., 2008; Bafumi and Herron, 2010).", 
        "162": "Our results suggest a different direction: self-reported political extremity is more an indication of political engagement than of ideological self-placement (Abramowitz, 2010).", 
        "163": "In fact, only self-reported extremists appear to devote much of their Twitter activity to politics at all.", 
        "164": "While our study focused solely on text posted by the user, follow-up work can use other modalities such as images or social network analysis to improve prediction performance.", 
        "165": "In addition, our work on user-level modeling can be integrated with work on message-level political bias to study how this is revealed across users with various levels of engagement.", 
        "166": "Another direction of future study will look at political ideology prediction in other countries and cultures, where ideology has different or multiple dimensions.", 
        "167": "Acknowledgments  The authors acknowledge the support of the Templeton Religion Trust, grant TRT-0048.", 
        "168": "We wish to thank Prof. David S. Rosenblum for supporting the research visit of Ye Liu."
    }, 
    "document_id": "P17-1068.pdf.json"
}
