{
    "abstract_sentences": {
        "1": "Word-level language detection is necessary for analyzing code-switched text, where multiple languages could be mixed within a sentence.", 
        "2": "Existing models are restricted to code-switching between two specific languages and fail in real-world scenarios as text input rarely has a priori information on the languages used.", 
        "3": "We present a novel unsupervised word-level language detection technique for codeswitched text for an arbitrarily large number of languages, which does not require any manually annotated training data.", 
        "4": "Our experiments with tweets in seven languages show a 74% relative error reduction in word-level labeling with respect to competitive baselines.", 
        "5": "We then use this system to conduct a large-scale quantitative analysis of code-switching patterns on Twitter, both global as well as regionspecific, with 58M tweets."
    }, 
    "body_sentences": {
        "1": "  Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 1971\u20131982 Vancouver, Canada, July 30 - August 4, 2017. c\u00a92017 Association for Computational Linguistics\nhttps://doi.org/10.18653/v1/P17-1180  1 Introduction  In stable multilingual societies, communication often features fluid alteration between two or more languages \u2013 a phenomenon known as code-switching1 (Gumperz, 1982; Myers-Scotton, 1993).", 
        "2": "It has been studied extensively in linguistics, primarily as a speech phenomenon (Poplack, 1980; Gumperz, 1982; Myers-Scotton, 1993; Milroy and Muysken, 1995; Auer, 2013).", 
        "3": "However, the growing popularity of computer mediated\n\u2217* This work was done when the authors were affiliated with Microsoft Research.", 
        "4": "1This paper uses the terms \u2018code-switching\u2019 and \u2018codemixing\u2019 interchangeably.", 
        "5": "communication, particularly social media, has resulted in language data in the text form which exhibits code-switching, among other speechlike characteristics (Crystal, 2001; Herring, 2003; Danet and Herring, 2007; Cardenas-Claros and Isharyanti, 2009).", 
        "6": "With the large amount of online content generated by multilingual users around the globe, it becomes necessary to design techniques to analyze mixed language, which can help not only in developing end-user applications, but also in conducting fundamental sociolinguistic studies.", 
        "7": "Language detection (LD) is a prerequisite to several NLP techniques.", 
        "8": "Most state-of-the-art LD systems detect a single language for an entire document or sentence.", 
        "9": "Such methods often fail to detect code-switching, which can occur within a sentence.", 
        "10": "In recent times, there has been some effort to build word-level LD for code-switching between a specific pair of languages (Nguyen and Dogruo\u0308z, 2013; Elfardy et al., 2013; Solorio et al., 2014; Barman et al., 2014).", 
        "11": "However, usually user-generated text (e.g., on social media) has no prior information of the languages being used.", 
        "12": "Further, as several previous social-media based studies on multilingualism have pointed out (Kim et al., 2014; Manley, 2012), lack of general wordlevel LD has been a bottleneck in studying codeswitching patterns in multilingual societies.", 
        "13": "This paper proposes a novel technique for wordlevel LD that generalizes to an arbitrarily large set of languages.", 
        "14": "The method does not require a priori information on the specific languages (potentially more than two) being mixed in an input text as long as the languages are from a fixed (arbitrarily large) set.", 
        "15": "Training is done without any manually annotated data, while achieving accuracies comparable to language-restricted systems trained\n1971\nwith large amounts of labeled data.", 
        "16": "With a wordlevel LD accuracy of 96.3% on seven languages, this technique enabled us to analyze patterns of code-switching on Twitter, which is the second key contribution of this paper.", 
        "17": "To the best of our knowledge, this is the first quantitative study of its kind, particularly at such a large-scale.", 
        "18": "2 Related Work  In this section, we will briefly survey the language detection techniques (see Hughes et al.", 
        "19": "(2006) and Garg et al.", 
        "20": "(2014) for comprehensive surveys), and sociolinguistic studies on multilingualism (see Nguyen et al.", 
        "21": "(2016) for a detailed survey) that were enabled by these techniques.", 
        "22": "Early work on LD (Cavnar and Trenkle, 1994; Dunning, 1994) focused on detecting a single language for an entire document.", 
        "23": "These obtained high accuracies on well-formed text (e.g., news articles), which led to LD being considered solved (McNamee, 2005).", 
        "24": "However, there has been renewed interest with the amount of user-generated content on the web.", 
        "25": "Such text poses unique challenges such as short length, misspelling, idiomatic expressions and acronyms (Carter et al., 2013; Goldszmidt et al., 2013).", 
        "26": "Xia et al.", 
        "27": "(2009), Tromp and Pechenizkiy (2011) and Lui and Baldwin (2012) created LD systems for monolingual sentences, web pages and tweets.", 
        "28": "Zhang et al.", 
        "29": "(2016) built an unsupervised model to detect the majority language in a document.", 
        "30": "There has also been document-level LD that assigns multiple language to each document (Prager, 1999; Lui et al., 2014).", 
        "31": "However, documents were synthetically generated, restricted to inter-sentential language mixing.", 
        "32": "Also, these models do not fragment the document based on language, making language-specific analysis impossible.", 
        "33": "Document-level or sentence-level LD does not identify code-switching accurately, which can occur within a sentence.", 
        "34": "Word-level LD systems attempt to remedy this problem.", 
        "35": "Most work has been restricted to cases where two languages, known a priori, is to be detected in the input i.e, binary LD at the word-level.", 
        "36": "There has been work on Dutch-Turkish (Nguyen and Dogruo\u0308z, 2013), English-Bengali (Das and Gamba\u0308ck, 2014) and Standard and dialectal Arabic (Elfardy et al., 2013).", 
        "37": "King and Abney (2013) address wordlevel LD for bilingual documents in 30 language pairs, where the language pair is known a pri-\nori.", 
        "38": "The features for word-level LD proposed by Al-Badrashiny and Diab (2016) are languageindependent, however, at any given time, the model is only trained to tag a specific language pair.", 
        "39": "There have also been two shared task series on word-level LD: FIRE (Roy et al., 2013; Choudhury et al., 2014; Sequiera et al., 2015) focused on Indian languages and the EMNLP CodeSwitching Workshop (Solorio et al., 2014; Molina et al., 2016).", 
        "40": "These pairwise LD methods vary from dictionary-based to completely supervised and semi-supervised.", 
        "41": "None tackle the imminent lack of annotated data required for scaling to more than one language pair.", 
        "42": "There has been little research on word-level LD that is not restricted to two languages.", 
        "43": "Hammarstro\u0308m (2007) proposed a model for multilingual LD for short texts like queries.", 
        "44": "Gella et al.", 
        "45": "(2014) designed an algorithm for wordlevel LD across 28 languages.", 
        "46": "Jurgens et al.", 
        "47": "(2017) use an encoder-decoder architecture for word-level LD that supports dialectal variation and code-switching.", 
        "48": "However, these studies experiment with synthetically created multilingual data, constrained either by the number of language switches permitted or to phrase-level codeswitching, and are not equipped to handle the challenges posed by real-world code-switching.", 
        "49": "Using tweet-level LD systems like the CompactLanguageDetector2, there have been studies on multilingualism in specific cities like London (Manley, 2012) and Manchester (Bailey et al., 2013).", 
        "50": "These studies, as well as Bergsma et al.", 
        "51": "(2012), observe that existing LD systems fail on code-switched text.", 
        "52": "Kim et al.", 
        "53": "(2014) studied the linguistic behavior of bilingual Twitter users from Qatar, Switzerland and Que\u0301bec, and also acknowledge that code-switching could not be studied due to the absence of appropriate LD tools.", 
        "54": "Using word-level LD for English-Hindi (Gella et al., 2013), Bali et al.", 
        "55": "2014 observed that as much as 17% of Indian Facebook posts had codeswitching, and Rudra et al.", 
        "56": "(2016) showed that the native language is strongly preferred for expressing negative sentiment by English-Hindi bilinguals on Twitter.", 
        "57": "However, without accurate multilingual word-level LD, there have been no largescale studies on the extent and distribution of code-switching across various communities.", 
        "58": "2https://www.npmjs.com/package/cld  3 Generalized Word-level LD  We present Generalized Word-Level Language Detection, or GWLD, where:\n\u2022 The number of supported languages can be arbitrarily large\n\u2022 Any number of the supported languages can be mixed within a single input\n\u2022 The languages in the input do not need to be known a priori\n\u2022 Any number of language switches are allowed in the input.", 
        "59": "\u2022 No manual annotation is required for training\nFormalizing our model, let w = wi=1...n be a natural language text consisting of a sequence of words, w1 to wn.", 
        "60": "For our current work, we define words to be whitespace-separated tokens (details in Sec 5).", 
        "61": "Let L = {l1, l2, .", 
        "62": ".", 
        "63": ".", 
        "64": ", lk} be a set of k natural languages.", 
        "65": "We assume that each wi can be assigned to a unique language lj \u2208 L.\nWe also define universal tokens like numbers, emoticons, URLs, emails and punctuation, which do not belong to any specific natural language.", 
        "66": "Certain strings of alphabetic characters representing generic interjections or sounds, such as oh, awww, zzz also fall in this category.", 
        "67": "For labeling these tokens, we use an auxiliary set of labels, XL = {xl1, xl2, .", 
        "68": ".", 
        "69": ".", 
        "70": ", xlk}.", 
        "71": "Labeling each universal token with a specific language li (using xli) instead of generically labeling all such tokens xl allows preserving linguistic context when a memoryless model like Hidden Markov Models (HMM) are used for tagging.", 
        "72": "Further, various NLP tasks on might require the input text, including these universal tokens, to be split by language.", 
        "73": "For input w, let the output from the LD system be y = yi=1...n, a sequence of labels, where yi \u2208 L \u222a XL.", 
        "74": "yi = lj if and only if, in the context of w, wi is a word from lj .", 
        "75": "If wi is a universal token, yi = xlj , when yi\u22121 = lj or yi\u22121 = xlj .", 
        "76": "If w1 is a universal token, y1 = xlj , where lj is the label of the first token \u2208 L in the input.", 
        "77": "Fig.", 
        "78": "1 shows a few examples of labeled codeswitched tweets.", 
        "79": "Named entities (NE) are assigned labels according to the convention used by King and Abney (2013).", 
        "80": "4 Method  Word-level LD is essentially a sequence labeling task.", 
        "81": "We use a Hidden Markov Model (HMM),\nthough any other sequence labeling technique, e.g., CRFs, can be used as well.", 
        "82": "The intuition behind the model architecture is simple \u2013 a person who is familiar with k languages can easily recognize (and also understand) the words when any of those languages are codeswitched, even if s/he has never seen any mixed language text before.", 
        "83": "Analogously, is it possible that monolingual language models, when combined, can identify code-switched text accurately?", 
        "84": "Imagine we have k HMMs, where the ith HMM has two states li and xli.", 
        "85": "Each state can label a word.", 
        "86": "The HMMs are independent, but they are tied to a common start state s and end state e, forming a word-level LD model for monolingual text in one of the k languages.", 
        "87": "Now, we make transitions from li \u2192 lj possible, where i 6= j.", 
        "88": "This HMM, shown in Fig.", 
        "89": "2, is capable of generating and consequently, labeling code-switched text between any of the k languages.", 
        "90": "The solid and dotted lines show monolingual transitions and the added code-switching transitions respectively.", 
        "91": "Fig.", 
        "92": "2 depicts three languages, however, the number of languages can be arbitrarily large.", 
        "93": "Obtaining word-level annotated monolingual and code-switched data is expensive and nearly infeasible for a large number of languages.", 
        "94": "Instead, we automatically create weakly-labeled monolingual text (setW) and use it to initialize the HMM parameters.", 
        "95": "We then use Baum-Welch reestimation on unlabeled data (set U) that has monolingual and code-switched text in their natural distribution.", 
        "96": "Sec.", 
        "97": "5 discusses creation ofW and U .", 
        "98": "4.1 Structure, Initialization and Learning  The structure of the HMM shown in Fig.", 
        "99": "2 can be formally described using:\n\u2022 Set of states, S = s \u222a L \u222a XL \u222a e \u2022 Set of observations, O \u2022 Emission matrix (|S| \u00d7 |O|) \u2022 Transition matrix (|S| \u00d7 |S|)\nO consists of all seen events in the data, and a special symbol unk for all unseen events.", 
        "100": "We define an event as a token n-gram and we experimented with n = 1 to 3.", 
        "101": "It is important to mention that the n-grams do not spread over language states.", 
        "102": "We also use special start and end symbols, which are observed at states s and e respectively.", 
        "103": "Elements of O are effectively what the states of the HMM \u2018emit\u2019 or generate during decoding.", 
        "104": "For any input, the HMM always starts in the state s. The parameters to be learned are the transition and emission matrices.", 
        "105": "We initialize these matrices using W .", 
        "106": "The trigram, bigram and unigram word counts from the data for each language in W are used to create language models (LM) with modified Kneser-Ney smoothing (Chen and Goodman, 1999).", 
        "107": "The emission values for state li are initialized with the respective LM probabilities for all seen n-grams.", 
        "108": "We also assign a small probability to unk.", 
        "109": "The emissions for the xli state are initialized using the counts of universal tokens for the language li in W .", 
        "110": "These are identified using the preprocessing techniques discussed in Sec.", 
        "111": "5.1.", 
        "112": "Possible transitions for each monolingual HMM are li \u2192 li, li \u2192 xli and xli \u2192 li.", 
        "113": "We do not have the xli \u2192 xli transition, because preprocessing (Sec.", 
        "114": "5.1) concatenates successive universal tokens into a single token.", 
        "115": "This does not change the output as the tokens can easily be separated after LD, but is a useful simplification for the model.", 
        "116": "The transition values for li are initialized by the probability of transitions between words and universal tokens in the text fromW .", 
        "117": "As stated earlier, the model supports codeswitching by the addition of transitions li \u2192 lj , and xli \u2192 lj , for all i 6= j.", 
        "118": "For each state li, there are 2k \u2212 2 new transitions (Fig.", 
        "119": "2).", 
        "120": "We initialize these news edges with a small probability \u03c0, before normalizing transitions for each state.", 
        "121": "\u03c0, which we call the code-switch probability, is a hyperparameter tuned on a validation set.", 
        "122": "Starting with the initialized matrices, we reestimate the transition and emission matrices using the EM-like Baum-Welch algorithm (Welch, 2003) over the large set of unlabeled text U .", 
        "123": "4.2 Decoding  The input to the trained model is first preprocessed as described in Sec.", 
        "124": "5.1 (tokenization and identification of universal tokens).", 
        "125": "The Viterbi algorithm is then used with the HMM parameters to perform word-level LD.", 
        "126": "When an unknown n-gram, is encountered, its emission probability is estimated by recursively backing off to (n \u2212 1)-gram, until we find a known n-gram.", 
        "127": "If the unigram, i.e., the token, is also unknown, then the observation of the symbol unk is used instead.", 
        "128": "5 Dataset Creation  The data for both training and testing comes primarily from Twitter because of its public API, and studies have shown the presence of codeswitching in social media (Crystal, 2001; Herring, 2003; Danet and Herring, 2007; Cardenas-Claros and Isharyanti, 2009; Bali et al., 2014).", 
        "129": "Our experiments use monolingual and codeswitched tweets in seven languages \u2013 Dutch (nl), English (en), French (fr), German (de), Portuguese (pt), Spanish (es) and Turkish (tr).", 
        "130": "These form the set L. The choice of languages is motivated by several factors.", 
        "131": "First, LD is non-trivial as all these languages use the Latin script.", 
        "132": "Second, a large volume of tweets are generated in these languages.", 
        "133": "Third, there is annotated code-switched data available in nl-tr and en-es, which can be used for validation and testing.", 
        "134": "Lastly, we know that certain pairs of these languages are code-switched often.", 
        "135": "5.1 Collection and Preprocessing  Using the Twitter API (Twitter, 2013), we collected tweets over May-July 2015.", 
        "136": "We selected tweets identified by Twitter LD API (Twitter, 2015) as one of the languages in L. We also removed non-Latin script tweets.", 
        "137": "As preprocessing, each tweet is first tokenized using ark-twitter (Gimpel et al., 2011) and URLs, hashtags and user mentions are identified using regular expressions.", 
        "138": "We also identify emoticons, punctuation, digits, special characters, and some universal interjections and abbreviations (such as RT, aww) as universal tokens.", 
        "139": "We use an existing dictionary (Chittaranjan et al., 2014) for the latter.", 
        "140": "Let the set of tweets after preprocessing be T .", 
        "141": "5.2 SetsW and U We use the COVERSET algorithm (Gella et al., 2014) on each tweet in T .", 
        "142": "It obtains a confidence score for a word wi belonging to a language lj using a Naive Bayes classifier trained on Wikipedia.", 
        "143": "These scores are used to find the minimal set of languages are required to label all the input words.", 
        "144": "If COVERSET detects the tweet as monolingual (i.e., one language can label all words) and the identified language is the same as the Twitter LD label, the tweet is added to the weakly-labeled set W .", 
        "145": "These tweets are almost certainly monolingual, as COVERSET has very high recall (and low precision) for detecting code-switching.", 
        "146": "As these are not manually labeled, we call them weaklylabeled.", 
        "147": "W contains 100K tweets in each language (700K in total).", 
        "148": "From T , we randomly select 100K tweets in each of the seven languages based on the Twitter LD API labels.", 
        "149": "These tweets do not have wordlevel language labels and may be code-switched or have an incorrect Twitter language label.", 
        "150": "We use these as unlabeled data, the set U .", 
        "151": "5.3 Validation and Test Sets  We curate two word-level gold-standard datasets for validation and testing.", 
        "152": "These sets contain monolingual tweets in each of the seven languages as well as code-switched tweets from certain language pairs, based on the availability of real-world data.", 
        "153": "However, it must be noted that GWLD can\ndetect code-switching between more than two languages.", 
        "154": "The language-wise distribution is shown in Table 1.", 
        "155": "Including universal tokens, the validation and test set contain 33981 and 58221 tokens respectively.", 
        "156": "The annotated tweets will be made available for public use.", 
        "157": "For es-en, we use the word-level annotated test set from the code-switching shared task on language detection (Solorio et al., 2014).", 
        "158": "We ignore the tokens labeled NE, Ambiguous and Mixed during our system evaluation (Sec.", 
        "159": "6), as they do not fall in the scope of this work.", 
        "160": "The words labeled \u2018Other\u2019 were marked as xli where li is en or es, based on the context.", 
        "161": "We also use existing nltr validation and test sets (Nguyen and Dogruo\u0308z, 2013), which contain posts from a web forum.", 
        "162": "For the other language pairs, we created our own validation and test sets, as none already exist.", 
        "163": "We randomly selected tweets for which COVERSET identified code-switching with high confidence.", 
        "164": "We gave 215 of these to six annotators for word-level annotation.", 
        "165": "It is difficult to find annotators who know all seven languages; elaborate guidelines were provided on using online machine translation, dictionaries and search engines for the task.", 
        "166": "Four out of the six annotators had high inter-annotator agreement \u2013 the agreement on L1 (language that the majority of the words in the tweet belong to) was 0.93, L2 (the other language, whenever present) was 0.8 and whether the tweet is code-switched was 0.84.", 
        "167": "We did not find any instances of code-switching between more than two\nlanguages, which is rare in general.", 
        "168": "We distributed 3000 tweets between the four annotators (monolingual and code-switched tweets from COVERSET).", 
        "169": "Disagreements were settled between the annotators and a linguist.", 
        "170": "A subset of the annotated tweets form the validation and test sets (Table 1), and were removed fromW and U .", 
        "171": "6 Experiments and Results  We compare GWLD with three existing systems: LINGUINI (Prager, 1999), LANGID (Lui and Baldwin, 2012), and POLYGLOT (Lui et al., 2014).", 
        "172": "None of these perform word-level LD, however, LANGID and POLYGLOT return a list of languages with confidence scores for the input.", 
        "173": "Since codeswitching with more than two languages is absent in our dataset, we consider up to two language labels.", 
        "174": "We define the tweet to be monolingual if the difference between the confidence values for the top two languages is greater than a parameter \u03b4.", 
        "175": "Otherwise, it is assumed to be code-switched with the top two languages.", 
        "176": "\u03b4 is tuned independently for the two LD systems on the validation set by maximizing the metric L1L2 Accuracy (Sec.", 
        "177": "6.2).", 
        "178": "Inspired by Gella et al.", 
        "179": "(2013), we also compare with dictionary-based word-level LD baselines.", 
        "180": "6.1 Dictionary-based Baselines  For each language, we build a lexicon of all the words and their frequencies found in W for that language.", 
        "181": "Let the lexicon for language li \u2208 L be lexi.", 
        "182": "Let f(lexi, wj) be the frequency of wj in lexi.", 
        "183": "We define the following baselines:\nMAXFREQ: For each wj in w, MAXFREQ returns lexi that has the maximum frequency for that token.", 
        "184": "Therefore, the language label for wj is yj = l[argmaxi f(lexi,wj)].", 
        "185": "If the token is not found\nin any lexicon, yj is assigned the value of yj\u22121.", 
        "186": "MINCOVER: We find the smallest subset mincov(w) \u2282 L, such that for all wj in input w, we have at least one language li \u2208 mincov(w) with f(lexi, wj) > 0.", 
        "187": "If there is no such language, then wj is not considered while computing mincov(w).", 
        "188": "Once mincov(w) is obtained, labels yi are computed using the MAXFREQ strategy, where the set of languages is restricted to mincov(w) instead of L. Note that mincov(w) need not be unique for w; in such cases, we choose the mincov(w) which maximizes the sum of lexical frequencies based on MAXFREQ labels.", 
        "189": "6.2 Metrics  We define the Accuracy (Acc) of an LD system as the fraction of words in the test set that are labeled correctly.", 
        "190": "Since the existing LD systems do not label languages at word-level, we also define:\nIsMix is the fraction of tweets that are correctly identified as either monolingual or code-mixed.", 
        "191": "L1L2 Accuracy (L1L2Acc) is the mean accuracy of detecting language(s) at tweet-level.", 
        "192": "For monolingual tweets, this accuracy is 1 if the gold standard label is detected by the LD system, else 0.", 
        "193": "For code-switched tweets, the accuracy is 1 if both languages are detected, 0.5 if one language is detected, and 0 otherwise.", 
        "194": "L1L2Acc is the average over all test set tweets.", 
        "195": "6.3 Results  We use these metrics to assess performance on the test set for the baselines, existing LD systems and GWLD (Table 2).", 
        "196": "Initial refers to the HMM model estimated from W and Reestimated refers to the final model after Baum-Welch reestimation.", 
        "197": "The parameter \u03c0 is tuned on the validation set using grid search.", 
        "198": "Reestimated GWLD has the best accuracy of 0.963 and performs significantly better than all the other systems for all metrics.", 
        "199": "Reesimatation improves the word-levelAcc for L1 from 0.89 to 0.97 and for L2 from 0.43 to 0.82.", 
        "200": "LINGUINI and POLYGLOT likely have low L1L2Acc because they are trained on synthetically-created documents with no word-level code-switching.", 
        "201": "Since our test set contains pre-existing annotations for en-es (Solorio et al., 2014) and nl-tr (Nguyen and Dogruo\u0308z, 2013), we compare with state-of-the-art results on those datasets.", 
        "202": "On en-es tokens, Al-Badrashiny and Diab (2016) reports an F1-score of 0.964; GWLD obtains 0.978.", 
        "203": "Nguyen and Dogruo\u0308z (2013) report 0.976 Acc on the nl-tr\ntest set.", 
        "204": "We obtain a less competitive 0.936.", 
        "205": "However, when errors between nl-en are ignored as most of these are en words with nl gold-standard labels (convention followed by the dataset creators), the revised Acc is 0.963.", 
        "206": "Notably, unlike GWLD, both these models use large amounts of annotated data for training and are restricted to detecting only two languages.", 
        "207": "Error Analysis: GWLD sometimes detects languages that are not present in the tweet, which account for a sizable fraction (39%) of all word-level errors.", 
        "208": "Not detecting a language switch causes 8% of the errors.", 
        "209": "Most other errors are caused by named entities, single-letter tokens, unseen words and the nl-en annotation convention in the test set from Nguyen and Dogruo\u0308z (2013).", 
        "210": "6.4 Robustness of GWLD  We test the robustness of GWLD by varying the size of the weakly-labeled set, the unlabeled dataset and the number of languages the model is trained to support.", 
        "211": "6.4.1 Size ofW and U The variation of Acc with the size ofW is shown in Figure 3a.", 
        "212": "Even with 0.25% of the set (250\ntweets for each li \u2208 L), the model has accuracy of nearly 0.96.", 
        "213": "A slow rise in accuracy is observed as the number of tweets in W is increased.", 
        "214": "We also experiment with varying the size of U .", 
        "215": "In Figure 3a, we see that with 0.25% of U (around 1,400 randomly sampled tweets), the accuracy on the test set is lower than 0.91.", 
        "216": "This quickly increases with 10% of U .", 
        "217": "Thus, GWLD achieves Acc comparable to existing systems with very little weakly-labeled data (just 250 tweets per language, which are easily procurable for most languages) and around 50,000 unlabeled tweets.", 
        "218": "6.4.2 Noise inW Since a small, but pure, W gives high accuracy (Sec.", 
        "219": "6.4.1), we evaluate how artificially introduced noise affectsAcc.", 
        "220": "The noise introduced into the W of each language comes uniformly from the other six languages.", 
        "221": "Figure 3b shows how increasing fractions of noise slowly degrades accuracy, with a steep drop to 0.11 accuracy at 90% noise, where the tweets from each incorrect language outnumber the correct language tweets.", 
        "222": "We test this with a pairwise model as well, as noise from a single language might have greater effect.", 
        "223": "The accuracy falls to 0.36 at 50% noise (Fig.", 
        "224": "3b).", 
        "225": "At this point, W has an equal number of tweets from each language and is essentially useless.", 
        "226": "6.4.3 Number of languages  Pairwise Models: Table 3 details two performance metrics (defined in Sec.", 
        "227": "5.2) for our model trained on only two languages and the corresponding 7-language GWLD Acc for that language pair.", 
        "228": "Incremental Addition of Languages: We test Acc while incrementally adding languages to the model in a random order (nl-en-pt-fr-de-es-tr).", 
        "229": "Figure 4 shows the variation in Acc for nl-en, pten and fr-en as more languages are added to the\nmodel.", 
        "230": "Although there is a slight degradation, in absolute terms, the accuracy remains very high.", 
        "231": "7 Code-Switching on Twitter  The high accuracy and fast processing speed (the current multithreaded implementation labels 2.5M tweets per hour) of GWLD enables us to conduct large-scale and reliable studies of CS patterns on Twitter for the 7 languages.", 
        "232": "In this paper, we conduct two such studies.", 
        "233": "The first study analyzes 50M tweets from across the world to understand the extent and broad patterns of switching among these languages.", 
        "234": "In the second study, we analyze 8M tweets from 24 cities to gain insights into geography-specific CS patterns.", 
        "235": "7.1 Worldwide Code-Switching Trends  We collected 50 million unique tweets that were identified by the Twitter LD API as one of the 7 languages.", 
        "236": "We place this constraint to avoid tweets from unsupported languages during analysis.", 
        "237": "Figure 5 shows the overall language distribution, including the CS language-pair distribution.", 
        "238": "Approximately 96.5% of the tweets are monolingual, a majority of which are en (74%).", 
        "239": "Around 3.5% of all tweets are code-switched.", 
        "240": "Globally, en-es, en-fr and en-pt are the three most\ncommonly mixed pairs accounting for 21.5%, 20.8% and 18.4% of all CS tweets in our data respectively.", 
        "241": "Interestingly, 85.4% of the CS tweets have en as one of the languages; fr is the next most popularly mixed language, with fr-es (3.2%), fr-pt (1.2%) and fr-nl (0.6%) as the top three observed pairs.", 
        "242": "Although around 1% of CS tweets were detected as containing more than two languages, these likely have low precision because of language overdetection as discussed in Sec.", 
        "243": "6.3.", 
        "244": "Figure 6 shows the fraction of code-switch points, i.e., how many times the language changes in a CS tweet, for all the languages, as well as for three language pairs with to highlight different trends.", 
        "245": "Most CS tweets have one CS-point, which implies that the tweet begins with one language, and then ends with another.", 
        "246": "Such tweets are very frequent for en-de where we observe that usually the tweets state the same fact in both en and de.", 
        "247": "This so-called translation function (Begum et al., 2016) of CS is probably adopted for reaching out to a wider and global audience.", 
        "248": "In contrast, es-fr tweets have fewer tweets with single and far more with two CS-point than average.", 
        "249": "Tweets with two CS-points typically imply the inclusion of a short phrase or chunk from another language.", 
        "250": "en-tr tweets have the highest number of CS-points, implying rampant and fluid switching between the two languages at all structural levels.", 
        "251": "7.2 City-Specific Code-Switching Trends  Cosmopolitan cities are melting pots of cultures, which make them excellent locations for studying multilingualism and language interaction, including CS (Bailey et al., 2013).", 
        "252": "We collected tweets from 24 populous and highly cosmopolitan cities from Europe, North America and South America, where the primarily spoken language is one of the 7 languages detectable by GWLD.", 
        "253": "Around 8M tweets were collected from these cities.", 
        "254": "Table 4 shows the top and bottom 6 cities, ranked by the fraction of CS tweets from that city.", 
        "255": "The total number of tweets analyzed and the top two CS pairs, along with their fractions (of CS tweets from that city) are also reported.", 
        "256": "More details can be found in the supplementary material.", 
        "257": "It is interesting to note that the 6 cities with lowest CS tweet fractions have en as the major language, whereas the 6 cities with highest CS fractions are from non-English (Turkish, Spanish and French) speaking geographies.", 
        "258": "In fact, the Pearson\u2019s cor-\nrelation between the fraction of monolingual English tweets and CS tweets for these 24 cities is \u22120.85.", 
        "259": "Further, from Table 4 one can also observe that for non-English speaking geographies, the majority language is most commonly mixed with English, followed by French (Spanish, if French is the majority language).", 
        "260": "Istanbul is an exception, where Dutch is the second most commonly mixed language with Turkish, presumably because of the large Turkish immigrant population in Netherlands resulting in a sizeable TurkishDutch bilingual diaspora (Dog\u0306ruo\u0308z and Backus, 2009; Nguyen and Dogruo\u0308z, 2013).", 
        "261": "Is there a difference in the way speakers mix a pair of languages, say en and es, in en-speaking goegraphies like San Diego, Miami, Houston and New York City, and es-speaking geographies like Madrid, Barcelona, Buenos Aires and Mexico City?", 
        "262": "Indeed, as shown in Fig.", 
        "263": "7, the distribution of the lengths of en and es runs (contiguous sequence of words in a single language beginning and ending with either a CS-point or beginning/end of a tweet) in en-es CS tweets is significantly different in en-speaking and es-speaking geographies.", 
        "264": "en runs are longer in en-speaking cities and vice versa, showing that the second language is likely used in short phrases.", 
        "265": "8 Conclusion and Future Work  We present GWLD, a system for word-level language detection for an arbitrarily large set of languages that is completely unsupervised.", 
        "266": "Our re-\nsults on monolingual and code-switched tweets in seven Latin script languages show a high 0.963 accuracy, significantly out-performing existing systems.", 
        "267": "Using GWLD, we conducted a large-scale study of CS trends among these languages, both globally and in specific cities.", 
        "268": "One of the primary observations of this study is that while code-switching on Twitter is common worldwide (3.5%), it is much more common in non-English speaking cities like Istanbul (12%) where 90% of the population speak Turkish.", 
        "269": "On the other hand, while a third of the population of Houston speaks Spanish and almost everybody English, only 1% of the tweets from the city are code-switched.", 
        "270": "All the trends indicate a global dominance of English, which might be because Twitter is primarily a medium for broadcast, and English tweets have a wider audience.", 
        "271": "Bergsma et al.", 
        "272": "(2012) show that \u201c[On Twitter] bilinguals bridge between monolinguals with English as a hub, while monolinguals tend not to directly follow each other.\u201d Androutsopoulos (2006) argues that due to linguistic non-homogenity of online public spaces, languages like en, fr and de are typically preferred for communication, even though in private spaces, \u201dbilingual talk\u201d differs considerably in terms of distribution and CS patterns.", 
        "273": "As future directions, we plan to extend GWLD to several other languages and conduct similar sociolinguistic studies on CS patterns including not only more languages and geographies, but also other aspects like topic and sentiment.", 
        "274": "Acknowledgments  We would like to thank Prof. Shambavi Pradeep and her students from BMS College of Engineering for assisting with data annotation.", 
        "275": "We are also grateful to Ashutosh Baheti and Silvana Hartmann from Microsoft Research (Bangalore, India) for help with data organization and error analysis."
    }, 
    "document_id": "P17-1180.pdf.json"
}
