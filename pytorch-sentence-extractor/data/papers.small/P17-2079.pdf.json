{
    "abstract_sentences": {
        "1": "We propose AliMe Chat, an open-domain chatbot engine that integrates the joint results of Information Retrieval (IR) and Sequence to Sequence (Seq2Seq) based generation models.", 
        "2": "AliMe Chat uses an attentive Seq2Seq based rerank model to optimize the joint results.", 
        "3": "Extensive experiments show our engine outperforms both IR and generation based models.", 
        "4": "We launch AliMe Chat for a real-world industrial application and observe better results than another public chatbot."
    }, 
    "body_sentences": {
        "1": "  Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 498\u2013503 Vancouver, Canada, July 30 - August 4, 2017. c\u00a92017 Association for Computational Linguistics\nhttps://doi.org/10.18653/v1/P17-2079  1 Introduction  Chatbots have boomed during the last few years, e.g., Microsoft\u2019s XiaoIce, Apple\u2019s Siri, Google\u2019s Google Assistant.", 
        "2": "Unlike traditional apps where users interact with them through simple and structured language (e.g., \u201csubmit\u201d, \u201ccancel\u201d, \u201corder\u201d, etc.", 
        "3": "), chatbots allow users to interact with them using natural language, text or speech (even image).", 
        "4": "We are working on enabling bots to answer customer questions in the E-commerce industry.", 
        "5": "Currently, our bot serves millions of customer questions per day (mainly Chinese, also some English).", 
        "6": "The majority of them is business-related, but also around 5% of them is chat-oriented (several hundreds of thousands in number).", 
        "7": "To offer better user experience, it is necessary to build an opendomain chatbot engine.", 
        "8": "Commonly used techniques for building opendomain chatbots include IR model (Ji et al., 2014; Yan et al., 2016b) and generation model (Bahdanau et al., 2015; Sutskever et al., 2014; Vinyals and Le, 2015).", 
        "9": "Given a question, the former retrieves the nearest question in a Question-Answer (QA) knowledge base and takes the paired answer, the latter generates an answer based on a\npre-trained Seq2Seq model.", 
        "10": "Often, IR models fail to handle long-tail questions that are not close to those in a QA base, and generation models may generate inconsistent or meaningless answers (Li et al., 2016; Serban et al., 2016).", 
        "11": "To alleviate these problems, we propose a hybrid approach that integrates both IR and generation models.", 
        "12": "In our approach, we use an attentive Seq2Seq rerank model to optimize the joint results.", 
        "13": "Specifically, for a question, we first use an IR model to retrieve a set of QA pairs and use them as candidate answers, and then rerank the candidate answers using an attentive Seq2Seq model: if the top candidate has a score higher than a certain threshold, it will be taken as the answer; otherwise the answer will be offered by a generation based model (see Fig.", 
        "14": "1 for the detailed process).", 
        "15": "Our paper makes the following contributions:\n\u2022 We propose a novel hybrid approach that uses an attentive Seq2Seq model to optimize the joint results of IR and generation models.", 
        "16": "\u2022 We conducted a set of experiments to assess the approach.", 
        "17": "Results show that our approach outperforms both IR and generation.", 
        "18": "\u2022 We compared our chatbot engine with a public chatbot.", 
        "19": "Evidence suggests that our engine has a better performance.", 
        "20": "\u2022 We launched AliMe Chat for a real-world industrial application.", 
        "21": "The rest of the paper is structured as follows: Section 2 presents our hybrid approach, followed by experiments in Section 3, related work is in Section 4, and Section 5 concludes our work.", 
        "22": "2 A Seq2Seq based Rerank Approach  We present an overview of our approach in Fig.", 
        "23": "1.", 
        "24": "At first, we construct a QA knowledge base from the chat log of our online customer service cen-\n498\nter.", 
        "25": "Based on this QA knowledge base, we then develop three models: an IR model, a generation based model and a rerank model.", 
        "26": "There are two points to be noted: (1) all the three models are based on words (i.e., word segmentation is needed): the input features of IR model are words, while those of generation model and rerank model are word embeddings, which are pre-trained using fasttext (Bojanowski et al., 2016) and further fine-tuned in the two models; (2) our generation based model and rerank model are built on the same Seq2Seq structure, the former is to generate an output while the latter is to score the candidate answers with regarding to an input question.", 
        "27": "Given an input question q and a threshold T , the procedure of our approach is as follows:\n\u2022 First, we use the IR model to retrieve a set of k candidate QA pairs \u3008qkbi , ri\u3009ki=1 (k = 10).", 
        "28": "\u2022 Second, we pair q with each candidate an-\nswer ri and calculate a confidence score o(ri) = s(q, ri) for each pair using the scoring function in Eqn.", 
        "29": "2 of the rerank model.", 
        "30": "\u2022 Third, we consider the answer r with the maximal score o(r) = max o(ri): if o(r) \u2265 T , take the answer r; otherwise output a reply r\u2032 from the generation based model.", 
        "31": "Here, the threshold T is obtained through an empirical study, to be discussed in Section 3.2.", 
        "32": "2.1 QA Knowledge Base  We use the chat log of our online customer service center between 2016-01-01 and 2016-06-01 as our original data source (the conversations are taken between customers and staff).", 
        "33": "We construct QA pairs from conversations by pairing each question with an adjacent answer.", 
        "34": "When needed, we flatten consecutive questions (resp.", 
        "35": "answers) by concate-\nnating them.", 
        "36": "After that, we filter out QA pairs that contain business related keywords.", 
        "37": "Finally, we obtained 9,164,834 QA pairs.", 
        "38": "2.2 IR Model  Our retrieval model employs search technique to find the most similar question for each input and then obtain the paired answer.", 
        "39": "With word segmentation, we build an inverted index for the set of all 9,164,834 questions by mapping each word to a set of questions that contain that word.", 
        "40": "Given a question, we segment it into a set of words, remove stop words, extend the set with their synonyms, and use the refined set to call back a set of QA candidate pairs.", 
        "41": "We then employ BM25 (Robertson et al., 2009) to calculate similarities between the input question and the retrieved questions, and take the paired answer of the most similar one as the answer.", 
        "42": "2.3 Generation based Model  Our generation based model is built on the attentive Seq2Seq structure (Bahdanau et al., 2015).", 
        "43": "Let \u03b8i = {y1, y2, \u00b7 \u00b7 \u00b7 , yi\u22121, ci}, the probability of generating a word yi at position i is given by Eqn.", 
        "44": "1, where f is a nonlinear function that computes the probability, si\u22121 is the hidden state of the output at position i \u2212 1, ci is a context vector that depends on (h1, h2, \u00b7 \u00b7 \u00b7 , hm), the hidden states of the input sequence: ci = \u2211m j=1 \u03b1ijhj , \u03b1ij = a(si\u22121, hj) is given by an alignment model that scores how well the input at position j matches to the output at i\u2212 1 (Bahdanau et al., 2015).", 
        "45": "An example is shown in Fig.", 
        "46": "2, where i = 3 and m = 4.\np(yi = wi|\u03b8i) = p(yi = wi|y1, y2, .", 
        "47": ".", 
        "48": ".", 
        "49": ", yi\u22121, ci) = f(yi\u22121, si\u22121, ci) (1)\nWe choose Gated Recurrent Units (GRU) as our Recurrent Neural Network (RNN) unit.", 
        "50": "A few important implementations are discussed below.", 
        "51": "Bucketing and padding.", 
        "52": "To handle questions and answers of different lengths, we employ the bucket mechanism proposed in Tensorflow 1.", 
        "53": "We use five buckets (5, 5), (5, 10), (10, 15), (20, 30), (45, 60) to accommodate QA pairs of different length, e.g., a question of length 4 and an answer of length 8 will be put in bucket (5, 10), and pad questions and answers with a special symbol \u201c PAD\u201d when needed.", 
        "54": "Softmax over sampled words.", 
        "55": "To speed up the training process, we apply softmax to a set of sampled vocabulary words (the target word and 512 random ones) rather than the whole set.", 
        "56": "The idea is similar with the importance sampling strategy in (Jean et al., 2014).", 
        "57": "Beam search decoder.", 
        "58": "In the decode phase, we use beam search, which maintains top-k (k = 10) output sequences at each moment t, instead of greedy search, which keeps only one at each time t, to make our generation more reasonable.", 
        "59": "2.4 Attentive Seq2Seq Rerank Model  Our rerank model uses the same attentive Seq2Seq model to score candidate answers with regarding to an input question.", 
        "60": "Specifically, we choose mean probability, denoted as sMean-Prob in Eqn.", 
        "61": "2, as our scoring function (a candidate answer is treated as a word sequence w1, w2, \u00b7 \u00b7 \u00b7 , wn).", 
        "62": "We have also tried inverse of averaged cross-entropy and harmonic mean, but they had a poorer performance.", 
        "63": "sMean-Prob = 1\nn\nn\u2211\ni=1\np(yi = wi|\u03b8i) (2)\n1https://www.tensorflow.org/tutorials/seq2seq  3 Experiments  In our experiments, we first examined the effectiveness of attentive Seq2Seq model with the scoring criterion mean probability; we then evaluated the effectiveness of IR, Generation, IR + Rerank, IR + Rerank + Generation (our approach); we also conducted an online A/B test on our approach and a baseline chatbot engine; lastly, we compared our engine with a publicly available chatbot.", 
        "64": "For evaluation, we have business analysts go through the answer of each testing question (two analysts for the experiment comparing with another public chatbot, and one for the other experiments), and mark them with three graded labels: \u201c0\u201d for unsuitable, \u201c1\u201d means that the answer is only suitable in certain contexts, \u201c2\u201d indicates that the answer is suitable.", 
        "65": "To determine whether an answer is suitable or not, we define five evaluation rules, namely \u201cright in grammar\u201d, \u201csemantically related\u201d, \u201cwell-spoken language\u201d, \u201ccontext independent\u201d and \u201cnot overly generalized\u201d.", 
        "66": "An answer will be labeled as suitable only if it satisfies all the rules, neutral if it satisfies the first three and breaks either of the latter two, and unsuitable otherwise.", 
        "67": "We use top-1 accuracy (Ptop1) as the criterion because the output of some approaches can be more than one (e.g., IR).", 
        "68": "This indicator measures whether the top-1 candidate is suitable or neutral, and is calculated as follows: Ptop1 = (Nsuitable + Nneutral)/Ntotal, where Nsuitable means the number of questions marked as suitable (other symbols are defined similarly).", 
        "69": "3.1 Evaluating Rerank Models  We first compared two Seq2Seq models (the basic one proposed in (Cho et al., 2014), the attentive one presented in Section 2.4), on three scor-\ning criteria (mean probability, inverse of averaged cross-entropy and harmonic mean) using a set of randomly sampled 500 questions.", 
        "70": "We show the Ptop1 result in Table 1, which suggests that the attentive Seq2Seq model with sMean-Prob has the best performance.", 
        "71": "We use it in our rerank model.", 
        "72": "3.2 Evaluating Candidate Approaches  We then evaluated the effectiveness of the following four approaches with another set of 600 questions: IR, Generation, IR + Rerank, IR + Rerank + Generation.", 
        "73": "We present the result in Fig.", 
        "74": "3.", 
        "75": "Clearly the proposed approach (IR + Rerank + Generation) has the best top-1 accuracy: with a confidence score threshold T = 0.19, Ptop1 = 60.01%.", 
        "76": "Here, questions with a score higher than 0.19 (the left of the dashed line, 535 out of 600), are answered using rerank, and the rest is handled by generation.", 
        "77": "The Ptop1 for the other three alternatives are 47.11%, 52.02%, and 56.23%, respectively.", 
        "78": "Note that a narrowly higher Ptop1 can be achieved if a higher threshold is used (e.g., 0.48), or, put differently, rerank less and generate more.", 
        "79": "We use the lower threshold because of the uncontrollability and poor interpretability of Seq2Seq generation: with an elegant decrease at the Ptop1 , we gain more controllability and interpretability.", 
        "80": "3.3 Online A/B Test  We implemented the proposed method in AliMe Chat, our online chatbot engine, and conducted an A/B test on the new and the existing IR method (questions are equally distributed to the two approaches).", 
        "81": "We randomly sampled 2136 QA pairs, with 1089 questions answered by IR and 1047 handled by our hybrid approach, and compared\ntheir top-1 accuracies.", 
        "82": "As shown in Table 2, the new approach has a Ptop1 of 60.36%, which is much higher than that of the IR baseline (40.86%).", 
        "83": "3.4 Comparing with a Public Chatbot  To further evaluate our approach, we compared it with a publicly available chatbot 2.", 
        "84": "We select 878 out of the 1047 testing questions (used in the A/B test) by removing questions relevant to our chatbot, and use it to test the public one.", 
        "85": "To compare their answers with ours, two business analysts were asked to choose a better response for each testing question.", 
        "86": "Table 3 shows the averaged results from the two analysts, clearly our chatbot has a better performance (better on 37.64% of the 878 questions and worse on 18.84%).", 
        "87": "The Kappa measure between the analysts is 0.71, which shows a substantial agreement.", 
        "88": "3.5 Online Serving  We deployed our approach in our chatbot engine.", 
        "89": "For online serving, reranking is of key importance to run time performance: if k candidate QA pairs are ranked asynchronously, the engine has to wait for the last reranker and it will get worse when QPS (questions per second) is high.", 
        "90": "Our solution is to bundle each k QA pairs together and transform it into a k\u00d7nmatrix (n is the maximal length of the concatenation of the k QA pairs, padding is used when needed), and then make use of parallel matrix multiplication in the rerank model to accelerate the computation.", 
        "91": "In our experiments, the batch approach helps to save 41% of the processing time when comparing with the asynchronous way.", 
        "92": "Specifically, more than 75% of questions take less than 150ms with rerank and less than 200ms with generation.", 
        "93": "Moreover, our engine is able to support a peak QPS of 42 on a cluster of 5 service instances, with each reserving 2 cores and 4G memory on an Intel Xeon E5-2430 server.", 
        "94": "This makes our approach applicable to industrial bots.", 
        "95": "2http://www.tuling123.com/\nWe launched AliMe Chat as an online service and integrated it into AliMe Assist, our intelligent assistant in the E-commerce field that supports not only chatting but also customer service (e.g., sales return), shopping guide and life assistance (e.g., book flight).", 
        "96": "We show an example chat dialog generated by our chat service 3 in Fig 4  4 Related Work  Closed-domain dialog systems typically use ruleor template- based methods (Williams and Zweig, 2016; Wen et al., 2016), and dialog state tracking (Henderson, 2015; Wang and Lemon, 2013; Mrksic et al., 2015).", 
        "97": "Differently, open-domain chatbots often adopt data-driven techniques.", 
        "98": "Commonly used include IR and Seq2Seq generation.", 
        "99": "IR based techniques mainly focus on finding the nearest question(s) from a QA knowledge base for an input question, e.g., (Isbell et al., 2000), (Ji et al., 2014), (Yan et al., 2016b).", 
        "100": "A recent work (Yan et al., 2016a) has tried a neural network based method for matching.", 
        "101": "Usually, IR based models have difficulty in handling long-tail questions.", 
        "102": "Seq2Seq based generation models are typically trained on a QA knowledge base or conversation corpus, and used to generate an answer for each input.", 
        "103": "In this direction, RNN based Seq2Seq models are shown to be effective (Cho et al., 2014;\n3Interested readers can access AliMe Assist through the Taobao App by following the path \u201c(My Taobao)\u2192(My AliMe)\u201d.", 
        "104": "Sutskever et al., 2014; Ritter et al., 2011; Shang et al., 2015; Sordoni et al., 2015; Serban et al., 2016).", 
        "105": "A basic Seq2Seq model is proposed in (Sutskever et al., 2014), and enhanced with attention by (Bahdanau et al., 2015).", 
        "106": "Further, Sordoni et al.", 
        "107": "(2015) considered context information, Li et al.", 
        "108": "(2016) tried to let Seq2Seq models generate diversified answers by attaching a diversitypromoting objective function.", 
        "109": "Despite many efforts, Seq2Seq generation models are still likely to generate inconsistent or meaningless answers.", 
        "110": "Our work combines both IR based and generation based models.", 
        "111": "Our work differs from another recent combinational approach (Song et al., 2016) in that they use an IR model to rerank the union of retrieved and generated answers.", 
        "112": "Furthermore, we found that our attentive Seq2Seq rerank approach helps to improve the IR results significantly.", 
        "113": "5 Conclusion  In this paper, we proposed an attentive Seq2Seq based rerank approach that combines both IR and generation based model.", 
        "114": "We have conducted a series of evaluations to assess the effectiveness of our proposed approach.", 
        "115": "Results show that our hybrid approach outperforms both the two models.", 
        "116": "We implemented this new method in an industrial chatbot and released an online service.", 
        "117": "There are many interesting problems to be further explored.", 
        "118": "One is context, which is of key importance to multi-round interaction in dialog system.", 
        "119": "Currently, we use a simple strategy to incorporate context: given a question, if less than three candidates are retrieved by the IR model, we enhance it with its previous question and sent the concatenation to the IR engine again.", 
        "120": "We have tried other context-aware techniques, e.g.", 
        "121": "context sensitive model (Sordoni et al., 2015), neural conversation model (Sutskever et al., 2014), but they do not scale up well in our scenario.", 
        "122": "We are still exploring scalable context-aware methods.", 
        "123": "Also, we are working on personification, i.e., empowering our chatbot with characters and emotions.", 
        "124": "Acknowledgments  The authors would like to thank Juwei Ren, Lanbo Li, Zhongzhou Zhao, Man Yuan, Qingqing Yu, Jun Yang and other members of Alibaba Cloud for helpful discussions and comments.", 
        "125": "We would also like to thank reviewers for their valuable comments."
    }, 
    "document_id": "P17-2079.pdf.json"
}
