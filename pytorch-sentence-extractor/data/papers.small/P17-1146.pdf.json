{
    "abstract_sentences": {
        "1": "The performance of Japanese predicate argument structure (PAS) analysis has improved in recent years thanks to the joint modeling of interactions between multiple predicates.", 
        "2": "However, this approach relies heavily on syntactic information predicted by parsers, and suffers from error propagation.", 
        "3": "To remedy this problem, we introduce a model that uses grid-type recurrent neural networks.", 
        "4": "The proposed model automatically induces features sensitive to multi-predicate interactions from the word sequence information of a sentence.", 
        "5": "Experiments on the NAIST Text Corpus demonstrate that without syntactic information, our model outperforms previous syntax-dependent models."
    }, 
    "body_sentences": {
        "1": "  Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 1591\u20131600 Vancouver, Canada, July 30 - August 4, 2017. c\u00a92017 Association for Computational Linguistics\nhttps://doi.org/10.18653/v1/P17-1146  1 Introduction  Predicate argument structure (PAS) analysis is a basic semantic analysis task, in which systems are required to identify the semantic units of a sentence, such as who did what to whom.", 
        "2": "In prodrop languages such as Japanese, Chinese and Italian, arguments are often omitted in text, and such argument omission is regarded as one of the most problematic issues facing PAS analysis (Iida and Poesio, 2011; Sasano and Kurohashi, 2011; Hangyo et al., 2013).", 
        "3": "In response to the argument omission problem, in Japanese PAS analysis, a joint model of the interactions between multiple predicates has been gaining popularity and achieved the state-ofthe-art results (Ouchi et al., 2015; Shibata et al., 2016).", 
        "4": "This approach is based on the linguistic intuition that the predicates in a sentence are semantically related to each other, and capturing this relation can be useful for PAS analysis.", 
        "5": "In the exam-\nple sentence in Figure 1, the word \u201c\u7537 i (mani)\u201d is the accusative argument of the predicate \u201c\u902e\u6355\u3057 \u305f (arrested)\u201d and is shared by the other predicate \u201c\u9003\u8d70\u3057\u305f (escaped)\u201d as its nominative argument.", 
        "6": "Considering the semantic relation between \u201c\u902e\u6355 \u3057\u305f (arrested)\u201d and \u201c\u9003\u8d70\u3057\u305f (escaped)\u201d, we intuitively know that the person arrested by someone is likely to be the escaper.", 
        "7": "That is, information about one predicate-argument relation could help to identify another predicate-argument relation.", 
        "8": "However, to model such multi-predicate interactions, the joint approach in the previous studies relies heavily on syntactic information, such as part-of-speech (POS) tags and dependency relations predicted by POS taggers and syntactic parsers.", 
        "9": "Consequently, it suffers from error propagation caused by pipeline processing.", 
        "10": "To remedy this problem, we propose a neural model which automatically induces features sensitive to multi-predicate interactions exclusively from the word sequence information of a sentence.", 
        "11": "The proposed model takes as input all predicates and their argument candidates in a sentence at a time, and captures the interactions using gridtype recurrent neural networks (Grid-RNN) without syntactic information.", 
        "12": "1591\nIn this paper, we first introduce a basic model that uses RNNs.", 
        "13": "This model independently estimates the arguments of each predicate without considering multi-predicate interactions (Sec.", 
        "14": "3).", 
        "15": "Then, extending this model, we propose a neural model that uses Grid-RNNs (Sec.", 
        "16": "4).", 
        "17": "Performing experiments on the NAIST Text Corpus (Iida et al., 2007), we demonstrate that even without syntactic information, our neural models outperform previous syntax-dependent models (Imamura et al., 2009; Ouchi et al., 2015).", 
        "18": "In particular, the neural model using Grid-RNNs achieved the best result.", 
        "19": "This suggests that the proposed grid-type neural architecture effectively captures multi-predicate interactions and contributes to performance improvements.", 
        "20": "1  2 Japanese Predicate Argument Structure Analysis    2.1 Task Description  In Japanese PAS analysis, arguments are identified that each fulfills one of the three major case roles, nominative (NOM), accusative (ACC) and dative (DAT) cases, for each predicate.", 
        "21": "Arguments can be divided into the following three categories according to the positions relative to their predicates (Hayashibe et al., 2011; Ouchi et al., 2015):\nDep: Arguments that have direct syntactic dependency on the predicate.", 
        "22": "Zero: Arguments referred to by zero pronouns within the same sentence that have no direct syntactic dependency on the predicate.", 
        "23": "Inter-Zero: Arguments referred to by zero pronouns outside of the same sentence.", 
        "24": "1Our source code is publicly available at https://github.com/hiroki13/neural-pasa-system\nFor example, in Figure 1, the nominative argument \u201c\u8b66\u5bdf (police)\u201d for the predicate \u201c\u902e\u6355\u3057\u305f (arrested)\u201d is regarded as a Dep argument, because the argument has a direct syntactic dependency on the predicate.", 
        "25": "By contrast, the nominative argument \u201c\u7537 i (mani)\u201d for the predicate \u201c\u9003\u8d70\u3057 \u305f (escaped)\u201d is regarded as a Zero argument, because the argument has no direct syntactic dependency on the predicate.", 
        "26": "In this paper, we focus on the analysis for these intra-sentential arguments, i.e., Dep and Zero.", 
        "27": "In order to identify inter-sentential arguments (Inter-Zero), a much broader space must be searched (e.g., the whole document), resulting in a much more complicated analysis than intrasentential arguments.2 Owing to this complication, Ouchi et al.", 
        "28": "(2015) and Shibata et al.", 
        "29": "(2016) focused exclusively on intra-sentential argument analysis.", 
        "30": "Following this trend, we also restrict our focus to intra-sentential argument analysis.", 
        "31": "2.2 Challenging Problem  Arguments are often omitted in Japanese sentences.", 
        "32": "In Figure 1, \u03d5i represents the omitted argument, called the zero pronoun.", 
        "33": "This zero pronoun \u03d5i refers to \u201c\u7537 i (mani)\u201d.", 
        "34": "In Japanese PAS analysis, when an argument of the target predicate is omitted, we have to identify the antecedent of the omitted argument (i.e., the Zero argument).", 
        "35": "The analysis of such Zero arguments is much more difficult than that for Dep arguments, owing to the lack of direct syntactic dependencies.", 
        "36": "For Dep arguments, the syntactic dependency between an argument and its predicate is a strong clue.", 
        "37": "In the sentence in Figure 1, for the predi-\n2The F-measure remains 10-20% (Taira et al., 2008; Imamura et al., 2009; Sasano and Kurohashi, 2011).", 
        "38": "cate \u201c\u902e\u6355\u3057\u305f (arrested)\u201d, the nominative argument is \u201c\u8b66\u5bdf (police)\u201d.", 
        "39": "This argument is easily identified by relying on the syntactic dependency.", 
        "40": "By contrast, because the nominative argument \u201c\u7537 i (mani)\u201d has no syntactic dependency on its predicate \u201c\u9003\u8d70\u3057\u305f (escaped)\u201d, we must rely on other information to identify the zero argument.", 
        "41": "As a solution to this problem, we exploit two kinds of information: (i) the context of the entire sentence, and (ii) multi-predicate interactions.", 
        "42": "For the former, we introduce single-sequence model that induces context-sensitive representations from a sequence of argument candidates of a predicate.", 
        "43": "For the latter, we introduce multisequence model that induces predicate-sensitive representations from multiple sequences of argument candidates of all predicates in a sentence (shown in Figure 2).", 
        "44": "3 Single-Sequence Model  The single-sequence model exploits stacked bidirectional RNNs (Bi-RNN) (Schuster and Paliwal, 1997; Graves et al., 2005, 2013; Zhou and Xu, 2015).", 
        "45": "Figure 3 shows the overall architecture, which consists of the following three components:\nInput Layer: Map each word to a feature vector representation.", 
        "46": "RNN Layer: Produce high-level feature vectors using Bi-RNNs.", 
        "47": "Output Layer: Compute the probability of each case label for each word using the softmax function.", 
        "48": "In the following subsections, we describe each of these three components in detail.", 
        "49": "3.1 Input Layer  Given an input sentence w1:T = (w1, \u00b7 \u00b7 \u00b7 , wT) and a predicate p, each word wt is mapped to a feature representation xt, which is the concatenation (\u2295) of three types of vectors:\nxt = x arg t \u2295 xpredt \u2295 xmarkt (1)\nwhere each vector is based on the following atomic features inspired by Zhou and Xu (2015):\nARG: Word index of each word.", 
        "50": "PRED: Word index of the target predicate and\nthe words around the predicate.", 
        "51": "MARK: Binary index that represents whether or not the word is the predicate.", 
        "52": "Figure 4 presents an example of the atomic features.", 
        "53": "For the ARG feature, we extract a word index xword \u2208 V for each word.", 
        "54": "Similarly, for the PRED feature, we extract each word index xword for the C words taking the target predicate at the center, where C denotes the window size.", 
        "55": "The MARK feature xmark \u2208 {0, 1} is a binary value that represents whether or not the word is the predicate.", 
        "56": "Then, using feature indices, we extract feature vector representations from each embedding matrix.", 
        "57": "Figure 5 shows the process of creating the feature vector x1 for the word w1 \u201c\u5f7c\u5973 (she)\u201d.", 
        "58": "We set two embedding matrices: (i) a word embedding matrix Eword \u2208 Rdword\u00d7|V|, and (ii) a mark embedding matrix Emark \u2208 Rdmark\u00d72.", 
        "59": "From each embedding matrix, we extract the corresponding column vectors and concatenate them as a feature vector xt based on Eq.", 
        "60": "1.", 
        "61": "Each feature vector xt is multiplied with a parameter matrix Wx:\nh (0) t = Wx xt (2)\nThe vector h(0)t is given to the first RNN layer as input.", 
        "62": "3.2 RNN Layer  In the RNN layers, feature vectors are updated recurrently using Bi-RNNs.", 
        "63": "Bi-RNNs process an input sequence in a left-to-right manner for oddnumbered layers and in a right-to-left manner for even-numbered layers.", 
        "64": "By stacking these layers, we can construct the deeper network structures.", 
        "65": "Stacked Bi-RNNs consist of L layers, and the hidden state in the layer \u2113 \u2208 (1, \u00b7 \u00b7 \u00b7 , L) is calculated as follows:\nh (\u2113) t =\n{ g(\u2113)(h (\u2113\u22121) t , h (\u2113) t\u22121) (\u2113 = odd)\ng(\u2113)(h (\u2113\u22121) t , h (\u2113) t+1) (\u2113 = even)\n(3)\nBoth of the odd- and even-numbered layers receive h(\u2113\u22121)t , the t-th hidden state of the \u2113\u22121 layer, as the first input of the function g(\u2113), which is an arbitrary function 3.", 
        "66": "For the second input of g(\u2113), odd-numbered layers receive h(\u2113)t\u22121, whereas evennumbered layers receive h(\u2113)t+1.", 
        "67": "By calculating the hidden states until the L-th layer, we obtain a hidden state sequence h(L)1:T = (h (L) 1 , \u00b7 \u00b7 \u00b7 ,h (L) T ).", 
        "68": "Using each vector h(L)t , we calculate the probability of case labels for each word in the output layer.", 
        "69": "3In this work, we used the Gated Recurrent Unit (GRU) (Cho et al., 2014) as the function g(\u2113).", 
        "70": "3.3 Output Layer  For the output layer, multi-class classification is performed using the softmax function:\nyt = softmax(Wy h (L) t )\nwhere h(L)t denotes a vector representation propagated from the last RNN layer (Fig 3).", 
        "71": "Each element of yt is a probability value corresponding to each label.", 
        "72": "The label with the maximum probability among them is output as a result.", 
        "73": "In this work, we set five labels: NOM, ACC, DAT, PRED, null.", 
        "74": "PRED is the label for the predicate, and null denotes a word that does not fulfill any case role.", 
        "75": "4 Multi-Sequence Model  Whereas the single-sequence model assumes independence between predicates, the multi-sequence model assumes multi-predicate interactions.", 
        "76": "To capture such interactions between all predicates in a sentence, we extend the singlesequence model to the multi-sequence model using Grid-RNNs (Graves and Schmidhuber, 2009; Kalchbrenner et al., 2016).", 
        "77": "Figure 6 presents the overall architecture for the multi-sequence model, which consists of three components:\nInput Layer: Map words to M sequences of feature vectors forM predicates.", 
        "78": "Grid Layer: Update the hidden states over different sequences using Grid-RNNs.", 
        "79": "Output Layer: Compute the probability of each case label for each word using the softmax function.", 
        "80": "In the following subsections, we describe these three components in detail.", 
        "81": "4.1 Input Layer  The multi-sequence model takes as input a sentence w1:T = (w1, \u00b7 \u00b7 \u00b7 , wT) and all predicates {pm}M1 in the sentence.", 
        "82": "For each predicate pm, the input layer creates a sequence of feature vectors Xm = (xm,1, \u00b7 \u00b7 \u00b7 ,xm,T) by mapping each input word wt to a feature vector xm,t based on Eq 1.", 
        "83": "That is, for M predicates, M sequences of feature vectors {Xm}M1 are created.", 
        "84": "Then, using Eq.", 
        "85": "2, each feature vector xm,t is mapped to h(0)m,t, and a feature sequence is created for a predicate pm, i.e.,H (0) m = (h (0) m,1, \u00b7 \u00b7 \u00b7 ,h (0) m,T).", 
        "86": "Consequently, forM predicates, we obtainM feature sequences {H(0)m }M1 .", 
        "87": "4.2 Grid Layer    Inter-Sequence Connections  For the grid layers, we use Grid-RNNs to propagate the feature information over the different sequences (inter-sequence connections).", 
        "88": "The figure on the right in Figure 6 shows the first grid layer.", 
        "89": "The hidden state is recurrently calculated from the upper-left (m = 1, t = 1) to the lowerright (m = M, t = T).", 
        "90": "Formally, in the \u2113-th layer, the hidden state h(\u2113)m,t is calculated as follows:\nh (\u2113) m,t=\n{ g(\u2113)(h (\u2113\u22121) m,t \u2295 h (\u2113) m\u22121,t,h (\u2113) m,t\u22121) (\u2113 = odd)\ng(\u2113)(h (\u2113\u22121) m,t \u2295 h (\u2113) m+1,t,h (\u2113) m,t+1) (\u2113 = even)\nThis equation is similar to Eq.", 
        "91": "3.", 
        "92": "The main difference is that the hidden state of a neighboring sequence, h(\u2113)m\u22121,t (or h (\u2113) m+1,t), is concatenated (\u2295) with the hidden state of the previous (\u2113\u2212 1) layer, h (\u2113\u22121) m,t , and is taken as input of the function g\n(\u2113).", 
        "93": "In the figure on the right in Figure 6, the blue curved lines represent the inter-sequence connections.", 
        "94": "Taking as input the hidden states of neighboring sequences, the network propagates feature information over multiple sequences (i.e., predicates).", 
        "95": "By calculating the hidden states until the L-th layer, we obtain M sequences of the hidden states, i.e., {H(L)m }M1 , in which H (L) m = (h (L) m,1, \u00b7 \u00b7 \u00b7 ,h (L) m,T).", 
        "96": "Residual Connections  As more layers are stacked, it becomes more difficult to learn the model parameters, owing to various challenges such as the vanishing gradient problem (Pascanu et al., 2013).", 
        "97": "In this work,\nwe integrate residual connections (He et al., 2015; Wu et al., 2016) with our networks to form connections between layers.", 
        "98": "Specifically, the input vector h(\u2113\u22121)m,t of the \u2113-th layer is added to the output vector h(\u2113)m,t.", 
        "99": "Residual connections can also be applied to the single-sequence model.", 
        "100": "Thus, we can perform experiments on both models with/without residual connections.", 
        "101": "4.3 Output Layer  As with the single-sequence model, we use the softmax function to calculate the probability of the case labels of each word wt for each predicate pm:\nym,t = softmax(Wy h (L) m,t)\nwhere h(L)m,t is a hidden state vector calculated in the last grid layer.", 
        "102": "5 Related Work    5.1 Japanese PAS Analysis Approaches  Existing approaches to Japanese PAS analysis are divided into two categories: (i) the pointwise approach and (ii) the joint approach.", 
        "103": "The pointwise approach involves estimating the score of each argument candidate for one predicate, and then selecting the argument candidate with the maximum score as an argument (Taira et al., 2008; Imamura et al., 2009; Hayashibe et al., 2011; Iida et al., 2016).", 
        "104": "The joint approach involves scoring all the predicateargument combinations in one sentence, and then selecting the combination with the highest score (Yoshikawa et al., 2011; Sasano and Kurohashi,\n2011; Ouchi et al., 2015; Shibata et al., 2016).", 
        "105": "Compared with the pointwise approach, the joint approach achieves better results.", 
        "106": "5.2 Multi-Predicate Interactions  Ouchi et al.", 
        "107": "(2015) reported that it is beneficial to Japanese PAS analysis to capture the interactions between all predicates in a sentence.", 
        "108": "This is based on the linguistic intuition that the predicates in a sentence are semantically related to each other, and that the information regarding this semantic relation can be useful for PAS analysis.", 
        "109": "Similarly, in semantic role labeling (SRL), Yang and Zong (2014) reported that their reranking model, which captures the multi-predicate interactions, is effective for the English constituentbased SRL task (Carreras and Ma\u0300rquez, 2005).", 
        "110": "Taking this a step further, we propose a neural architecture that effectively models the multipredicate interactions.", 
        "111": "5.3 Neural Approaches    Japanese PAS  In recent years, several attempts have been made to apply neural networks to Japanese PAS analysis (Shibata et al., 2016; Iida et al., 2016)4.", 
        "112": "In Shibata et al.", 
        "113": "(2016), a feed-forward neural network is used for the score calculation part of the joint model proposed by Ouchi et al.", 
        "114": "(2015).", 
        "115": "In Iida et al.", 
        "116": "(2016), multi-column convolutional neural networks are used for the zero anaphora resolution task.", 
        "117": "Both models exploit syntactic and selectional preference information as the atomic features of neural networks.", 
        "118": "Overall, the use of neural networks has resulted in advantageous performance levels, mitigating the cost of manually designing combination features.", 
        "119": "In this work, we demonstrate that even without such syntactic information, our neural models can realize comparable performance exclusively using the word sequence information of a sentence.", 
        "120": "English SRL  Some neural models have achieved high performance without syntactic information in English SRL.", 
        "121": "Collobert et al.", 
        "122": "(2011) and Zhou and Xu (2015) worked on the English constituent-based\n4These previous studies used unpublished datasets and evaluated the performance with different experimental settings.", 
        "123": "Consequently, we cannot compare their models with ours.", 
        "124": "SRL task (Carreras and Ma\u0300rquez, 2005) using neural networks.", 
        "125": "In Collobert et al.", 
        "126": "(2011), their model exploited a convolutional neural network and achieved a 74.15% F-measure without syntactic information.", 
        "127": "In Zhou and Xu (2015), their model exploited bidirectional RNNs with linear-chain conditional random fields (CRFs) and achieved the state-of-the-art result, an 81.07% Fmeasure.", 
        "128": "Our models should be regarded as an extension of their model.", 
        "129": "The main differences between Zhou and Xu (2015) and our work are: (i) constituent-based vs dependency-based argument identification and (ii) the multi-predicate consideration.", 
        "130": "For the constituent-based SRL, Zhou and Xu (2015) used CRFs to capture the IOB label dependencies, because systems are required to identify the spans of arguments for each predicate.", 
        "131": "By contrast, for Japanese dependency-based PAS analysis, we replaced the CRFs with the softmax function, because in Japanese, arguments are rarely adjacent to each other.5 Furthermore, whereas the model described in Zhou and Xu (2015) predicts arguments for each predicate independently, our multisequence model jointly predicts arguments for all predicates in a sentence concurrently by considering the multi-predicate interactions.", 
        "132": "6 Experiments    6.1 Experimental Settings    Dataset  We used the NAIST Text Corpus 1.5, which consists of 40,000 sentences from Japanese newspapers (Iida et al., 2007).", 
        "133": "For the experiments, we adopted standard data splits (Taira et al., 2008; Imamura et al., 2009; Ouchi et al., 2015):\nTrain: Articles: Jan 1-11, Editorials: Jan-Aug Dev: Articles: Jan 12-13, Editorials: Sept Test: Articles: Jan 14-17, Editorials: Oct-Dec\nWe used the word boundaries annotated in the NAIST Text Corpus and the target predicates that have at least one argument in the same sentence.", 
        "134": "We did not use any external resources.", 
        "135": "Learning  We trained the model parameters by minimizing\n5In our preliminary experiment, we could not confirm the performance improvement by CRFs.", 
        "136": "the cross-entropy loss function:\nL(\u03b8) = \u2212 \u2211\nn\n\u2211\nt\nlogP (yt|xt) + \u03bb\n2 ||\u03b8||2 (4)\nwhere \u03b8 is a set of model parameters, and the hyper-parameter \u03bb is the coefficient governing the L2 weight decay.", 
        "137": "Implementation Details  We implemented our neural models using a deep learning library, Theano (Bastien et al., 2012).", 
        "138": "The number of epochs was set at 50, and we reported the result of the test set in the epoch with the best F-measure from the development set.", 
        "139": "The parameters were optimized using the stochastic gradient descent method (SGD) via a mini-batch, whose size was selected from {2, 4, 8}.", 
        "140": "The learning rate was automatically adjusted using Adam (Kingma and Ba, 2014).", 
        "141": "For the L2 weight decay, the hyper-parameter \u03bb in Eq.", 
        "142": "4 was selected from {0.001, 0.0005, 0.0001}.", 
        "143": "In the neural models, the number of the RNN and Grid layers were selected from {2, 4, 6, 8}.", 
        "144": "The window size C for the PRED feature (Sec.", 
        "145": "3.1) was set at 5.", 
        "146": "Words with a frequency of 2 or more in the training set were mapped to each word index, and the remaining words were mapped to the unknown word index.", 
        "147": "The dimensions dword and dmark of the embeddings were set at 32.", 
        "148": "In the single-sequence model, the parameters of GRUs were set at 32\u00d7 32.", 
        "149": "In the multi-sequence model, the parameters of GRUs related to the input values were set at 64 \u00d7 32, and the remaining were set at 32\u00d7 32.", 
        "150": "The initial values of all parameters were sampled according to a uniform distribution from [\u2212 \u221a 6\u221a\nrow+col ,\n\u221a 6\u221a\nrow+col ], where row and col\nare the number of rows and columns of each matrix, respectively.", 
        "151": "Baseline Models  We compared our models to existing models in previous works (Sec.", 
        "152": "5.1) that use the NAIST Text Corpus 1.5.", 
        "153": "As a baseline for the pointwise approach, we used the pointwise model6 proposed in Imamura et al.", 
        "154": "(2009).", 
        "155": "In addition, as a baseline for the joint approach, we used the model proposed in Ouchi et al.", 
        "156": "(2015).", 
        "157": "These models exploit gold annotations in the NAIST Text Corpus as POS tags and dependency relations.", 
        "158": "6We compared the results of the model reimplemented by Ouchi et al.", 
        "159": "(2015).", 
        "160": "6.2 Results    Neural Models vs Baseline Models  Table 1 presents F-measures from our neural sequence models with eight RNN or Grid layers and the baseline models on the test set.", 
        "161": "For the significant test, we used the bootstrap resampling method.", 
        "162": "According to all metrics, both the single(Single-Seq) and multi-sequence models (MultiSeq) outperformed the baseline models.", 
        "163": "This confirms that our neural models realize high performance, even without syntactic information, by learning contextual information effective for PAS analysis from the word sequence of the sentence.", 
        "164": "In particular, for zero arguments (Zero), our models achieved a considerable improvement compared to the joint model in Ouchi et al.", 
        "165": "(2015).", 
        "166": "Specifically, the single-sequence model improved by approximately 2.0 points, and the multisequence model by approximately 3.0 points according to the F-measure.", 
        "167": "These results suggest that modeling the context of the entire sentence using RNNs are beneficial to Japanese PAS analysis, particularly to zero argument identification.", 
        "168": "Effects of Multiple Predicate Consideration  As Table 1 shows, the multi-sequence model significantly outperformed the single-sequence model in terms of the F-measure overall (81.42% vs 81.15%).", 
        "169": "These results demonstrate that the grid-type neural architecture can effectively capture multi-predicate interactions by connecting the sequences of the argument candidates for all predicates in a sentence.", 
        "170": "Compared to the single-sequence model for dif-\nferent argument types, the multi-sequence model achieved slightly better results for direct dependency arguments (Dep) (88.10% vs 88.17%).", 
        "171": "In addition, for zero arguments (Zero), which have no syntactic dependency on their predicate, the multisequence model outperformed the single-sequence model by approximately 1.0 point according to the F-measure (46.10% vs 47.12%).", 
        "172": "This shows that capturing multi-predicate interactions is particularly effective for zero arguments, which is consistent with the results in Ouchi et al.", 
        "173": "(2015).", 
        "174": "Effects of Network Depth  Table 2 presents F-measures from the neural sequence models with different network depths and with/without residual connections.", 
        "175": "The performance tends to improve as the RNN or Grid layers get deeper with residual connections.", 
        "176": "In particular, the two models with eight layers and residual connections achieved considerable improvements of approximately 1.0 point according to the F-measure compared to models without residual connections.", 
        "177": "This means that residual connections contribute to effective parameter learning of deeper models.", 
        "178": "Effects of the Number of Predicates  Table 3 presents F-measures from the neural sequence models with different numbers of predicates in a sentence.", 
        "179": "In Table 3, M denotes how\nmany predicates appear in a sentence.", 
        "180": "For example, the sentence in Figure 1 includes two predicates, \u201carrested\u201d and \u201cescaped\u201d, and thus in this exampleM = 2.", 
        "181": "Overall, performance of both models gradually deteriorated as the number of predicates in a sentence increased, because sentences that contain many predicates are complex and difficult to analyze.", 
        "182": "However, compared to the singlesequence model, the multi-sequence model suppressed performance degradation, especially for zero arguments (Zero).", 
        "183": "By contrast, for direct dependency arguments (Dep), both models either achieved almost equivalent performance or the single-sequence model outperformed the multisequence model.", 
        "184": "A Detailed investigation of the relation between the number of predicates in a sentence and the complexity of PAS analysis is an interesting line for future work.", 
        "185": "Comparison per Case Role  Table 4 shows F-measures for each case role.", 
        "186": "For reference, we show the results of the previous studies using the NAIST Text Corpus 1.4\u03b2 with external resources as well.7\n7The major difference between the NAIST Text Corpus 1.4\u03b2 and 1.5 is the revision of the annotation criterion for the dative case (DAT) (corresponding to Japanese case marker \u201c \u306b\u201d).", 
        "187": "Argument and adjunct usages of the case marker \u201c\u306b\u201d are not distinguished in 1.4\u03b2, making the identification of the dative case seemingly easy (Ouchi et al., 2015).", 
        "188": "Comparing the models using the NAIST Text Corpus 1.5, the single- and multi-sequence models outperformed the baseline models according to all metrics.", 
        "189": "In particular, for the dative case, the two neural models achieved much higher results, by approximately 30 points.", 
        "190": "This suggests that although dative arguments appear infrequently compared with the other two case arguments, the neural models can learn them robustly.", 
        "191": "In addition, for zero arguments (Zero), the neural models achieved better results than the baseline models.", 
        "192": "In particular, for zero arguments of the nominative case (NOM), the multisequence model demonstrated a considerable improvement of approximately 2.5 points according to the F-measure compared with the joint model in Ouchi et al.", 
        "193": "(2015).", 
        "194": "To achieve high accuracy for the analysis of such zero arguments, it is necessary to capture long distance dependencies (Iida et al., 2005; Sasano and Kurohashi, 2011; Iida et al., 2015).", 
        "195": "Therefore, the improvements of the results suggest that the neural models effectively capture long distance dependencies using RNNs that can encode the context of the entire sentence.", 
        "196": "7 Conclusion  In this work, we introduced neural sequence models that automatically induce effective feature representations from the word sequence information of a sentence for Japanese PAS analysis.", 
        "197": "The experiments on the NAIST Text Corpus demonstrated that the models realize high performance without the need for syntactic information.", 
        "198": "In particular, our multi-sequence model improved the\nperformance of zero argument identification, one of the problematic issues facing Japanese PAS analysis, by considering the multi-predicate interactions with Grid-RNNs.", 
        "199": "Because our neural models are applicable to SRL, applying our models for multilingual SRL tasks presents an interesting future research direction.", 
        "200": "In addition, in this work, the model parameters were learned without any external resources.", 
        "201": "In future work, we plan to explore effective methods for exploiting large-scale unlabeled data to learn the neural models.", 
        "202": "Acknowledgments  This work was partially supported by JST CREST Grant Number JPMJCR1513 and JSPS KAKENHI Grant Number 15K16053.", 
        "203": "We are grateful to the members of the NAIST Computational Linguistics Laboratory and the anonymous reviewers for their insightful comments."
    }, 
    "document_id": "P17-1146.pdf.json"
}
