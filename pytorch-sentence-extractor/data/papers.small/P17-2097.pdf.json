{
    "abstract_sentences": {
        "1": "We consider the ROC story cloze task (Mostafazadeh et al., 2016) and present several findings.", 
        "2": "We develop a model that uses hierarchical recurrent networks with attention to encode the sentences in the story and score candidate endings.", 
        "3": "By discarding the large training set and only training on the validation set, we achieve an accuracy of 74.7%.", 
        "4": "Even when we discard the story plots (sentences before the ending) and only train to choose the better of two endings, we can still reach 72.5%.", 
        "5": "We then analyze this \u201cending-only\u201d task setting.", 
        "6": "We estimate human accuracy to be 78% and find several types of clues that lead to this high accuracy, including those related to sentiment, negation, and general ending likelihood regardless of the story context."
    }, 
    "body_sentences": {
        "1": "  Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 616\u2013622 Vancouver, Canada, July 30 - August 4, 2017. c\u00a92017 Association for Computational Linguistics\nhttps://doi.org/10.18653/v1/P17-2097  1 Introduction  The ROC story cloze task (Mostafazadeh et al., 2016) tests a system\u2019s ability to choose the more plausible of two endings to a story.", 
        "2": "The incorrect ending is written to still fit the world of the story, e.g., the protagonist typically appears in both endings.", 
        "3": "The task is designed to test for \u201ccommonsense\u201d knowledge, where the difference between the two endings lies in the plausibility of the characters\u2019 actions.", 
        "4": "The best system of Mostafazadeh et al.", 
        "5": "(2016) achieves 58.5% accuracy.", 
        "6": "The ROC training and evaluation data differ in a key way.", 
        "7": "The training set contains 5-sentence stories.", 
        "8": "But the evaluation datasets (the validation and test sets) contain both a correct ending and an incorrect ending.", 
        "9": "This means that the task is one of outlier detection: systems must estimate the density of correct endings in the training data and\nthen detect which of the two endings is an outlier.", 
        "10": "This becomes difficult when the evaluation contains distractors that are still somewhat plausible.", 
        "11": "For example, a model may place mass on stories that consistently mention the same characters, but this will not be useful for the task because even the incorrect ending uses the correct character names.", 
        "12": "In this paper, we discard the 50k training stories and train only on the 1871-story validation set.", 
        "13": "We develop several neural models based on recurrent networks, comparing flat and hierarchical models for encoding the sentences in the story.", 
        "14": "We also use an attention mechanism based on the ending to identify useful parts of the plot.", 
        "15": "Our final model achieves 74.7% on the test set, outperforming all systems of Mostafazadeh et al.", 
        "16": "(2016) and approaching the state of the art results of concurrent work (Schwartz et al., 2017b).", 
        "17": "We then discard the first four sentences of each story and use our model to score endings alone.", 
        "18": "We achieve 72.5% on the test set, outperforming most prior work without even looking at the story plots.", 
        "19": "We do a small-scale manual study of this ending-only task, finding that humans can identify the better ending in approximately 78% of cases.", 
        "20": "We report several reasons for the high accuracy of this ending-only setting, including some that are readily captured by automatic methods, such as sentiment analysis and the presence of negation words, as well as others that are more difficult, like those derived from world knowledge.", 
        "21": "Our results and analysis, combined with the similar concurrent observations of Schwartz et al.", 
        "22": "(2017a), suggest that any meaningful system for the ROC task must outperform the best ending-only baselines.", 
        "23": "2 Task and Datasets  We refer to a 5-sentence sequence as a story, the incomplete 4-sentence sequence as a plot, and the\n616\nfifth sentence as an ending.", 
        "24": "The ROC story corpus (Mostafazadeh et al., 2016) contains training, validation, and test sets.", 
        "25": "The training set contains 5-sentence stories.", 
        "26": "The validation and test sets contain 4-sentence plots followed by two candidate endings, with only one correct.", 
        "27": "Mostafazadeh et al.", 
        "28": "(2016) evaluated several methods for solving the task.", 
        "29": "Since the training set does not contain incorrect endings, their methods are based on computing similarity between the plot and ending.", 
        "30": "Their best results were obtained with the Deep Structured Semantic Model (DSSM) (Huang et al., 2013) which represents texts using character trigram counts followed by neural network layers and a similarity function.", 
        "31": "Concurrently with our work, the LSDSem 2017 shared task was held (Mostafazadeh et al., 2017), focusing on the ROC story cloze task.", 
        "32": "Several of the participants made similar observations to what we describe here, namely that supervised learning on the validation set is more effective than learning directly from the training set, as well as noting certain biases in the endings (Schwartz et al., 2017a,b; Bugert et al., 2017; Flor and Somasundaran, 2017; Schenk and Chiarcos, 2017; Roemmele et al., 2017; Goel and Singh, 2017; Mihaylov and Frank, 2017).", 
        "33": "3 Models and Training  We now describe our model variations.", 
        "34": "The first (ENCPLOTEND) encodes the plot and ending separately, then scores them with a scoring function.", 
        "35": "The second (ENCSTORY) concatenates the plot and ending to form a story, then encodes that story and scores its representation with a scoring function.", 
        "36": "When encoding a sequence of multiple sentences, whether with ENCPLOTEND or ENCSTORY, we consider two choices: a hierarchical encoder (HIER) that first encodes each sentence and then encodes the sentence representations, and a non-hierarchical encoder (FLAT) that simply encodes the concatenation of all sentences.", 
        "37": "We also consider the possibility of including an endingoriented attention mechanism (ATT).", 
        "38": "For training, we use a simple supervised hinge loss objective.", 
        "39": "3.1 Encoders  Our encoders encode text sequences into representations.", 
        "40": "When using our HIER model, we use a hierarchical recurrent neural network (RNN) (Li et al., 2015) with two levels.", 
        "41": "The first RNN en-\ncodes the sequence of words in a sentence; the same RNN is used for sentences in the plot and for each candidate ending.", 
        "42": "The second RNN encodes the sequence of sentence representations in a plot or story.", 
        "43": "When using our FLAT model, we only use the first RNN described above; the only change is that the input becomes the concatenation of multiple sentences (separated by sentence boundary tokens).", 
        "44": "Below we use i as a subscript to index sentences in the story or plot, and j as a superscript to index individual words in sentences.", 
        "45": "E.g., we use wi to indicate the ith sentence of the story/plot and we use wi(j) to denote the word embedding vector of the jth word in the ith sentence.", 
        "46": "3.1.1 Encoding Word Sequences  We use a bidirectional long short-term memory (BiLSTM) RNN (Hochreiter and Schmidhuber, 1997) to encode a sentence.", 
        "47": "For sentence wi:\nfi = forward-LSTM1(wi)\nbi = backward-LSTM1(wi)\nwhere fi and bi are hidden vector sequences.", 
        "48": "We add the forward and backward vectors at each step to obtain vectors hi, then average to obtain sentence representation Si:\nhi = fi + bi Si = 1\n|wi|\n|wi|\u2211\nj=1\nh (j) i (1)\nWe define this function from word sequence wi to sentence representation Si by ENCWORDS(wi).", 
        "49": "3.1.2 Adding Attention  Attention mechanisms (Bahdanau et al., 2015; Mnih et al., 2014) have yielded considerable performance gains for machine comprehension (Hermann et al., 2015; Sukhbaatar et al., 2015; Chen et al., 2016), parsing (Vinyals et al., 2015), and machine translation (Luong et al., 2015).", 
        "50": "After generating the representation e = S5 = ENCWORDS(w5) for candidate ending w5, we use it to compute the attention over the individual hidden vectors of each sentence to compute modified sentence representations S\u2020i .", 
        "51": "That is:\n\u03b1 (j) i = e >Mh(j)i \u03b2 (j) i \u221d exp{\u03b1 (j) i }\nS\u2020i = |wi|\u2211\nj=1\n\u03b2 (j) i h (j) i (2)\nwhere h(j)i is the jth entry of hi and M is a bilinear attention matrix.1 Figure 1 shows this architecture.", 
        "52": "We define this attention-augmented encoder as ATTENCWORDS(wi, e).", 
        "53": "3.1.3 Encoding Sentence Sequences  We use another BiLSTM to encode the sequence S of sentence representations Si:\nF = forward-LSTM2(S)\nB = backward-LSTM2(S)\nENCSENTS(S) = F-1 +B-1\nwhere F-1 is the final hidden vector in F .", 
        "54": "We also use this encoder to encode the ending e by treating it as a sequence containing only one element.", 
        "55": "3.2 Model Variations  Given our encoders, we now define the final representations D for our modeling variations, combining each of HIER and FLAT with each of ENCSTORY and ENCPLOTEND:\nwk1 = \u3008w1, ...,wk\u22121,wk\u3009 Sk1 = \u3008S1, ...,Sk\u3009 DFLATS = ENCWORDS(w51) Si = ENCWORDS(wi)\nDFLATPE = \u3008ENCWORDS(w41),S5\u3009 DHIERS = ENCSENTS(S51) DHIERPE = \u3008ENCSENTS(S41), ENCSENTS(S5)\u3009\nWhen using attention, we replace ENCWORDS above with ATTENCWORDS.", 
        "56": "After encoding the story as D, we use a feedforward network to act as a score function that takes D as input and generates a one-dimensional (scalar) output.", 
        "57": "We use tanh as the activation function on each layer of the feed-forward network and tune the numbers of hidden layers and the layer widths.", 
        "58": "3.3 Training  Since we are training on the validation set which contains both correct and incorrect endings, we minimize the following hinge loss:\nL = max(0,\u2212score(D+) + score(D\u2212) + \u03b4)\nwhere D+ is the representation of the correct story, D\u2212 is the representation of the incorrect story, and \u03b4 = 1 is the margin.", 
        "59": "1In preliminary experiments we found bilinear attention to work better than attention based on cosine similarity.", 
        "60": "4 Experimental Setup  We shuffle and split the validation set into 5 folds and do 5-fold cross validation.", 
        "61": "For modeling decisions, we tune based on the average accuracy of the held-out folds.", 
        "62": "For final experiments, we choose the fold with the best held-out accuracy and report its test set accuracy.", 
        "63": "We use Adam (Kingma and Ba, 2015) for optimization with learning rate 0.001 and mini-batch size 50.", 
        "64": "We use pretrained 300-dimensional GloVe embeddings trained on Wikipedia and Gigaword (Pennington et al., 2014) and keep them fixed during training.", 
        "65": "We use L2 regularization for the score feed-forward network, which has a single hidden layer of size 512.", 
        "66": "We use 300 for the LSTM hidden vector dimensionality for both encoders.", 
        "67": "5 Results  Modeling Decisions.", 
        "68": "We first evaluate our modeling decisions, using the averaged held-out fold accuracy as our model selection criterion.", 
        "69": "Table 1 shows results when comparing FLAT/HIER and ENCSTORY/ENCPLOTEND.", 
        "70": "Hierarchical modeling helps especially with ENCPLOTEND.", 
        "71": "Table 2 shows the contribution of attention when using HIER.", 
        "72": "Attention helps when separately encoding the plot and ending, but not when encoding the entire story.", 
        "73": "We suspect this is because when we use ENCSTORY, the higher BiLSTM processes the sequence \u3008S\u20201,S\u20202,S\u20203,S\u20204,S5\u3009.", 
        "74": "That is, the first four sentence representations are in a different space from the ending due to the use of attention.", 
        "75": "Final Results.", 
        "76": "Table 3 shows final results.", 
        "77": "We report the best result from Mostafazadeh et al.", 
        "78": "(2016), the best result from the concurrently-held LSDSem shared task (Schwartz et al., 2017b), and our final system configuration (with decisions tuned via cross validation as shown in Tables 1-2, then using the model with the best held-out fold accuracy).", 
        "79": "Our model achieves 74.7%, which is close to the state of the art result of 75.2%.2\nWe also report the results of stripping away the plots and running our system on just the endings (\u201cending only\u201d).", 
        "80": "We use the FLAT BiLSTM model on the ending followed by the feed-forward scoring function, using the same loss as above for training.", 
        "81": "We again use 5-fold cross validation\n2We also tried to train the DSSM on the validation set, but were unable to approach the performance of our model.", 
        "82": "The DSSM appears to benefit greatly from the training set.", 
        "83": "on the validation set and choose the model with the highest held-out fold accuracy.", 
        "84": "We achieve 72.5%, matching the similar ending-only result of Schwartz et al.", 
        "85": "(2017b).", 
        "86": "We estimate human performance in the ending-only setting to be 78%.", 
        "87": "We provide more details in Section 6.1.", 
        "88": "These results suggest that the dataset contains systematic biases in the composition of its endings and that any meaningful system for the task must outperform the best ending-only baseline.", 
        "89": "We also report the results of two n-gram language model baselines.", 
        "90": "We estimated trigram models using KenLM (Heafield, 2011) from two different datasets: (1) the entire training stories, and (2) only the endings from the training stories.", 
        "91": "Using only the endings works better, even though it uses one fifth of the data; this further shows the importance of focusing on endings for this task.", 
        "92": "6 Analysis  We analyze the attention weights in our final model.", 
        "93": "Figure 2 shows the distribution of attention weights over position bins, aggregated over the plot sentences in the test set.", 
        "94": "We find that the attentions generated by the correct ending show higher weight for words early in the sentences, while the attentions for incorrect endings are higher at the ends of the sentences.", 
        "95": "We also study the ending-only task to uncover the different kinds of bias that lead to high accuracies in this setting.", 
        "96": "We consider automatic features that can be computed on the endings and evaluate the accuracy of relying solely upon each feature as a classification rule.", 
        "97": "We then compute correlations between our ending-only model and each feature.", 
        "98": "In addition to the trigram model described above, we consider the following rules:\n\u2022 sentiment: choose ending with higher predicted sentiment score from the Stanford sentiment an-\nalyzer (Socher et al., 2013).", 
        "99": "\u2022 negation: choose ending with fewer words from {not, neither, nor, never, n\u2019t, no, rarely}.", 
        "100": "\u2022 length: choose the longer ending.", 
        "101": "Table 4 shows the results.", 
        "102": "Each rule yields accuracy at least 53%, with the sentiment rule nearing 59%.", 
        "103": "Even though the negation rule is only applicable in 20% of cases, its bias is strong enough to yield 5% improvement over the random baseline.", 
        "104": "These results show several reasons why an endingonly model can perform well, and suggests that our model may be identifying positive sentiment, due to its correlation of 0.214 with that feature.", 
        "105": "We counted words in the correct and incorrect endings and in Table 5 we show some that differ between the top-50 lists for each category.", 
        "106": "E.g., \u201cnever\u201d appears among the top 50 words in incorrect endings but not correct endings.", 
        "107": "The word count differences are accordant with the results from the sentiment and negation word rules, with non-overlapping words showing significant sentiment difference and that correct endings are more neutral or positive than incorrect ones.", 
        "108": "6.1 Human Ending-Only Performance  In order to assess human performance, we randomly chose 100 ending pairs from the validation set and gave them to a human annotator, a native speaker of English who is familiar with the ROC task.", 
        "109": "The annotator was asked to select the more likely ending based only on the two endings provided.", 
        "110": "He was correct on 78, observing several kinds of cues in the endings alone in addition to those mentioned above.", 
        "111": "In some cases, one ending sentence is simply much more likely than the other based on world knowledge.", 
        "112": "For example, the ending \u201cthe glasses fixed his headaches immediately\u201d is much more likely than \u201cthe optometrist gave him comfortable sneakers\u201d.", 
        "113": "It is possible that the plot could change the preferred ending to the second, but this appears to be rare in the ROC dataset.", 
        "114": "In another example, \u201cI practice all the time now\u201d is more likely than \u201cI hope I drop the batons\u201d because it seems unlikely that anyone would ever hope to drop batons in the surmised world of the story.", 
        "115": "While these instances still test for a kind of \u201ccommonsense\u201d or \u201cworld\u201d knowledge, they do not require the plot to answer.", 
        "116": "7 Conclusions and Future Work  Our models use none of the ROC training data but achieve strong performance, even when discarding the story plots.", 
        "117": "We uncovered several sources of bias in the endings that make the ending-only task solvable with greater than 70% accuracy.", 
        "118": "Our results suggest that any meaningful system for the ROC story cloze task should perform better than the best ending-only system.", 
        "119": "In future work, we will experiment with additional modeling choices, including adding attention to the higher BiLSTM and adding a decoder and a multi-task objective during training to improve stability.", 
        "120": "Acknowledgments  We acknowledge Zhongtian Dai for his assistance and expertise and we thank Yejin Choi, Nasrin Mostafazadeh, Michael Roth, Roy Schwartz, and the anonymous reviewers for valuable discussions and insights."
    }, 
    "document_id": "P17-2097.pdf.json"
}
