{
    "abstract_sentences": {
        "1": "Connections between relations in relation extraction, which we call class ties, are common.", 
        "2": "In distantly supervised scenario, one entity tuple may have multiple relation facts.", 
        "3": "Exploiting class ties between relations of one entity tuple will be promising for distantly supervised relation extraction.", 
        "4": "However, previous models are not effective or ignore to model this property.", 
        "5": "In this work, to effectively leverage class ties, we propose to make joint relation extraction with a unified model that integrates convolutional neural network (CNN) with a general pairwise ranking framework, in which three novel ranking loss functions are introduced.", 
        "6": "Additionally, an effective method is presented to relieve the severe class imbalance problem from NR (not relation) for model training.", 
        "7": "Experiments on a widely used dataset show that leveraging class ties will enhance extraction and demonstrate the effectiveness of our model to learn class ties.", 
        "8": "Our model outperforms the baselines significantly, achieving stateof-the-art performance."
    }, 
    "body_sentences": {
        "1": "  Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 1810\u20131820 Vancouver, Canada, July 30 - August 4, 2017. c\u00a92017 Association for Computational Linguistics\nhttps://doi.org/10.18653/v1/P17-1166  1 Introduction  Relation extraction (RE) aims to classify the relations between two given named entities from natural-language text.", 
        "2": "Supervised machine learning methods require numerous labeled data to work well.", 
        "3": "With the rapid growth of volume of relation types, traditional methods can not keep up with the step for the limitation of labeled data.", 
        "4": "In order to narrow down the gap of data sparsity, Mintz et al.", 
        "5": "(2009) propose distant supervision (DS) for relation extraction, which automati-\n\u2217 Corresponding author.", 
        "6": "cally generates training data by aligning a knowledge facts database (ie.", 
        "7": "Freebase (Bollacker et al., 2008)) with texts.", 
        "8": "Class ties mean the connections between relations in relation extraction.", 
        "9": "In general, we conclude that class ties can have two types: weak class ties and strong class ties.", 
        "10": "Weak class ties mainly involve the co-occurrence of relations such as place of birth and place lived, CEO of and founder of.", 
        "11": "On the contrary, strong class ties mean that relations have latent logical entailments.", 
        "12": "Take the two relations of capital of and city of for example, if one entity tuple has the relation of capital of, it must express the relation fact of city of, because the two relations have the entailment of capital of \u21d2 city of.", 
        "13": "Obviously the opposite induction is not correct.", 
        "14": "Further take the sentence of \u201cJonbenet told me that her mother [Patsy Ramsey]e1 never left [Atlanta]e2 since she was born.\u201d in DS scenario for example.", 
        "15": "This sentence expresses two relation facts which are place of birth and place lived.", 
        "16": "However, the word \u201cborn\u201d is a strong bios to extract place of birth, so it may not be easy to predict the relation of place lived, but if we can incorporate the weak ties between the two relations, extracting place of birth will provide evidence for prediction of place lived.", 
        "17": "Exploiting class ties is necessary for DS based relation extraction.", 
        "18": "In DS scenario, there is a challenge that one entity tuple can have multiple rela-\n1810\ntion facts as shown in Table 1, which is called relation overlapping (Hoffmann et al., 2011; Surdeanu et al., 2012).", 
        "19": "However, the relations of one entity tuple can have class ties mentioned above which can be leveraged to enhance relation extraction for it narrowing down potential searching spaces and reducing uncertainties between relations when predicting unknown relations.", 
        "20": "If one pair entities has CEO of, it will contain founder of with high possibility.", 
        "21": "To exploit class ties between relations, we propose to make joint extraction for all positive labels of one entity tuple with considering pairwise connections between positive and negative labels inspired by (Fu\u0308rnkranz et al., 2008; Zhang and Zhou, 2006).", 
        "22": "As the two relations with class ties shown in Table 1, by joint extraction of two relations, we can maintain the class ties (co-occurrence) of them from training samples to be learned by potential model, and then leverage this learned information to extract instances with unknown relations, which can not be achieved by separated extraction for it dividing labels apart losing information of cooccurrence.", 
        "23": "To classify positive labels from negative ones, we adopt pairwise ranking to rank positive ones higher than negative ones, exploiting pairwise connections between them.", 
        "24": "In a word, joint extraction exploits class ties between relations and pairwise ranking classify positive labels from negative ones.", 
        "25": "Furthermore, combining information across sentences will be more appropriate for joint extraction which provides more information from other sentences to extract each relation (Zheng et al., 2016; Lin et al., 2016).", 
        "26": "In Table 1, sentence #1 is the evidence for place of birth, but it also expresses the meaning of \u201cliving in someplace\u201d, so it can be aggregated with sentence #2 to extract place lived.", 
        "27": "Meanwhile, the word of \u201chometown\u201d in sentence #2 can provide evidence for place of birth which should be combined with sentence #1 to extract place of birth.", 
        "28": "In this work, we propose a unified model that integrates pairwise ranking with CNN to exploit class ties.", 
        "29": "Inspired by the effectiveness of deep learning for modeling sentences (LeCun et al., 2015), we use CNN to encode sentences.", 
        "30": "Similar to (Santos et al., 2015; Lin et al., 2016), we use class embeddings to represent relation classes.", 
        "31": "The whole model architecture is presented in Figure 1.", 
        "32": "We first use CNN to embed sentences, then we introduce two variant methods to combine the\nembedded sentences into one bag representation vector aiming to aggregate information across sentences, after that we measure the similarity between bag representation and relation class in realvalued space.", 
        "33": "With two variants for combining sentences, three novel pairwise ranking loss functions are proposed to make joint extraction.", 
        "34": "Besides, to relieve the bad impact of class imbalance from NR (not relation) (Japkowicz and Stephen, 2002) for training our model, we cut down loss propagation from NR class during training.", 
        "35": "Our experimental results on dataset of Riedel et al.", 
        "36": "(2010) are evident that: (1) Our model is much more effective than the baselines; (2) Leveraging class ties will enhance relation extraction and our model is efficient to learn class ties by joint extraction; (3) A much better model can be trained after relieving class imbalance from NR.", 
        "37": "Our contributions in this paper can be encapsulated as follows: \u2022 We propose to leverage class ties to enhance relation extraction.", 
        "38": "An effective deep ranking model which integrates CNN and pairwise ranking framework is introduced to exploit class ties.", 
        "39": "\u2022 We propose an effective method to relieve the impact of data imbalance from NR for model training.", 
        "40": "\u2022 Our method achieves state-of-the-art performance.", 
        "41": "2 Related Work  We summarize related works on two main aspects:  2.1 Distant Supervision Relation Extraction  Previous works on DS based RE ignore or are not effective to leverage class ties between rela-\ntions.", 
        "42": "Riedel et al.", 
        "43": "(2010) introduce multi-instance learning to relieve the wrong labelling problem, ignoring class ties.", 
        "44": "Afterwards, Hoffmann et al.", 
        "45": "(2011) and Surdeanu et al.", 
        "46": "(2012) model this problem by multi-instance multi-label learning to extract overlapping relations.", 
        "47": "Though they also propose to make joint extraction of relations, they only use information from single sentence losing information from other sentences.", 
        "48": "Han and Sun (2016) try to use Markov logic model to capture consistency between relation labels, on the contrary, our model leverages deep ranking to learn class ties automatically.", 
        "49": "With the remarkable success of deep learning in CV and NLP (LeCun et al., 2015), deep learning has been applied to relation extraction (Zeng et al., 2014, 2015; Santos et al., 2015; Lin et al., 2016), the specific deep learning architecture can be CNN (Zeng et al., 2014), RNN (Zhou et al., 2016), etc.", 
        "50": "Zeng et al.", 
        "51": "(2015) propose a piecewise convolutional neural network with multi-instance learning for DS based relation extraction, which improves the precision and recall significantly.", 
        "52": "Afterwards, Lin et al.", 
        "53": "(2016) introduce the mechanism of attention (Luong et al., 2015; Bahdanau et al., 2014) to select the sentences to relieve the wrong labelling problem and use all the information across sentences.", 
        "54": "However, the two deep learning based models only make separated extraction thus can not model class ties between relations.", 
        "55": "2.2 Deep Learning to Rank  Deep learning to rank has been widely used in many problems to serve as a classification model.", 
        "56": "In image retrieval, Zhao et al.", 
        "57": "(2015) apply deep semantic ranking for multi-label image retrieval.", 
        "58": "In text matching, Severyn and Moschitti (2015) adopt learning to rank combined with deep CNN for short text pairs matching.", 
        "59": "In traditional supervised relation extraction, Santos et al.", 
        "60": "(2015) design a pairwise loss function based on CNN for single label relation extraction.", 
        "61": "Based on the advantage of deep learning to rank, we propose pairwise learning to rank (LTR) (Liu, 2009) combined with CNN in our model aiming to jointly extract multiple relations.", 
        "62": "3 Proposed Model  In this section, we first conclude the notations used in this paper, then we introduce the used\nCNN for sentence embedding, afterwards, we present our algorithm of how to learn class ties between relations of one entity tuple.", 
        "63": "3.1 Notation  We define the relation classes as L = {1, 2, \u00b7 \u00b7 \u00b7 , C}, entity tuples as T = {ti}Mi=1 and mentions1 as X = {xi}Ni=1.", 
        "64": "Dataset is constructed as follows: for entity tuple ti \u2208 T and its relation class set Li \u2286 L, we collect all the mentions Xi that contain ti, the dataset we use is D = {(ti, Li, Xi)}Hi=1.", 
        "65": "Given a data (tk, Lk, Xk) \u2208 {(ti, Li, Xi)}Hi=1, the sentence embeddings of Xk encoded by CNN are defined as Sk = {si}|Xk|i=1 and we use class embeddingsW \u2208 R|L|\u00d7d to represent the relation classes.", 
        "66": "3.2 CNN for Sentence Embedding  We take the effective CNN architecture adopted from (Zeng et al., 2015; Lin et al., 2016) to encode sentence and we briefly introduce CNN in this section.", 
        "67": "More details of our CNN can be obtained from previous work.", 
        "68": "3.2.1 Words Representations  \u2022 Word Embedding Given a word embedding matrix V \u2208 Rlw\u00d7d1 where lw is the size of word dictionary and d1 is the dimension of word embedding, the words of a mention x = {w1, w2, \u00b7 \u00b7 \u00b7 , wn} will be represented by realvalued vectors from V .", 
        "69": "\u2022 Position Embedding The position embedding of a word measures the distance from the word to entities in a mention.", 
        "70": "We add position embeddings into words representations by appending position embedding to word embedding for every word.", 
        "71": "Given a position embedding matrix P \u2208 Rlp\u00d7d2 where lp is the number of distances and d2 is the dimension of position embeddings, the dimension of words representations becomes dw = d1 + d2 \u00d7 2.", 
        "72": "3.2.2 Convolution, Piecewise max-pooling  After transforming words in x to real-valued vectors, we get the sentence q \u2208 Rn\u00d7dw .", 
        "73": "The set of kernels K is {Ki}dsi=1 where ds is the number of kernels.", 
        "74": "Define the window size as dwin and given one kernel Kk \u2208 Rd\nwin\u00d7dw , the convolution operation is defined as follows:\nm[i] = q[i:i+dwin\u22121] Kk + b[k] (1) 1The sentence containing one certain entity is called men-\ntion.", 
        "75": "where m is the vector after conducting convolution along q for n \u2212 dwin + 1 times and b \u2208 Rds is the bias vector.", 
        "76": "For these vectors whose indexes out of range of [1, n], we replace them with zero vectors.", 
        "77": "By piecewise max-pooling, when pooling, the sentence is divided into three parts: m[p0:p1], m[p1:p2] andm[p2:p3] (p1 and p2 are the positions of entities, p0 is the beginning of sentence and p3 is the end of sentence).", 
        "78": "This piecewise max-pooling is defined as follows:\nz[j] = max(m[pj\u22121:pj ]) (2)\nwhere z \u2208 R3 is the result of mention x processed by kernel Kk; 1 \u2264 j \u2264 3.", 
        "79": "Given the set of kernels K, following the above steps, the mention x can be embedded to o where o \u2208 Rds\u22173.", 
        "80": "3.2.3 Non-Linear Layer, Regularization  To learn high-level features of mentions, we apply a non-linear layer after pooling layer.", 
        "81": "After that, a dropout layer is applied to prevent overfitting.", 
        "82": "We define the final fixed sentence representation as s \u2208 Rdf (df = ds \u2217 3).", 
        "83": "s = g(o) \u25e6 h (3)\nwhere g(\u00b7) is a non-linear function and we use tanh(\u00b7) in this paper; h is a Bernoulli random vector with probability p to be 1.", 
        "84": "3.3 Learning Class Ties by Joint Extraction with Pairwise Ranking  As mentioned above, to learn class ties, we propose to make joint extraction with considering pairwise connections between positive labels and negative ones.", 
        "85": "Pairwise ranking is applied to achieve this goal.", 
        "86": "Besides, combining information across sentences is necessary for joint extraction.", 
        "87": "More specifically, as shown in Figure 2, from down to top, all information from sentences is pre-propagated to provide enough information for joint extraction.", 
        "88": "From top to down, pairwise ranking jointly extracting positive relations by combining losses, which are back-propagated to CNN to learn class ties.", 
        "89": "3.3.1 Combining Information across Sentences  We propose two options to combine sentences to provide enough information for joint extraction.", 
        "90": "\u2022 AVE The first option is average method.", 
        "91": "This method regards all the sentences equally and directly average the values in all dimensions of sentence embedding.", 
        "92": "This AVE function is defined as follows:\ns = 1\nn\n\u2211\nsi\u2208Sk si (4)\nwhere n is the number of sentences and s is the representation vector combining all sentence embeddings.", 
        "93": "Because it weights the importance of sentences equally, this method may bring much noise data from two aspects: (1) the wrong labelling data; (2) irrelated mentions for one relation class, for all sentences containing the same entity tuple being combined together to construct the bag representation.", 
        "94": "\u2022 ATT The second one is a sentence-level attention algorithm used by Lin et al.", 
        "95": "(2016) to measure the importance of sentences aiming to relieve the wrong labelling problem.", 
        "96": "For every sentence, ATT will calculate a weight by comparing the sentence to one relation.", 
        "97": "We first calculate the similarity between one sentence embedding and relation class as follows:\nej = a \u00b7W[c] \u00b7 sj (5)\nwhere ej is the similarity between sentence embedding sj and relation class c and a is a bias factor.", 
        "98": "In this paper, we set a as 0.5.", 
        "99": "Then we apply Softmax to rescale e (e = {ei}|Xk|i=1 ) to [0, 1].", 
        "100": "We get the weight \u03b1j for sj as follows:\n\u03b1j = exp(ej)\u2211 ei\u2208e exp(ei)\n(6)\nso the function to merge s with ATT is as follows:\ns =\n|Xk|\u2211\ni=1\n\u03b1i \u00b7 si (7)  3.3.2 Joint Extraction by Combining Losses to Learn Class Ties  Firstly, we have to present the score function to measure the similarity between s and relation c. \u2022 Score Function We use dot function to produce score for s to be predicted as relation c. The score function is as follows:\nF(s, c) =W[c] \u00b7 s (8)\nThere are other options for score function.", 
        "101": "In Wang et al.", 
        "102": "(2016), they propose a margin based loss function that measures the similarity between s and W[c] by distance.", 
        "103": "Because score function is not an important issue in our model, we adopt dot function, also used by Santos et al.", 
        "104": "(2015) and Lin et al.", 
        "105": "(2016), as our score function.", 
        "106": "Now we start to introduce the ranking loss function.", 
        "107": "Pairwise ranking aims to learn the score function F(s, c) that ranks positive classes higher than negative ones.", 
        "108": "This goal can be summarized as follows:\n\u2200c+ \u2208 Lk, \u2200c\u2212 \u2208 L\u2212Lk : F(s, c+) > F(s, c\u2212)+\u03b2 (9) where \u03b2 is a margin factor which controls the minimum margin between the positive scores and negative scores.", 
        "109": "To learn class ties between relations, we extend the formula (9) to make joint extraction and we propose three ranking loss functions with variants of combining sentences.", 
        "110": "Followings are the proposed loss functions: \u2022 with AVE (Variant-1) We define the marginbased loss function with option of AVE to aggregate sentences as follows:\nG[ave] = \u2211\nc+\u2208Lk \u03c1[0, \u03c3+ \u2212F(s, c+)]+\n+\u03c1|Lk|[0, \u03c3\u2212 + F(s, c\u2212)]+ (10)\nwhere [0, \u00b7 ]+ = max(0, \u00b7 ); \u03c1 is the rescale factor, \u03c3+ is positive margin and \u03c3\u2212 is negative margin.", 
        "111": "Similar to Santos et al.", 
        "112": "(2015) and Wang et al.", 
        "113": "(2016), this loss function is designed to rank positive classes higher than negative ones controlled by the margin of \u03c3+ \u2212 \u03c3\u2212.", 
        "114": "In reality, F(s, c+) will be higher than \u03c3+ and F(s, c\u2212) will be lower\nthan \u03c3\u2212.", 
        "115": "In our work, we set \u03c1 as 2, \u03c3+ as 2.5 and \u03c3\u2212 as 0.5 adopted from Santos et al.", 
        "116": "(2015).", 
        "117": "Similar to Weston et al.", 
        "118": "(2011) and Santos et al.", 
        "119": "(2015), we update one negative class at every training round but to balance the loss between positive classes and negative ones, we multiply |Lk| before the right term in function (10) to expand the negative loss.", 
        "120": "We apply mini-bach based stochastic gradient descent (SGD) to minimize the loss function.", 
        "121": "The negative class is chosen as the one with highest score among all negative classes (Santos et al., 2015), i.e.", 
        "122": ":\nc\u2212 = argmax c\u2208L\u2212Lk F(s, c) (11)\n\u2022 with ATT (Variant-2) Now we define the loss function for the option of ATT to combine sentences as follows:\nG[att] = \u2211\nc+\u2208Lk (\u03c1[0, \u03c3+ \u2212F(sc+ , c+)]+\n+\u03c1[0, \u03c3\u2212 + F(sc+ , c\u2212)]+) (12)\nwhere sc means the attention weights of representation s are merged by comparing sentence embeddings with relation class c and c\u2212 is chosen by the following function:\nc\u2212 = argmax c\u2208L\u2212Lk F(sc+ , c) (13)\nwhich means we update one negative class in every training round.", 
        "123": "We keep the values of \u03c1, \u03c3+ and \u03c3\u2212 same as values in function (10).", 
        "124": "According to this loss function, we can see that: for each class c+ \u2208 Lk, it will capture the most related information from sentences to merge sc + , then rank F(sc+ , c+) higher than all negative scores which each is F(sc+ , c\u2212) (c\u2212 \u2208 L \u2212 Lk).", 
        "125": "We use the same update algorithm to minimize this loss.", 
        "126": "\u2022 Extended with ATT (Variant-3) According to function (12), for each c+, we only select one negative class to update the parameters, which only considers the connections between positive classes and negative ones, ignoring connections between positive classes, so we extend function (12) to better exploit class ties by considering the connections between positive classes.", 
        "127": "We give out the extended loss function as follows:\nG[Exatt] = \u2211 c\u2217\u2208Lk ( \u2211 c+\u2208Lk \u03c1[0, \u03c3+ \u2212F(sc\u2217 , c+)]+\n+\u03c1[0, \u03c3\u2212 + F(sc\u2217 , c\u2212)]+) (14)\nSimilar to function (13), we select c\u2212 as follows:\nc\u2212 = argmax c\u2208L\u2212Lk F(sc\u2217 , c) (15)\nand we use the same method to update this loss function as discussed above.", 
        "128": "From the function (14), we can see that: for c\u2217 \u2208 Lk, after merging the bag representation s with c\u2217, we share s with all the other positive classes and update the class embeddings of other positive classes with s, in this way, the connections between positive classes can be captured and learned by our model.", 
        "129": "In loss function (10), (12) and (14), we combine losses from all positive labels to make joint extraction to capture the class ties among relations.", 
        "130": "Suppose we make separated extraction, the losses from positive labels will be divided apart and will not get enough information of connections between positive labels, comparing to joint extraction.", 
        "131": "Connections between positive labels and negative ones are exploited by controlling margins: \u03c3+ and \u03c3\u2212.", 
        "132": "3.4 Relieving Impact of NR  In relation extraction, the dataset will always contain certain negative samples which do not express relations classified as NR (not relation).", 
        "133": "Table 2 presents the proportion of NR samples in SemEval-2010 Task 8 dataset2 (Erk and Strapparava, 2010) and dataset from Riedel et al.", 
        "134": "(2010), which shows almost data is about NR in the latter dataset.", 
        "135": "Data imbalance will severely affect the model training and cause the model only sensitive to classes with high proportion (He and Garcia, 2009).", 
        "136": "In order to relieve the impact of NR in DS based relation extraction, we cut the propagation of loss from NR, which means if relation c is NR, we set its loss as 0.", 
        "137": "Our method is similar to Santos et al.", 
        "138": "(2015) with slight variance.", 
        "139": "Santos et al.", 
        "140": "(2015) directly omit the NR class embedding, but we keep it.", 
        "141": "If we use ATT method to combine information across sentences, we can not omit NR class\n2This is a dataset for relation extraction in traditional supervision framework.", 
        "142": "Algorithm 1: Merging loss function of Variant-3 input : L, (tk, Lk, Xk) and Sk; output: G[Exatt];\n1 G[Exatt] \u2190 0; 2 for c\u2217 \u2208 Lk do 3 Merge representation sc \u2217 by function (5), (6), (7); 4 for c+ \u2208 Lk do 5 if c+ is not NR then 6 G[Exatt] \u2190 G[Exatt] + \u03c1[0, \u03c3+ \u2212\nF(sc\u2217 , c+)]+;\n7 c\u2212 \u2190 argmaxc\u2208L\u2212Lk F(sc \u2217 , c); 8 G[Exatt] \u2190 G[Exatt] + \u03c1[0, \u03c3\n\u2212 + F(sc\u2217 , c\u2212)]+; 9 return G[Exatt];\nembedding according to function (6) and (7), on the contrary, it will be updated from the negative classes\u2019 loss.", 
        "143": "In Algorithm 1, we give out the pseudocodes of merging loss with Variant-3 and considering to relieve the impact of NR.", 
        "144": "4 Experiments    4.1 Dataset and Evaluation Criteria  We conduct our experiments on a widely used dataset, developed by Riedel et al.", 
        "145": "(2010) and has been used by Hoffmann et al.", 
        "146": "(2011), Surdeanu et al.", 
        "147": "(2012), Zeng et al.", 
        "148": "(2015) and Lin et al.", 
        "149": "(2016).", 
        "150": "The dataset aligns Freebase relation facts with the New York Times corpus, in which training mentions are from 2005-2006 corpus and test mentions from 2007.", 
        "151": "Following Mintz et al.", 
        "152": "(2009), we adopt heldout evaluation framework in all experiments.", 
        "153": "Aggregated precision/recall curves are drawn and precision@N (P@N) is reported to illustrate the model performance.", 
        "154": "4.2 Experimental Settings  Word Embeddings.", 
        "155": "We use a word2vec tool that is gensim3 to train word embeddings on NYT corpus.", 
        "156": "Similar to Lin et al.", 
        "157": "(2016), we keep the words that appear more than 100 times to construct word dictionary and use \u201cUNK\u201d to represent the other ones.", 
        "158": "3http://radimrehurek.com/gensim/models/word2vec.html\nHyper-parameter Settings.", 
        "159": "Three-fold validation on the training dataset is adopted to tune the parameters following Surdeanu et al.", 
        "160": "(2012).", 
        "161": "We use grid search to determine the optimal hyperparameters.", 
        "162": "We select word embedding size from {50, 100, 150, 200, 250, 300}.", 
        "163": "Batch size is tuned from {80, 160, 320, 640}.", 
        "164": "We determine learning rate among {0.01, 0.02, 0.03, 0.04}.", 
        "165": "The window size of convolution is tuned from {1, 3, 5}.", 
        "166": "We keep other hyper-parameters same as Zeng et al.", 
        "167": "(2015): the number of kernels is 230, position embedding size is 5 and dropout rate is 0.5.", 
        "168": "Table 3 shows the detailed parameter settings.", 
        "169": "4.3 Comparisons with Baselines  Baseline.", 
        "170": "We compare our model with the following baselines: \u2022 Mintz (Mintz et al., 2009) the original distantly supervised model.", 
        "171": "\u2022 MultiR (Hoffmann et al., 2011) a multiinstance learning based graphical model which aims to address overlapping relation problem.", 
        "172": "\u2022 MIML (Surdeanu et al., 2012) also solving overlapping relations in a multi-instance multilabel framework.", 
        "173": "\u2022 PCNN+ATT (Lin et al., 2016) the state-ofthe-art model in dataset of Riedel et al.", 
        "174": "(2010) which applies ATT to combine the sentences.", 
        "175": "Results and Discussion.", 
        "176": "We compare our three variants of loss functions with the baselines and the results are shown in Figure 3.", 
        "177": "From the results we can see that: (1) Rank + AVE (Variant1) achieves comparable results with PCNN+ATT; (2) Rank + ATT (Variant-2) and Rank + ExATT (Variant-3) significantly outperform PCNN + ATT with much higher precision and slightly higher recall in whole view; (3) Rank + ExATT (Variant-3) exhibits the best performances comparing with all the other methods including PCNN + ATT, Rank + AVE and Rank + ATT.", 
        "178": "4.4 Impact of Joint Extraction and Class Ties  In this section, we conduct experiments to reveal the effectiveness of our model to learn class ties with three variant loss functions mentioned above, and the impact of class ties for relation extraction.", 
        "179": "As mentioned above, we make joint extraction to learn class ties, so to achieve the goal of this set of experiments, we compare joint extraction with separated extraction.", 
        "180": "To make separated extraction, we divide the labels of entity tuple into single label and for one relation label we only select the sentences expressing this relation, then we use this dataset to train our model with the three variant loss functions.", 
        "181": "We conduct experiments with Rank + AVE (Variant-1), Rank + ATT (Variant-2) and Rank + ExATT (Variant3) relieving impact of NR.", 
        "182": "Aggregated P/R curves are drawn and precisions@N (100, 200, \u00b7 \u00b7 \u00b7 , 500) are reported to show the model performances.", 
        "183": "Experimental results are shown in Figure 4 and Table 4.", 
        "184": "From the results we can see that: (1) For Rank + ATT and Rank + ExATT, joint extraction exhibits better performance than separated extraction, which demonstrates class ties will improve relation extraction and the two methods are effective to learn class ties; (2) For Rank + AVE, surprisingly joint extraction does not keep up with separated extraction.", 
        "185": "For the second phenomenon, the explanation may lie in the AVE method to aggregate sentences will incorporate noise data consistent with the finding in Lin et al.", 
        "186": "(2016).", 
        "187": "When make joint extraction, we will combine all sentences containing the same entity tuple no matter which class type is expressed, so it will engender much noise if we only combine them equally.", 
        "188": "4.5 Comparisons of Variant Joint Extractions  To make joint extraction, we have proposed three variant loss functions including Rank + AVE, Rank + ATT and Rank + ExATT in the above discussion and Figure 3 shows that the three variants achieve different performances.", 
        "189": "In this experiment, we aim to compare the three variants in detail.", 
        "190": "We conduct the experiments with the three variants under the setting of relieving im-\npact of NR and joint extraction.", 
        "191": "We draw the P/R curves and report the top N (100, 200, \u00b7 \u00b7 \u00b7 , 500) precisions to compare model performance with the three variants.", 
        "192": "From the results as shown in Figure 5 and Table 5 we can see that: (1) Comparing Rank + AVE with Rank + ATT, from the whole view, they can achieve the similar maximal recall point, but Rank + ATT exhibits higher precision in all range of recall; (2) Comparing Rank + ATT with Rank + ExATT, Rank + ExATT achieves much better performance with broader range of recall and higher precision in almost range of recall.", 
        "193": "4.6 Impact of NR Relation  The goal of this experiment is to inspect how much relation of NR can affect the model performance.", 
        "194": "We use Rank + AVE, Rank + ATT, Rank + ExATT under the setting of relieving impact of NR or not to conduct experiments.", 
        "195": "We draw the aggregated P/R curves as shown in Figure 6, from which we can see that after relieving the impact of NR, the model performance can be improved significantly.", 
        "196": "Then we further evaluate the impact of NR for convergence behavior of our model in model train-\ning.", 
        "197": "Also with the three variant loss functions, in each iteration, we record the maximal value of Fmeasure 4 to represent the model performance at current epoch.", 
        "198": "Model parameters are tuned for 15 times and the convergence curves are shown in Figure 7.", 
        "199": "From the result, we can find out: \u201c+NR\u201d converges quicker than \u201c-NR\u201d and arrives to the final score at the around 11 or 12 epoch.", 
        "200": "In general, \u201c-NR\u201d converges more smoothly and will achieve better performance than \u201c+NR\u201d in the end.", 
        "201": "4.7 Case Study  Joint vs. Sep.", 
        "202": "Extraction (Class Ties).", 
        "203": "We randomly select an entity tuple (Cuyahoga County, Cleveland) from test set to see its scores for every relation class with the method of Rank + ATT under the setting of relieving impact of NR with joint extraction and separated extraction.", 
        "204": "This entity tuple have two relations: /location/./county seat and /location/./contains, which derive from the same root class and they have weak class ties for they all relating to topic of \u201clocation\u201d.", 
        "205": "We rescale the scores by adding value 10.", 
        "206": "The results are shown in Figure 8, from which we can see that: under joint extraction setting, the two gold relations have the highest scores among the other relations but under separated extraction setting, only /location/./contains can be distinguished from the negative relations, which demonstrates that joint extraction is better than separated extraction by capturing the class ties between relations.", 
        "207": "4F = 2 \u2217 P \u2217R/(P +R)  5 Conclusion and Future Works  In this paper, we leverage class ties to enhance relation extraction by joint extraction using pairwise ranking combined with CNN.", 
        "208": "An effective method is proposed to relieve the impact of NR for model training.", 
        "209": "Experimental results on a widely used dataset show that leveraging class ties will enhance relation extraction and our model is effective to learn class ties.", 
        "210": "Our method significantly outperforms the baselines.", 
        "211": "In the future, we will focus on two aspects: (1) Our method in this paper considers pairwise intersections between labels, so to better exploit class ties, we will extend our method to exploit all other labels\u2019 influences on each relation for relation extraction, transferring second-order to high-order (Zhang and Zhou, 2014); (2) We will focus on other problems by leveraging class ties between labels, specially on multi-label learning problems (Zhou et al., 2012) such as multi-category text categorization (Rousu et al., 2005) and multi-label image categorization (Zha et al., 2008).", 
        "212": "Acknowledgments  Firstly, we would like to thank Xianpei Han and Kang Liu for their valuable suggestions on the initial version of this paper, which have helped a lot to improve the paper.", 
        "213": "Secondly, we also want to express gratitudes to the anonymous reviewers for their hard work and kind comments, which will further improve our work in the future.", 
        "214": "This work was supported by the National High-tech Research and Development Program (863 Program) (No.", 
        "215": "2014AA015105) and National Natural Science Foundation of China (No.", 
        "216": "61602490)."
    }, 
    "document_id": "P17-1166.pdf.json"
}
