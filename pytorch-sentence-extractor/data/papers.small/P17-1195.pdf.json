{
    "abstract_sentences": {
        "1": "We have been developing an end-to-end math problem solving system that accepts natural language input.", 
        "2": "The current paper focuses on how we analyze the problem sentences to produce logical forms.", 
        "3": "We chose a hybrid approach combining a shallow syntactic analyzer and a manuallydeveloped lexicalized grammar.", 
        "4": "A feature of the grammar is that it is extensively typed on the basis of a formal ontology for pre-university math.", 
        "5": "These types are helpful in semantic disambiguation inside and across sentences.", 
        "6": "Experimental results show that the hybrid system produces a well-formed logical form with 88% precision and 56% recall."
    }, 
    "body_sentences": {
        "1": "  Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 2131\u20132141 Vancouver, Canada, July 30 - August 4, 2017. c\u00a92017 Association for Computational Linguistics\nhttps://doi.org/10.18653/v1/P17-1195  1 Introduction  Frege and Russell, the initiators of the mathematical logic, delved also into the exploration of a theory of natural language semantics (Frege, 1892; Russell, 1905).", 
        "2": "Since then, symbolic logic has been a fundamental tool and a source of inspiration in the study of language meaning.", 
        "3": "It suggests that the formalization of the two realms, mathematical reasoning and language meaning, is actually the two sides of the same coin \u2013 probably, we could not even conceive the idea of formalizing language meaning without grounding it onto mathematical reasoning.", 
        "4": "This point was first clarified by Tarski (1936; 1944) mainly on formal languages and then extended to natural languages by Davidson (1967).", 
        "5": "Montague (1970a; 1970b; 1973) further embodied it by putting forward a terrifyingly arrogant and attractive idea of seeing a natural language as a formal language.", 
        "6": "The automation of end-to-end math problem solving thus has an outstanding status in the re-\nsearch themes in natural language processing.", 
        "7": "The conceptual basis has been laid down, which connects text to the truth (= answer) through reasoning.", 
        "8": "However, we have not seen a fully automated system that instantiates it end-to-end.", 
        "9": "We wish to add a piece to the big picture by materializing it.", 
        "10": "Past studies have mainly targeted at primary school level arithmetic word problems (Bobrow, 1964; Charniak, 1969; Kushman et al., 2014; Hosseini et al., 2014; Shi et al., 2015; Roy and Roth, 2015; Zhou et al., 2015; Koncel-Kedziorski et al., 2015; Mitra and Baral, 2016; Upadhyay et al., 2016).", 
        "11": "In their nature, arithmetic questions are quantifier-free.", 
        "12": "Moreover they tend to include only \u2227 (and) as the logical connective.", 
        "13": "The main challenge in these works was to extract simple numerical relations (most typically equations) from a real-world scenario described in a text.", 
        "14": "Seo et al.", 
        "15": "(2015) took SAT geometry questions as their benchmark.", 
        "16": "However, the nature of SAT geometry questions restricts the resulting formula\u2019s complexity.", 
        "17": "In \u00a73, we will show that none of them includes \u2200 (for all), \u2228 (or) or\u2192 (implies).", 
        "18": "It suggests that this type of questions require little need to analyze the logical structure of the problems beyond conjunctions of predicates.", 
        "19": "2131\nWe take pre-university math problems falling in the theory of real-closed fields (RCF) as our benchmark because of their variety and complexity.", 
        "20": "The subject areas include real and linear algebra, complex numbers, calculus, and geometry.", 
        "21": "Furthermore, many problems involve more than one subject: e.g., algebraic curves and calculus as in Fig.", 
        "22": "1.", 
        "23": "Their logical forms include all the logical connectives, quantifiers, and \u03bb-abstraction.", 
        "24": "Our goal is to recognize the complex logical structures precisely, including the scopes of the quantifiers and other logical operators.", 
        "25": "In the rest of the paper, we first present an overview of an end-to-end problem solving system (\u00a72) and analyze the complexity of the preuniversity math benchmark in comparison with others (\u00a73).", 
        "26": "Among the modules in the end-to-end system, we focus on the sentence-level semantic parsing component and describe an extensivelytyped grammar (\u00a74 and \u00a75), an analyzer for the math expressions in the text (\u00a76), and two semantic parsing techniques to fight against the scarcity of the training data (\u00a77) and the complexity of the domain (\u00a78).", 
        "27": "Experimental results show the effectiveness of the presented techniques as well as the complexity of the task through an in-depth analysis of the end-to-end problem solving results (\u00a79).", 
        "28": "2 End-to-end Math Problem Solving  Fig.", 
        "29": "2 presents an overview of our end-to-end math problem solving system.", 
        "30": "A math problem text is firstly analyzed with a dependency parser.", 
        "31": "Anaphoric and coreferential expressions in the text are then identified and their antecedents are determined.", 
        "32": "We assume the math formulas in the problems are encoded in MathML presentation mark-up.", 
        "33": "A specialized parser processes each one of them to determine its syntactic category and semantic content.", 
        "34": "The semantic representation of each sentence is determined by a semantic parser based on Combinatory Categorial Grammar (CCG) (Steedman, 2001, 2012).", 
        "35": "The output from the CCG parser is a ranked list of sentence-level logical forms for each sentence.", 
        "36": "After the sentence-level processing steps, we determine the logical relations among the sentence-level logical forms (discourse parsing) by a simple rule-based system.", 
        "37": "It produces a tree structure whose leaves are labeled with sentences and internal nodes with logical connectives.", 
        "38": "Free variables in the logical form are then bound by some quantifiers (or kept free) and their scopes are determined according to the logical structure of the problem.", 
        "39": "A semantic representation of a problem is obtained as a formula in a higher-order logic through these language analysis steps.", 
        "40": "The logical representation is then rewritten using a set of axioms that define the meanings of the predicate and function symbols in the formula, such as maximum defined as follows:\nmaximum(x, S)\u2194 x \u2208 S \u2227 \u2200y(y \u2208 S \u2192 y \u2264 x), as well as several logical rules such as \u03b2reduction.", 
        "41": "We hope to obtain a representation of the initial problem expressed in a decidable math theory such as RCF through these equivalencepreserving rewriting.", 
        "42": "Once we find such a formula, we invoke a computer algebra system (CAS) or an automatic theorem prover (ATP) to derive the answer.", 
        "43": "The reasoning module (i.e., the formula rewriting and the deduction with CAS and ATP) of the system has been extensively tested on a large collection of manually formalized pre-university math problems that includes more than 1,500 problems.", 
        "44": "It solves 70% of the them in the time limit of 10 minutes per problem.", 
        "45": "Table 1 shows the rate of successfully solved problems in the manually formalized version of the benchmark problems used in the current paper.", 
        "46": "3 Profile of the Benchmark Data  Our benchmark problems, UNIV, were collected from the past entrance exams of seven top-ranked universities in Japan.", 
        "47": "In the exams held in odd numbered years from 1999 to 2013, we exhaustively selected the problems which are ultimately expressible in RCF.", 
        "48": "They occupied 40% of all the problems.", 
        "49": "We divided the problems into two sets: DEV for development (those from year 1999 to 2005) and TEST for test (those from year 2007 to 2013).", 
        "50": "DEV was used for the lexicon development and the tuning of the end-to-end system.", 
        "51": "The problem texts (both in English and Japanese) with MathML mark-up and manually translated logical forms are publicly available at https: //github.com/torobomath.", 
        "52": "The manually translated logical forms were formulated in a higher-order semantic language introduced later in the paper.", 
        "53": "The translation was done as faithfully as possible to the original wordings of the problems.", 
        "54": "They thus keep the inherent logical structures expressed in natural language.", 
        "55": "Table 2 lists several statistics of the UNIV problems in the English version and their manual formalization.", 
        "56": "For comparison, the statistics of three other benchmarks are also listed.", 
        "57": "JOBS and GEOQUERY are collections of natural language queries against databases.", 
        "58": "They have been widely used as\nbenchmarks for semantic parsing (e.g., Tang and Mooney, 2001; Zettlemoyer and Collins, 2005, 2007; Kwiatkowski et al., 2010, 2011; Liang et al., 2011).", 
        "59": "The queries are annotated with logical forms in Prolog.", 
        "60": "We converted them to equivalent higher-order formulas to collect comparable statistics.", 
        "61": "GEOMETRY is a collection of SAT geometry questions compiled by Seo et al.", 
        "62": "(2015).", 
        "63": "We formalized the GEOMETRY questions1 in our semantic language in the same way as UNIV.", 
        "64": "In Table 2, the first column lists the number of problems.", 
        "65": "The next three provide statistics of the problem texts: average number of words and sentences in a problem (\u2018Avg.", 
        "66": "tokens\u2019 and \u2018Avg.", 
        "67": "sents\u2019), and the number of unique words in the whole dataset.2 They reveal that the sentences in UNIV are significantly longer than the others and more than three sentences have to be correctly processed for a problem.", 
        "68": "The remaining columns provide the statistics about the logical complexities of the problems.", 
        "69": "\u2018Atoms\u2019 stands for the average number of the occurrences of predicates per problem.", 
        "70": "The next three columns list the number of variables bound by \u2203, \u2200, and \u03bb.", 
        "71": "We count sequential occurrences of the same binder as one.", 
        "72": "The columns for \u2227, \u2228, \u00ac, and \u2192 list the average number of them per problem.3 We can see UNIV includes a wider variety of quantifiers and connectives than the others.", 
        "73": "The final column lists the numbers of unique \u2018sketches\u2019 of the logical forms in the dataset.", 
        "74": "What\n1Including all conditions expressed in the diagrams.", 
        "75": "2 All the math formulas in the texts were replaced with a special token \u201cMATH\u201d before counting words.", 
        "76": "3 \u2227 and \u2228 was counted as operators with arbitrary arity.", 
        "77": "E.g., there is only one \u2227 in A \u2227B \u2227 C.\nwe call \u2018sketch\u2019 here is a signature that encodes the overall structure of a logical form.", 
        "78": "Table 3 shows the top four most frequent sketches observed in the datasets.", 
        "79": "In a sketch, P stands for a (conjunction of) predicate(s) and f stands for a term.", 
        "80": "\u2203, \u2200, and \u03bb stand for (immediately nested sequence of) the binders.", 
        "81": "To obtain the sketch of a formula \u03c6, we first replace all the predicate symbols in \u03c6 to P and function symbols and constants to f .", 
        "82": "We then eliminate all variables in \u03c6 and \u2018flatten\u2019 it by applying the following rewriting rules to the sub-formulas in \u03c6 in the bottom-up order:\nf(..., f(\u03b11, \u03b12, ..., \u03b1n), ...)\u21d2 f(..., \u03b11, \u03b12, ..., \u03b1n, ...) P (..., f(\u03b11, \u03b12, ..., \u03b1n), ...)\u21d2 P (..., \u03b11, \u03b12, ..., \u03b1n, ...)\n\u03b1 \u2228 \u03b1 \u2228 \u03b2 \u21d2 \u03b1 \u2228 \u03b2, \u03b1 \u2227 \u03b1\u21d2 \u03b1 \u2203\u2203\u03c8 \u21d2 \u2203\u03c8, \u2200\u2200\u03c8 \u21d2 \u2200\u03c8, \u03bb\u03bb\u03c8 \u21d2 \u03bb\u03c8\nFinally, we sort the arguments of P s and fs and remove the duplicates among them.", 
        "83": "For instance, to obtain the sketch of the following formula:\n\u2200k\u2200m (\nmaximum(m, set(\u03bbe.", 
        "84": "(e < k))) \u2192 k \u2212 1 \u2264 m \u2227m < k\n) ,\nwe replace the predicate/function symbols as in:\n\u2200k\u2200m (\nP (m, f(\u03bbe.P (e, k))) \u2192 P (f(k, f),m) \u2227 P (m, k)\n) ,\nand then eliminate the variables to have:\n\u2200\u2200(P (f(\u03bbP ))\u2192 P (f(f)) \u2227 P ),\nand finally flatten it to:\n\u2200(P (\u03bbP )\u2192 P ).", 
        "85": "Table 3 shows that a wide variety of structures are found in UNIV while other data sets are dominated by a small number of structures.", 
        "86": "Table 4 presents some of less frequent sketches found in UNIV (DEV).", 
        "87": "In actuality, 67% of the unique sketches found in UNIV (DEV) occur only once in the dataset.", 
        "88": "These statistics suggest that the distribution of the logical structures found in UNIV, and math text in general, is very long-tailed.", 
        "89": "4 A Type System for Pre-university Math  Our semantic language is a higher-order logic (lambda calculus) with parametric polymorphism.", 
        "90": "Table 5 presents the types in the language.", 
        "91": "The atomic types are defined so that they capture the selectional restriction of verbs and other\nargument-taking phrases as precisely as possible.", 
        "92": "For instance, an equation in real domain, e.g., x2 \u2212 1 = 0, can be regarded as a set of reals, i.e., {x | x2 \u2212 1 = 0}.", 
        "93": "However, we never say \u2018a solution of a set.\u2019 We thus discriminate an equation from a set in the type system even though the concept of equation is mathematically dispensable.", 
        "94": "Entities of equation and set are built by constructor functions that take a higher-order term as the argument as in eqn(\u03bbx.x2 \u2212 1) and set(\u03bbx.x2 \u2212 1).", 
        "95": "Related concepts such as \u2018solution\u2019 and \u2018element\u2019 are defined by the axioms for corresponding function and predicate symbols:\n\u2200f\u2200x(solution(x, eqn(f))\u2194 fx) \u2200s\u2200x(element(x, set(s))\u2194 sx).", 
        "96": "Distinction of cardinal numbers (Card) and ordinal numbers (Ord), and the introduction of \u2018integer division\u2019 type (QuoRem) are also linguistically motivated.", 
        "97": "The former is necessary to capture the difference between, e.g., \u2018kth integer in n1, n2, .", 
        "98": ".", 
        "99": ".", 
        "100": ", nm\u2019 and \u2018k integers in n1, n2, .", 
        "101": ".", 
        "102": ".", 
        "103": ", nm.\u2019 An object of type QuoRem is conceptually a pair of integers that represent the quotient and the remainder of integer division.", 
        "104": "It is linguistically distinct from the type of Pair(Z,Z) because, e.g., in\nSelect a pair of integers (n,m) and divide n by m. If the remainder (of \u03c6) is zero, ...\nthe null (i.e., omitted) pronoun \u03c6 has \u2018the result of division n/m\u2019 as its antecedent but not (n,m).", 
        "105": "Polymorphism is a mandatory part of the language.", 
        "106": "Especially, the semantics of plural noun\nphrases is expressed by polymorphic lists and tuples: e.g., \u2018the radii of the circles C1, C2, and C3\u2019 is of type ListOf(R) and \u2018the function f and its maximum value\u2019 is of type Pair(R2R,R).", 
        "107": "5 Lexicon and Grammar    5.1 Combinatory Categorial Grammar  An instance of CCG grammar consists of a lexicon and a small number of combinatory rules.", 
        "108": "A lexicon is a set of lexical items, each of which associates a word surface form with a syntactic category and a semantic function: e.g.,\nsum :: NP/PP : \u03bbx.sum of(x)\nintersects :: S\\NP/PP : \u03bby.\u03bbx.intersect(x, y) A syntactic category is one of atomic categories, such as NP, PP, and S, or a complex category in the form of X/Y or X\\Y, where X and Y are syntactic categories.", 
        "109": "The syntactic categories and the semantic functions of constituents are combined by applying combinatory rules.", 
        "110": "The most fundamental rules are forward (>) and backward (<) application:\n> X/Y : f Y : x\nX : fx < Y : x X\\Y : f X : fx\nThe atomic categories are further classified by features such as num(ber) and case of noun phrases.", 
        "111": "In the current paper, the features are written as in NP[num=pl,case=acc].", 
        "112": "5.2 A Japanese CCG Grammar and Lexicon  We developed a Japanese CCG following the analysis of basic constructions by Bekki (2010) but significantly extending it by covering various phenomena related to copula verbs, action verbs, argument-taking nouns, appositions and so forth.", 
        "113": "The semantic functions are defined in the format of a higher-order version of dynamic predicate logic (Eijck and Stokhof, 2006).", 
        "114": "The dynamic property is necessary to analyze semantic phenomena related to quantifications, such as donkey anaphora.", 
        "115": "In the following examples, we use English instead of Japanese and the standard notation of higher-order logic for the sake of readability.", 
        "116": "We added two atomic categories, Sn and Sa, to the commonly used S, NP, and N. Category Sn is assigned to a proposition expressed as a math formula, such as \u2018x > 0\u2019.", 
        "117": "Semantically it is of type Bool but syntactically it behaves both like a noun phrase and a sentence.", 
        "118": "Category Sa is assigned to a sentence where the main verb is an action verb such as add and rotate.", 
        "119": "Such a sentence introduces the result of the action as a discourse entity (i.e., what can be an antecedent of coreferential expressions).", 
        "120": "The action verbs can also mediate quantification as in:\nWhen any k\u2208K is divided by m, the quotient is 3.", 
        "121": "\u2200k(k \u2208 K \u2192 quo of(quorem(k,m)) = 3)\nwhere quorem(k,m) represents the result of the division (i.e., the pair of the quotient and the remainder) and quo of is a function that extracts the quotient from it.", 
        "122": "To handle such phenomena, we posit the semantic type of Sa as Pair(\u03b1, Bool) where the two components respectively bring the result of an action and the condition on it (including quantification).", 
        "123": "Fig.", 
        "124": "3 presents a derivation tree for the above example.4\nThe atomic category NP, N, and Sa in our grammar have type feature.", 
        "125": "Its value is one of the types defined in the semantic language or a type variable when the entity type is underspecified.", 
        "126": "The lexical entry for \u2018(an integer) divides (an integer)\u2019 and \u2018(a set) includes (an element)\u2019 would thus have the following categories (other features than type are not shown):\ndivides :: S\\NP[type=Z]/NP[type=Z] includes :: S\\NP[type=SetOf(\u03b1)]/NP[type=\u03b1]\nWhen defining a lexical item, we don\u2019t have to explicitly specify the type features in most cases.", 
        "127": "They can be usually inferred from the definition of\n4 In Fig.", 
        "128": "3, the semantic part is in the dynamic logic format as in our real grammar where the dynamic binding (\u2203x;\u03c6) \u2192 \u03c8 is interpreted as \u2200x(\u03c6 \u2192 \u03c8) in the standard predicate logic.", 
        "129": "Following our analysis of an analogous construction in Japanese, the null pronoun after \u2018the quotient\u2019 is filled by analysing the second clause as including a gap rather than filling it by zero-pronoun resolution.", 
        "130": "the semantic function.", 
        "131": "In the above example, divides will have \u03bby.\u03bbx.", 
        "132": "(x|y) and includes will have \u03bby.\u03bbx.", 
        "133": "(y \u2208 x) as their semantic functions.", 
        "134": "For both cases, the type feature of the NP arguments can be determined from the type definitions of the operators | and \u2208 in the ontology.", 
        "135": "The lexicon currently includes 54,902 lexical items for 8,316 distinct surface forms, in which 5,094 lexical items for 1,287 surface forms are for function words and functional multi-word expressions.", 
        "136": "The number of unique categories in the lexicon is 10,635.", 
        "137": "When the type features are ignored, there are still 4,026 distinct categories.", 
        "138": "6 Math Expression Analysis  The meaning of a math expression is composed with the semantic functions of surrounding words to produce a logical form.", 
        "139": "We dynamically generate lexical items for each math expression in a problem.", 
        "140": "Consider the following sentence including two \u2018equations\u2019:\nIf a2\u22124=0, then x2+ax+1=0 has a real solution.", 
        "141": "The latter, x2+ax+1 = 0, should receive a lexical item of a noun phrase, NP : eqn(\u03bbx.x2 + a + 1), but the former, a2\u22124 = 0, should receive category S since it denotes a proposition.", 
        "142": "Such disambiguation is not always possible without semantic analysis of the text.", 
        "143": "We thus generate more than one lexical item for ambiguous expressions and let the semantic parser make a choice.", 
        "144": "To generate the lexical items, we first collect appositions to the math expressions, such as \u2018integer n and m\u2019 and \u2018equation x2 + a = 0,\u2019 and use them as the type constraints on the variables and the compound expressions.", 
        "145": "Compound expressions are then parsed with an operator precedence parser (Aho et al., 2006).", 
        "146": "Overloaded operators, such as + for numbers and vectors, are resolved using the type constrains whenever possible.", 
        "147": "Finally, we generate all possible interpretations of the expressions and select appropriate syntactic categories.", 
        "148": "We have seen only three categories of math expressions: NP, Sn, and T/(T\\NP).", 
        "149": "The last one is used for a NP with post-modification, as in:\n>\nn > 0\nT/(T\\NP ) : \u03bbP.", 
        "150": "(n > 0 \u2227 P (n))\nis an even number\nS\\NP : \u03bbx.", 
        "151": "(even(x))\nS : n > 0 \u2227 even(n)  7 Two-step Semantic Parsing  Two central issues in parsing are the cost of the search and the accuracy of disambiguation.", 
        "152": "Supervised learning is commonly used to solve both.", 
        "153": "It is however very costly to create the training data by manually annotating a large number of sentences with CCG trees.", 
        "154": "Past studies have tried to bypass it by so-called weak supervision, where a parser is trained only with the logical form (e.g., Kwiatkowski et al.", 
        "155": "2011) or even only with the answers to the queries (e.g., Liang et al.", 
        "156": "2011).", 
        "157": "Although the adaptation of such methods to the pre-university math data is an interesting future direction, we developed yet another approach based on a hybrid of shallow dependency parsing and the detailed CCG grammar.", 
        "158": "The syntactic structure of Japanese sentences has traditionally been analyzed based on the relations among word chunks called bunsetsus.", 
        "159": "A bunsetsu consists of one or more content words followed by zero or more function words.", 
        "160": "The dependencies among bunsetsus mostly correspond to the predicate-argument and interclausal dependencies (Fig.", 
        "161": "4).", 
        "162": "The dependency structure hence matches the overall structure of a CCG tree only leaving the details unspecified.", 
        "163": "We derive a full CCG-tree by using a bunsetsu dependency tree as a constraint.", 
        "164": "We assume: (i) the fringe of each sub-tree in the dependency tree has a corresponding node in the CCG tree.", 
        "165": "We call such a node in the CCG tree \u2018a matching node.\u2019 We further assume: (ii) a matching node is combined with another CCG tree node whose span includes at least one word in the head bunsetsu of the matching node.", 
        "166": "Fig.", 
        "167": "5 presents an example of a sentence consisting of four bunsetsus (rounded squares), each of which contains two words.", 
        "168": "In the figure, the i-th cell in the k-th row from the bottom is the CKY cell for the span from i-th to\n(i+k-1)-th words.", 
        "169": "Under the two assumptions, we only need to fill the hatched cells given the dependency structure shown below the CKY chart.", 
        "170": "The hatched cells with a white circle indicate the positions of the matching nodes.", 
        "171": "Even under the constraint of a dependency tree, it is impractical to do exhaustive search.", 
        "172": "We use beam search based on a simple score function on the chart items that combines several features such as the number of atomic categories in the item.", 
        "173": "We also use N -best dependency trees to circumvent the dependency errors.", 
        "174": "The restricted CKY parsing is repeated on the N -best dependency trees until a CCG tree is obtained.", 
        "175": "Our hope is to reject a dependency error as violation of the syntactic and semantic constraints encoded in the CCG lexicon.", 
        "176": "In the experiment, we used a Japanese dependency parser developed by Kudo and Matsumoto (2002).", 
        "177": "We modified it to produce N -best outputs and used up to 20-best trees per sentence.", 
        "178": "8 Global Type Coherency  The well-typedness of the logical form is usually guaranteed by the combinatory rules.", 
        "179": "However, they do not always guarantee the type coherency among the interpretations of the math expressions.", 
        "180": "For instance, consider the following derivation:\n>\nif x+ y \u2208 U, S/S : \u03bbP.", 
        "181": "(addR(x, y) \u2208 U \u2192 P ) then x+ z \u2208 V. S : addV(x, y) \u2208 V\nS : addR(x, y) \u2208 U \u2192 addV(x, z) \u2208 V\nThe + symbol is interpreted as the addition of real numbers (addR) in the first clause but that of vectors (addV) in the second one.", 
        "182": "The logical form is not typable because the two occurrences of xmust have different types.", 
        "183": "The forward application rule does not reject this derivation since the categories of the two clauses perfectly match the rule schema.", 
        "184": "We can reject such inconsistency by doing type checking on the logical form at every step of the\nAlgorithm 1 Global type coherence check procedure PARSEPROBLEM\nEnvs\u2190 \u2205; AllDerivs\u2190 [] for each sentence s in the problem do\nChart\u2190 INITIALIZECKYCHART(s, Envs) Derivs\u2190 TWOSTEPPARSING(s, Chart) Envs\u2190 UPDATEENVIRONMENTS(Envs, Derivs) AllDerivs\u2190 AllDerivs \u2295 [Derivs]\nreturn AllDerivs\n// s: a sentence; Envs: a set of environments procedure INITIALIZECKYCHART(s, Envs)\nChart\u2190 empty CKY chart for each token t in s do\nfor each lexical item C : f for t do // C: category, f : semantic function if t is a math expression then\nfor each environment \u0393 \u2208 Envs do if \u0393 is unifiable with FV(f ) then\nadd (C,\u0393 t FV(f)) to Chart else // t is a normal word\nadd (C, \u2205) to Chart return Chart\nFV(f ): the environment that maps the free variables in a semantic function f to their principal types determined by type inference on f .", 
        "185": "// Envs: a set of environments; Derivs: derivations trees procedure UPDATEENVIRONMENTS(Envs, Derivs)\nNewEnvs\u2190 \u2205 // environments for the next sentence for each derivation d \u2208 Derivs do\n\u0393\u2190 the environment at the root of d if \u0393 6= \u2205 then // update the environments\nNewEnvs\u2190 NewEnvs \u222a{\u0393} else // no update: there was no math expression\nNewEnvs\u2190 NewEnvs \u222a Envs // eliminate those subsumed by other environments return MOSTGENERALENVIRONMENTS(NewEnvs)\nderivation.", 
        "186": "It is however quite time consuming because we cannot use dynamic programming any more and need to do type checking on numerous chart items.", 
        "187": "Furthermore, such type inconsistency may happen across sentences.", 
        "188": "Instead, we consider the type environment while parsing.", 
        "189": "A type environment, written as {v1 : T1, v2 : T2, .", 
        "190": ".", 
        "191": ".", 
        "192": "}, is a finite function from variables to type expressions.", 
        "193": "A pair v : T means that the variable v must be of type T or its instance (e.g., SetOf(R) is an instance of SetOf(\u03b1)).", 
        "194": "For example, the logical form of the first clause of the above sentence is typable under {x :R, y :R, z :\u03b1,U :SetOf(R), V :\u03b2}, but that of the second clause isn\u2019t.", 
        "195": "Please refer, e.g., to (Pierce, 2002) for the formal definitions.", 
        "196": "Two environments \u03931 and \u03932 are unifiable iff there exists a substitution \u03c3 that maps the type variables in \u03931 and \u03932 to some type expressions so that \u03931\u03c3 = \u03932\u03c3 holds.", 
        "197": "We write \u03931 t \u03932 for the result of such substitution (i.e., unification) with the\nmost general \u03c3 (most general unifier, mgu).", 
        "198": "We associate a type environment with each chart item and refine it through parsing.", 
        "199": "The type constraints implied in a discourse are accumulated in the environment and block the generation of incoherent derivations (Algorithm 1).", 
        "200": "Fig.", 
        "201": "6 presents an example of a parsing result, in which the type constraints implied in the two clauses are unified at the root and the type of U is determined.", 
        "202": "When we apply a combinatory rule, we first check if the environments of the child chart items are unifiable.", 
        "203": "If so, we put the unified environment in the parent item and apply the unifier to the type features in the parent category.", 
        "204": "For instance, the forward application rule is revised as follows:\n(X/Y,\u03931) + (Y,\u03932)\u2192 (X\u03c3,\u03931 t \u03932), where \u03c3 is the mgu of \u03931 and \u03932 and X\u03c3 means\nthe application of \u03c3 to the type features in X .5\n5 To be precise, we also consider the type constraints induced through the unification of the categories.", 
        "205": "It can be seen in the derivation step for \u201cn divides 12\u201d in Fig.", 
        "206": "6, where the new constraint n :Z is induced by the unification of NP[\u03b1] and NP[Z] and merged into the environment of the parent.", 
        "207": "9 Experiments and Analysis  This section presents the overall performance of the current end-to-end system and demonstrates the effectiveness of the proposed parsing techniques.", 
        "208": "We also present an analysis of the failures.", 
        "209": "Table 6 presents the result of end-to-end problem solving on the UNIV data.", 
        "210": "It shows the failure in the semantic parsing is a major bottleneck in the current system.", 
        "211": "Since a problem in UNIV includes more than three sentences on average, parsing a whole problem is quite a high bar for a semantic parser.", 
        "212": "It is however necessary to solve it by the nature of the task.", 
        "213": "Once a problem-level logical form was produced, the system yielded a correct solution for 44% of such problems in DEV and 36% in TEST.", 
        "214": "Table 7 lists the fraction of the sentences on which the two-step parser produced a CCG tree within top-N dependency trees.", 
        "215": "We compared the results obtained with the dependency parser trained only on a news corpus (News) (Kurohashi and Nagao, 2003), which is annotated with bunsetsu level dependencies, and that trained additionally with a math problem corpus consisting of 6,000 sentences6 (News+Math).", 
        "216": "The math problem corpus was developed according to the same annotation guideline for the news corpus.", 
        "217": "The attachment accuracy of the dependency parser was 84% on math problem text when trained only on the news corpus but improved to 94% by the addition of the math problem corpus.", 
        "218": "The performance gain by increasing N is more evident in the results with the News parser than that with the News+Math parser.", 
        "219": "It suggests the grammar properly rejected wrong dependency trees, which were ranked higher by the News parser.", 
        "220": "The effect of the additional training is very large at small Ns and still significant at N = 20.", 
        "221": "It means that we successfully boosted both the speed and the success rate of CCG parsing only with the shallow dependency annotation on in-domain data.", 
        "222": "6 No overlap with DEV and TEST sections of UNIV.", 
        "223": "Table 8 shows the effect of CCG parsing with type environments.", 
        "224": "The column headed \u2018Typing failure\u2019 is the fraction of the problems on which no logical form was obtained due to typing failure.", 
        "225": "Parsing with type environment eliminated almost all such failures and significantly improved the number of correct answers.", 
        "226": "The remaining type failure was due to beam thresholding where a necessary derivation fell out of the beam.", 
        "227": "Table 9 lists the reasons for the parse failures on 1/4 of the TEST section (the problems taken from exams on 2007).", 
        "228": "In the table, \u201cunknown usage\u201d means a missing lexical item for a word already in the lexicon.", 
        "229": "\u201cUnknown word\u201d means no lexical item was defined for the word.", 
        "230": "Collecting unknown usages (especially that of a function word) is much harder than just compiling a list of words.", 
        "231": "Our experience in the lexicon development tells us that once we find a usage example, in the large majority of the cases, it is not difficult to write down its syntactic category and semantic function.", 
        "232": "Table 9 suggests that we can efficiently detect and collect unknown word usages through parsing failures on a large raw corpus of math problems.", 
        "233": "Table 10 presents the accuracy of the sentenceand problem-level logical forms produced on the year 1999 subset of DEV and the year 2007 subset of TEST.", 
        "234": "Although the recall on the unseen test data is not as high as we hope, the high precision of the sentence-level logical forms is encouraging.", 
        "235": "Table 11 provides the counts of the error types found in the wrong sentence-level logical forms produced on DEV-1999 and TEST-2007.", 
        "236": "It reveals the majority of the errors are related to the choice of quantifier (\u2203, \u2200, or free) and logical op-\nerators (e.g., \u2192 vs. \u2194) as well as the determination of their scopes.", 
        "237": "Meanwhile, we did not find an error related to the predicate-argument structure of a logical form.", 
        "238": "This fact and the results in Table 6 suggest that the selectional restrictions, encoded in the lexicon, properly rejected nonsensical predicate-argument relations.", 
        "239": "Our next step is to introduce a more sophisticated disambiguation model on top of the grammar, enjoying the properly confined search space.", 
        "240": "10 Conclusion  We have explained why the task of end-to-end math problem solving matters for a practical theory of natural language semantics and introduced the semantic parsing of pre-university math problems as a novel benchmark.", 
        "241": "The statistics of the benchmark data revealed that it includes far more complex semantic structures than the other benchmarks.", 
        "242": "We also presented an overview of an endto-end problem solving system and described two parsing techniques motivated by the scarcity of the annotated data and the need for the type coherency of the analysis.", 
        "243": "Experimental results demonstrated the effectiveness of the proposed techniques and showed the accuracy of the sentence-level logical form was 88% precision and 56% recall.", 
        "244": "Our future work includes the expansion of the lexicon with the aid of the semantic parser and the development of a disambiguation model for the binding and scoping structures."
    }, 
    "document_id": "P17-1195.pdf.json"
}
