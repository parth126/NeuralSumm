{
    "abstract_sentences": {
        "1": "Two types of data shift common in practice are 1. transferring from synthetic data to live user data (a deployment shift), and 2. transferring from stale data to current data (a temporal shift).", 
        "2": "Both cause a distribution mismatch between training and evaluation, leading to a model that overfits the flawed training data and performs poorly on the test data.", 
        "3": "We propose a solution to this mismatch problem by framing it as domain adaptation, treating the flawed training dataset as a source domain and the evaluation dataset as a target domain.", 
        "4": "To this end, we use and build on several recent advances in neural domain adaptation such as adversarial training (Ganin et al., 2016) and domain separation network (Bousmalis et al., 2016), proposing a new effective adversarial training scheme.", 
        "5": "In both supervised and unsupervised adaptation scenarios, our approach yields clear improvement over strong baselines."
    }, 
    "body_sentences": {
        "1": "  Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 1297\u20131307 Vancouver, Canada, July 30 - August 4, 2017. c\u00a92017 Association for Computational Linguistics\nhttps://doi.org/10.18653/v1/P17-1119  1 Introduction  Spoken language understanding (SLU) systems analyze various aspects of a user query by classifying its domain, intent, and semantic slots.", 
        "2": "For instance, the query how is traffic to target in bellevue has domain PLACES, intent CHECK ROUTE TRAFFIC, and slots PLACE NAME: target and ABSOLUTE LOCATION: bellevue.", 
        "3": "We are interested in addressing two types of data shift common in SLU applications.", 
        "4": "The first data shift problem happens when we transfer from synthetic data to live user data (a deployment shift).", 
        "5": "This is also known as the \u201ccold-start\u201d\nproblem; a model cannot be trained on the real usage data prior to deployment simply because it does not exist.", 
        "6": "A common practice is to generate a large quantity of synthetic training data that mimics the expected user behavior.", 
        "7": "Such synthetic data is crafted using domain-specific knowledge and can be time-consuming.", 
        "8": "It is also flawed in that it typically does not match the live user data generated by actual users; the real queries submitted to these systems are different from what the model designers expect to see.", 
        "9": "The second data shift problem happens when we transfer from stale data to current data (a temporal shift).", 
        "10": "In our use case, we have one set of training data from 2013 and wish to handle data from 2014\u20132016.", 
        "11": "This is problematic since the content of the user queries changes over time (e.g., new restaurant or movie names may be added).", 
        "12": "Consequently, the model performance degrades over time.", 
        "13": "Both shifts cause a distribution mismatch between training and evaluation, leading to a model that overfits the flawed training data and performs poorly on the test data.", 
        "14": "We propose a solution to this mismatch problem by framing it as domain adaptation, treating the flawed training dataset as a source domain and the evaluation dataset as a target domain.", 
        "15": "To this end, we use and build on several recent advances in neural domain adaptation such as adversarial training (Ganin et al., 2016) and domain separation network (Bousmalis et al., 2016), proposing a new adversarial training scheme based on randomized predictions.", 
        "16": "We consider both supervised and unsupervised adaptation scenarios (i.e., absence/presence of labeled data in the target domain).", 
        "17": "We find that unsupervised DA can greatly improve performance without requiring additional annotation.", 
        "18": "Super-\n1297\nvised DA with a small amount of labeled data gives further improvement on top of unsupervised DA.", 
        "19": "In experiments, we show clear gains in both deployment and temporal shifts across 5 test domains, yielding average error reductions of 74.04% and 41.46% for intent classification and 70.33% and 32.0% for slot tagging compared to baselines without adaptation.", 
        "20": "2 Related Work    2.1 Domain Adaptation  Our work builds on the recent success of DA in the neural network framework.", 
        "21": "Notably, Ganin et al.", 
        "22": "(2016) propose an adversarial training method for unsupervised DA.", 
        "23": "They partition the model parameters into two parts: one inducing domainspecific (or private) features and the other domaininvariant (or shared) features.", 
        "24": "The domaininvariant parameters are adversarially trained using a gradient reversal layer to be poor at domain classification; as a consequence, they produce representations that are domain agnostic.", 
        "25": "This approach is motivated by a rich literature on the theory of DA pioneered by Ben-David et al.", 
        "26": "(2007).", 
        "27": "We describe our use of adversarial training in Section 3.2.3.", 
        "28": "A special case of Ganin et al.", 
        "29": "(2016) is developed independently by Kim et al.", 
        "30": "(2016c) who motivate the method as a generalization of the feature augmentation method of Daume\u0301 III (2009).", 
        "31": "Bousmalis et al.", 
        "32": "(2016) extend the framework of Ganin et al.", 
        "33": "(2016) by additionally encouraging the private and shared features to be mutually exclusive.", 
        "34": "This is achieved by minimizing the dot product between the two sets of parameters and simultaneously reconstructing the input (for all domains) from the features induced by these parameters.", 
        "35": "Both Ganin et al.", 
        "36": "(2016) and Bousmalis et al.", 
        "37": "(2016) discuss applications in computer vision.", 
        "38": "Zhang et al.", 
        "39": "(2017) apply the method of Bousmalis et al.", 
        "40": "(2016) to tackle transfer learning in NLP.", 
        "41": "They focus on transfer learning between classification tasks over the same domain (\u201caspect transfer\u201d).", 
        "42": "They assume a set of keywords associated with each aspect and use these keywords to inform the learner of the relevance of each sentence for that aspect.", 
        "43": "2.2 Spoken Language Understanding  Recently, there has been much investment on the personal digital assistant (PDA) technology in in-\ndustry (Sarikaya, 2015; Sarikaya et al., 2016).", 
        "44": "Apples Siri, Google Now, Microsofts Cortana, and Amazons Alexa are some examples of personal digital assistants.", 
        "45": "Spoken language understanding (SLU) is an important component of these examples that allows natural communication between the user and the agent (Tur, 2006; El-Kahky et al., 2014).", 
        "46": "PDAs support a number of scenarios including creating reminders, setting up alarms, note taking, scheduling meetings, finding and consuming entertainment (i.e.", 
        "47": "movie, music, games), finding places of interest and getting driving directions to them (Kim et al., 2016a).", 
        "48": "Naturally, there has been an extensive line of prior studies for domain scaling problems to easily scale to a larger number of domains: pretraining (Kim et al., 2015c), transfer learning (Kim et al., 2015d), constrained decoding with a single model (Kim et al., 2016a), multi-task learning (Jaech et al., 2016), neural domain adaptation (Kim et al., 2016c), domainless adaptation (Kim et al., 2016b), a sequence-to-sequence model (Hakkani-Tu\u0308r et al., 2016), domain attention (Kim et al., 2017) and zero-shot learning(Chen et al., 2016; Ferreira et al., 2015).", 
        "49": "There are also a line of prior works on enhancing model capability and features: jointly modeling intent and slot predictions (Jeong and Lee, 2008; Xu and Sarikaya, 2013; Guo et al., 2014; Zhang and Wang, 2016; Liu and Lane, 2016a,b), modeling SLU models with web search click logs (Li et al., 2009; Kim et al., 2015a) and enhancing features, including representations (Anastasakos et al., 2014; Sarikaya et al., 2014; Celikyilmaz et al., 2016, 2010; Kim et al., 2016d) and lexicon (Liu and Sarikaya, 2014; Kim et al., 2015b).", 
        "50": "All the above works assume that there are no any data shift issues which our work try to solve.", 
        "51": "3 Method    3.1 BiLSTM Encoder  We use an LSTM simply as a mapping \u03c6 : Rd \u00d7 Rd\u2032 \u2192 Rd\u2032 that takes an input vector x and a state vector h to output a new state vector h\u2032 = \u03c6(x, h).", 
        "52": "See Hochreiter and Schmidhuber (1997) for a detailed description.", 
        "53": "Let C denote the set of character types and W the set of word types.", 
        "54": "Let \u2295 denote the vector concatenation operation.", 
        "55": "We encode an utterance using the wildly successful architecture given by bidirectional LSTMs (BiLSTMs) (Schuster and\nPaliwal, 1997; Graves, 2012).", 
        "56": "The model parameters \u0398 associated with this BiLSTM layer are\n\u2022 Character embedding ec \u2208 R25 for each c \u2208 C\n\u2022 Character LSTMs \u03c6Cf , \u03c6Cb : R25\u00d7R25 \u2192 R25\n\u2022 Word embedding ew \u2208 R100 for each w \u2208 W\n\u2022 Word LSTMs \u03c6Wf , \u03c6Wb : R150\u00d7R100 \u2192 R100\nLetw1 .", 
        "57": ".", 
        "58": ".", 
        "59": "wn \u2208 W denote a word sequence where word wi has character wi(j) \u2208 C at position j.", 
        "60": "First, the model computes a character-sensitive word representation vi \u2208 R150 as\nfCj = \u03c6 C f ( ewi(j), f C j\u22121 )\n\u2200j = 1 .", 
        "61": ".", 
        "62": ".", 
        "63": "|wi| bCj = \u03c6 C b ( ewi(j), b C j+1 ) \u2200j = |wi| .", 
        "64": ".", 
        "65": ".", 
        "66": "1 vi = f C |wi| \u2295 b C 1 \u2295 ewi\nfor each i = 1 .", 
        "67": ".", 
        "68": ".", 
        "69": "n.1 Next, the model computes\nfWi = \u03c6 W f ( vi, f W i\u22121 )\n\u2200i = 1 .", 
        "70": ".", 
        "71": ".", 
        "72": "n bWi = \u03c6 W b ( vi, b W i+1 ) \u2200i = n .", 
        "73": ".", 
        "74": ".", 
        "75": "1\nand induces a character- and context-sensitive word representation hi \u2208 R200 as\nhi = f W i \u2295 bWi (1)\nfor each i = 1 .", 
        "76": ".", 
        "77": ".", 
        "78": "n. For convenience, we write the entire operation as a mapping BiLSTM\u0398:\n(h1 .", 
        "79": ".", 
        "80": ".", 
        "81": "hn)\u2190 BiLSTM\u0398(w1 .", 
        "82": ".", 
        "83": ".", 
        "84": "wn)  3.2 Unsupervised DA  In unsupervised domain adaptation, we assume labeled data for the source domain but not the target domain.", 
        "85": "Our approach closely follows the previous work on unsupervised neural domain adaptation by Ganin et al.", 
        "86": "(2016) and Bousmalis et al.", 
        "87": "(2016).", 
        "88": "We have three BiLSTM encoders described in Section 3.1:\n1.", 
        "89": "\u0398src: induces source-specific features\n2.", 
        "90": "\u0398tgt: induces target-specific features\n3.", 
        "91": "\u0398shd: induces domain-invariant features\nWe now define a series of loss functions defined by these encoders.", 
        "92": "1For simplicity, we assume some random initial state vectors such as fC0 and bC|wi|+1 when we describe LSTMs.", 
        "93": "3.2.1 Source Side Tagging Loss  The most obvious objective is to minimize the model\u2019s error on labeled training data for the source domain.", 
        "94": "Let w1 .", 
        "95": ".", 
        "96": ".", 
        "97": "wn \u2208 W be an utterance in the source domain annotated with labels y1 .", 
        "98": ".", 
        "99": ".", 
        "100": "yn \u2208 L. We induce\n(hsrc1 .", 
        "101": ".", 
        "102": ".", 
        "103": "h src n )\u2190 BiLSTM\u0398src(w1 .", 
        "104": ".", 
        "105": ".", 
        "106": "wn)\n(hshd1 .", 
        "107": ".", 
        "108": ".", 
        "109": "h shd n )\u2190 BiLSTM\u0398shd(w1 .", 
        "110": ".", 
        "111": ".", 
        "112": "wn)\nThen we define the probability of tag y \u2208 L for the i-th word as\nzi = W 2 tag tanh ( W 1tagh\u0304i + b 1 tag ) + b2tag\np(y|hi) \u221d exp ([zi]y) where h\u0304i = hsrci \u2295 hshdi and \u0398tag = {W 1tag,W 2tag, b1tag, b2tag} denotes additional feedfoward parameters.", 
        "113": "The tagging loss is given by the negative log likelihood\nLtag (\u0398src,\u0398shd,\u0398tag) = \u2212 \u2211\ni\nlog p ( yi|h\u0304i )\nwhere we iterate over annotated words (wi, yi) on the source side.", 
        "114": "3.2.2 Reconstruction Loss  Following previous works, we ground feature learning by reconstructing encoded utterances.", 
        "115": "Both Bousmalis et al.", 
        "116": "(2016) and Zhang et al.", 
        "117": "(2017) use mean squared errors for reconstruction, the former of image pixels and the latter of words in a context window.", 
        "118": "In contrast, we use an attention-based LSTM that fully re-generates the input utterance and use its log loss.", 
        "119": "More specifically, let w1 .", 
        "120": ".", 
        "121": ".", 
        "122": "wn \u2208 W be an utterance in domain d \u2208 {src, tgt}.", 
        "123": "We first use the relevant encoders as before\n(hd1 .", 
        "124": ".", 
        "125": ".", 
        "126": "h d n)\u2190 BiLSTM\u0398d(w1 .", 
        "127": ".", 
        "128": ".", 
        "129": "wn)\n(hshd1 .", 
        "130": ".", 
        "131": ".", 
        "132": "h shd n )\u2190 BiLSTM\u0398shd(w1 .", 
        "133": ".", 
        "134": ".", 
        "135": "wn)\nThe concatenated vectors h\u0304i = hdi \u2295 hshdi are fed into the standard attention-based decoder (Bahdanau et al., 2014) to define the probability of word w at each position i with state vector \u00b5i\u22121 (where \u00b50 = h\u0304n):\n\u03b1j \u221d exp ( \u00b5>i\u22121h\u0304j ) \u2200j \u2208 {1 .", 
        "136": ".", 
        "137": ".", 
        "138": "n}\nh\u0303i = n\u2211\nj=1\n\u03b1j h\u0304j\n\u00b5i = \u03c6 R(\u00b5i\u22121 \u2295 h\u0303i, \u00b5i\u22121)\np(w|\u00b5i) \u221d exp ( [W 1rec\u00b5i + b 1 rec]w )\nwhere \u0398rec = {\u03c6R,W 1rec, b1rec} denotes additional parameters.", 
        "139": "The reconstruction loss is given by the negative log likelihood\nLrec (\u0398src,\u0398tgt,\u0398shd,\u0398rec) = \u2212 \u2211\ni\nlog p (wi|\u00b5i)\nwhere we iterate over words wi in both the source and target utterances.", 
        "140": "3.2.3 Adversarial Domain Classification Loss  Ganin et al.", 
        "141": "(2016) propose introducing an adversarial loss to make shared features domaininvariant.", 
        "142": "This is motivated by a theoretical result of Ben-David et al.", 
        "143": "(2007) who show that the generalization error on the target domain depends on how \u201cdifferent\u201d the source and the target domains are.", 
        "144": "This difference is approximately measured by\n2 ( 1\u2212 2 inf\n\u0398 error(\u0398)\n) (2)\nwhere error(\u0398) is the domain classification error using model \u0398.", 
        "145": "It is assumed that the source and target domains are balanced so that inf\u0398 error(\u0398) \u2264 1/2 and the difference lies in [0, 2].", 
        "146": "In other words, we want to make error(\u0398) as large as possible in order to generalize well to the target domain.", 
        "147": "The intuition is that the more domain-invariant our features are, the easier it is to benefit from the source side training when testing on the target side.", 
        "148": "It can also be motivated as a regularization term (Ganin et al., 2016).", 
        "149": "Let w1 .", 
        "150": ".", 
        "151": ".", 
        "152": "wn \u2208 W be an utterance in domain d \u2208 {src, tgt}.", 
        "153": "We first use the shared encoder\n(hshd1 .", 
        "154": ".", 
        "155": ".", 
        "156": "h shd n )\u2190 BiLSTM\u0398shd(w1 .", 
        "157": ".", 
        "158": ".", 
        "159": "wn)\nIt is important that we only use the shared encoder for this loss.", 
        "160": "Then we define the probability of domain d for the utterance as\nzi = W 2 adv tanh ( W 1adv n\u2211\ni=1\nhshdi + b 1 adv ) + b2adv\np(d|hi) \u221d exp ([zi]d)\nwhere \u0398adv = {W 1adv,W 2adv, b1adv, b2adv} denotes additional feedfoward parameters.", 
        "161": "The adversarial domain classification loss is given by the positive log likelihood\nLadv (\u0398shd,\u0398adv) = \u2211\ni\nlog p ( d(i)|w(i) )\nwhere we iterate over domain-annotated utterances (w(i), d(i)).", 
        "162": "Random prediction training While past work only consider using a negative gradient (Ganin et al., 2016; Bousmalis et al., 2016) or positive log likelihood (Zhang et al., 2017) to perform adversarial training, it is unclear whether these approaches are optimal for the purpose of \u201cconfusing\u201d the domain predictor.", 
        "163": "For instance, minimizing log likelihood can lead to a model accurately predicting the opposite domain, compromising the goal of inducing domain-invariant representations.", 
        "164": "Thus we propose to instead optimize the shared parameters for random domain predictions.", 
        "165": "Specifically, the above loss is replaced with\nLadv (\u0398shd,\u0398adv) = \u2212 \u2211\ni\nlog p ( d(i)|w(i) )\nwhere d(i) is set to be src with probability 0.5 and tgt with probability 0.5.", 
        "166": "By optimizing for random predictions, we achieve the desired effect: the shared parameters are trained to induce features that cannot discriminate between the source and the target domains.", 
        "167": "3.2.4 Non-Adversarial Domain Classification Loss  In addition to the adversarial loss for domaininvariant parameters, we also introduce a nonadversarial loss for domain-specific parameters.", 
        "168": "Given w1 .", 
        "169": ".", 
        "170": ".", 
        "171": "wn \u2208 W in domain d \u2208 {src, tgt}, we use the private encoder\n(hd1 .", 
        "172": ".", 
        "173": ".", 
        "174": "h d n)\u2190 BiLSTM\u0398d(w1 .", 
        "175": ".", 
        "176": ".", 
        "177": "wn)\nIt is important that we only use the private encoder for this loss.", 
        "178": "Then we define the probability of domain d for the utterance as\nzi = W 2 nadv tanh ( W 1nadv n\u2211\ni=1\nhdi + b 1 nadv ) + b2nadv\np(d|hi) \u221d exp ([zi]d)\nwhere \u0398nadv = {W 1nadv,W 2nadv, b1nadv, b2nadv} denotes additional feedfoward parameters.", 
        "179": "The nonadversarial domain classification loss is given by the negative log likelihood\nLnadv (\u0398d,\u0398nadv) = \u2211\ni\nlog p ( d(i)|w(i) )\nwhere we iterate over domain-annotated utterances (w(i), d(i)).", 
        "180": "3.2.5 Orthogonality Loss  Finally, following Bousmalis et al.", 
        "181": "(2016), we further encourage the domain-specific features to be mutually exclusive with the shared features by imposing soft orthogonality constraints.", 
        "182": "This is achieved as follows.", 
        "183": "Given an utterance w1 .", 
        "184": ".", 
        "185": ".", 
        "186": "wn \u2208 W in domain d \u2208 {src, tgt}.", 
        "187": "We compute\n(hd1 .", 
        "188": ".", 
        "189": ".", 
        "190": "h d n)\u2190 BiLSTM\u0398d(w1 .", 
        "191": ".", 
        "192": ".", 
        "193": "wn)\n(hshd1 .", 
        "194": ".", 
        "195": ".", 
        "196": "h shd n )\u2190 BiLSTM\u0398shd(w1 .", 
        "197": ".", 
        "198": ".", 
        "199": "wn)\nThe orthogonality loss for this utterance is given by\nLorth (\u0398src,\u0398tgt,\u0398shd) = \u2211\ni\n(hdi ) >hshdi\nwhere we iterate over words i in both the source and target utterances.", 
        "200": "3.2.6 Joint Objective  For unsupervised DA, we optimize\nLunsup (\u0398src,\u0398tgt,\u0398shd,\u0398tag,\u0398rec,\u0398adv) =\nLtag (\u0398src,\u0398shd,\u0398tag) +\nLrec (\u0398src,\u0398tgt,\u0398shd,\u0398rec) +\nLadv (\u0398shd,\u0398adv) +\nLnadv (\u0398src,\u0398nadv) +\nLnadv (\u0398tgt,\u0398nadv) +\nLorth (\u0398src,\u0398tgt,\u0398shd)\nwith respect to all model parameters.", 
        "201": "In an online setting, given an utterance we compute its reconstruction, adversarial, orthogonality, and tagging loss if in the source domain, and take a gradient step on the sum of these losses.", 
        "202": "3.3 Supervised DA  In supervised domain adaptation, we assume labeled data for both the source domain and the target domain.", 
        "203": "We can easily incorporate supervision in the target domain by adding Ltag (\u0398tgt,\u0398shd,\u0398tag) to the unsupervised DA objective:\nLsup (\u0398src,\u0398tgt,\u0398shd,\u0398tag,\u0398rec,\u0398adv) =\nLunsup (\u0398src,\u0398tgt,\u0398shd,\u0398tag,\u0398rec,\u0398adv) +\nLtag (\u0398tgt,\u0398shd,\u0398tag) (3)\nWe mention that the approach by Kim et al.", 
        "204": "(2016c) is a special case of this objective; they op-\ntimize\nLsup2 (\u0398src,\u0398tgt,\u0398shd,\u0398tag) =Ltag (\u0398src,\u0398shd,\u0398tag) +\nLtag (\u0398tgt,\u0398shd,\u0398tag) (4)\nwhich is motivated as a neural extension of the feature augmentation method of Daume\u0301 III (2009).", 
        "205": "4 Experiments  In this section, we conducted a series of experiments to evaluate the proposed techniques on datasets obtained from real usage.", 
        "206": "4.1 Test Domains and Tasks  We test our approach on a suite of 5 Microsoft Cortana domains with 2 separate tasks in spoken language understanding: (1) intent classification and (2) slot (label) tagging.", 
        "207": "The intent classification task is a multi-class classification problem with the goal of determining to which one of the n intents a user utterance belongs conditioning on the given domain.", 
        "208": "The slot tagging task is a sequence labeling problem with the goal of identifying entities and chunking of useful information snippets in a user utterance.", 
        "209": "For example, a user could say reserve a table at joeys grill for thursday at seven pm for five people.", 
        "210": "Then the goal of the first task would be to classify this utterance as MAKE RESERVATION intent given the domain PLACES, and the goal of the second task would be to tag joeys grill as RESTAURANT, thursday as DATE, seven pm as TIEM, and five as NUMBER PEOPLE.", 
        "211": "Table 1 gives a summary of the 5 test domains.", 
        "212": "We note that the domains have various levels of label granularity.", 
        "213": "4.2 Experimental Setup  We consider 2 possible domain adaptation (DA) scenarios: (1) adaptation of an engineered dataset to a live user dataset and (2) adaptation of an old\ndataset to a new dataset.", 
        "214": "For the first DA scenario, we test whether our approach can effectively make a system adapt from experimental, engineered data to real-world, live data.", 
        "215": "We use synthetic data which domain experts manually create based on a given domain schema2 before the system goes live as the engineered data.", 
        "216": "We use transcribed dataset from users\u2019 speech input as the live user data.", 
        "217": "For the second scenario, we test whether our approach can effectively make a system adapt over time.", 
        "218": "A large number of users will quickly generate a large amount of data, and the usage pattern could also change.", 
        "219": "We use annotation data over 1 month in 2013 (more precisely August of 2013) as our old dataset, and use the whole data between 2014 and 2016 as our new dataset regardless of whether the data type is engineered or live user.", 
        "220": "As we describe in the earlier sections, we consider both supervised and unsupervised DA.", 
        "221": "We apply our DA approach with labeled data in the target domain for the supervised setting and with unlabeled data for the unsupervised one.", 
        "222": "We give details of the baselines and variants of our approach below.", 
        "223": "Unsupervised DA baselines and variants:\n\u2022 SRC: a single LSTM model trained on a source domain without DA techniques\n\u2022 DAW : an unsupervised DA model with a word-level decoder (i.e., re-generate each word independently)\n\u2022 DAS : an unsupervised DA model with a sentence-level decoder described in Section 3.2\nSupervised DA baselines and variants:\n\u2022 SRC: a single LSTM model trained only on a source domain\n\u2022 TGT: a single LSTM model trained only on a target domain\n\u2022 Union: a single LSTM model trained on the union of source and target domains.", 
        "224": "\u2022 DA: a supervised DA model described in Section 3.3\n\u2022 DAA: DA with adversary domain training 2This is a semantic template that defines a set of intents and slots for each domain according to the intended functionality of the system.", 
        "225": "\u2022 DAU : DA with reasonably sufficient unlabeled data\nIn our experiments, all the models were implemented using Dynet (Neubig et al., 2017) and were trained using Stochastic Gradient Descent (SGD) with Adam (Kingma and Ba, 2015)\u2014an adaptive learning rate algorithm.", 
        "226": "We used the initial learning rate of 4\u00d7 10\u22124 and left all the other hyper parameters as suggested in Kingma and Ba (2015).", 
        "227": "Each SGD update was computed without a minibatch with Intel MKL (Math Kernel Library)3.", 
        "228": "We used the dropout regularization (Srivastava et al., 2014) with the keep probability of 0.4.", 
        "229": "We encode user utterances with BiLSTMs as described in Section 3.1.", 
        "230": "We initialize word embeddings with pre-trained embeddings used by Lample et al.", 
        "231": "(2016).", 
        "232": "In the following sections, we report intent classification results in accuracy percentage and slot results in F1-score.", 
        "233": "To compute slot F1-score, we used the standard CoNLL evaluation script4  4.3 Results: Unsupervised DA  We first show our results in the unsupervised DA setting where we have a labeled dataset in the source domain, but only unlabeled data in the target domain.", 
        "234": "We assume that the amount of data in both datasets is sufficient.", 
        "235": "Dataset statistics are shown in Table 2.", 
        "236": "The performance of the baselines and our model variants are shown in Table 3.", 
        "237": "The left side of the table shows the results of the DA scenario of adapting from engineered data to live user data, and the baseline which trained only on the source domain (SRC) show a poor performance, yielding on average 48.5% on the intent classification and 42.7% F1-score on the slot tagging.", 
        "238": "Using our DA approach with a word-level decoder (DAW ) shows a significant increase in performance in all 5 test domains, yielding on average 82.2% intent accuracy and 80.5% slot F1-score.", 
        "239": "The performance increases further using the DA approach with a sentence-level decoder DAS , yielding on average 85.6% intent accuracy and 83.0% slot F1-score.", 
        "240": "The right side of the table shows the results of the DA scenario of adapting from old to new data, and the baseline trained only on SRC also show\n3https://software.intel.com/en-us/articles/intelr-mkl-andc-template-libraries\n4http://www.cnts.ua.ac.be/conll2000/chunking/output.html\na similar poor performance, yielding on average 51.7% accuracy and 43.7% F1-score.", 
        "241": "DAW approach shows a significant performance increase in all 5 test domains, yielding on average 86.9%\nintent accuracy and 85.7% slot F1-score.", 
        "242": "Similarly, the performance increases further with the DAS with 90.2% intent accuracy and 89.3% F1score.", 
        "243": "Our DA approach variants yield average error reductions of 72.04% and 79.71% for intent classification and 70.33% and 80.99% for slot tagging.", 
        "244": "The results suggest that our DA approach can quickly make a model adapt from synthetic data to real-world data and from old data to new data with the additional use of only 2 to 2.5 more data from the target domain.", 
        "245": "Aside from the performance boost itself, the approach shows even more power since the new data from the target down do not need to be labeled and it only requires collecting a little more data from the target domain.", 
        "246": "We note that the model development sets were created only from the source domain for a fully unsupervised setting.", 
        "247": "But having the development set from the target domain shows even more boost in performance although not shown in the results, and labeling only the development set from the target domain is relatively less expensive than labeling the whole dataset.", 
        "248": "4.4 Results: Supervised DA  Second, we show our results in the supervised DA setting where we have a sufficient amount of labeled data in the source domain but relatively insufficient amount of labeled data in the target domain.", 
        "249": "Having more labeled data in the target domain would most likely help with the performance, but we intentionally made the setting more disadvantageous for our DA approach to better simulate real-world scenarios where there is usually lack of resources and time to label a large amount of new data.", 
        "250": "For each personal assistant test domain, we only used 1000 training utterances to simulate scarcity of newly labeled data, and dataset statistics are shown in Table 2.", 
        "251": "Unlike the unsupervised DA scenario, here we used the development sets created from the target domain shown in Table 4.", 
        "252": "The left side of Table 5 shows the results of the supervised DA approach of adapting from engineered data to live user data.", 
        "253": "The baseline trained only on the source (SRC) shows on average 48.5% intent accuracy and 42.7% slot F1-score.", 
        "254": "Training only on the target domain (TGT) increases the performance to 71.3% and 65.0%, but training on the union of the source and target domains (Union) again brings the performance down to 48.7% and 42.3%.", 
        "255": "As shown in the unsupervised setting, using our DA approach (DA) shows significant performance increase in all 5 test domains, yielding\non average 81.7% intent accuracy and 76.2% slot tagging.", 
        "256": "The DA approach with adversary domain training (DAA) shows similar performance compared to that ofDA, and performance shows more increase when using our DA approach with sufficient unlabeled data5 (DAU ), yielding on average 83.6% and 77.6%.", 
        "257": "For the second scenario of adapting from old to new dataset, the results show a very similar trend in performance.", 
        "258": "The results show that our supervised DA (DA) approach also achieves a significant performance gain in all 5 test domains, yielding average error reductions of 68.18% and 51.35% for intent classification and 60.90% and 50.09% for slot tagging.", 
        "259": "The results suggest that an effective domain adaptation can be done using the supervised DA by having only a handful more data of 1k newly labeled data points.", 
        "260": "In addition, having both a small amount of newly labeled data combined with sufficient unlabeled data can help the models perform even better.", 
        "261": "The poor performance of using the union of both source and target domain data might be due to the relatively very small size of the target domain data, overwhelmed by the data in the source domain.", 
        "262": "4.5 Results: Adversarial Domain Classification Loss  5This data is used for unsupervised DA experiments (Table 2).", 
        "263": "The impact on the performance of two different adversarial classification losses are shown in Table 6.", 
        "264": "RAND represents the unsupervised DA model with sentence-level decoder (DAS) using random prediction loss.", 
        "265": "The ADV shows the performance of same model using the adversarial loss of Ganin et al.", 
        "266": "(2016) as described in 3.2.3.", 
        "267": "Unfortunately, in the deployment shift scenario, using the adversarial loss fails to provide any improvement on intent classification accuracy and slot tagging F1 score, achieving 82.5% intent accuracy and 79.8% slot F1 score.", 
        "268": "These results align with our hypothesis that the adversarial loss using does not confuse the classifier sufficiently.", 
        "269": "4.6 Proxy A-distance\nThe results in shown in Table 7 show Proxy Adistance(Ganin et al., 2016) to check if our adversary domain training generalize well to the target domain.", 
        "270": "The distance between two datasets is computed by\nd\u0302A = 2(1\u2212 2 min {\u03b5, 1\u2212 \u03b5}) (5)\nwhere \u03b5 is a generalization error in discriminating between the source and target datasets.", 
        "271": "The range of d\u0302A distance is between 0 and 2.0.", 
        "272": "0 is the best case where adversary training successfully fake shared encoder to predict domains.", 
        "273": "In other words, thanks to adversary training our model make the domain-invariant features in shared encoder in order to generalize well to the target domain.", 
        "274": "4.7 Vocabulary distance between engineered data and live user data  The results in shown in Table 8 show the discrepancy between two datasets.", 
        "275": "We measure the degree of overlap between vocabulary V employed\nby the two datasets.", 
        "276": "We simply take the Jaccard coefficient between the two sets of such vocabulary: dV (s, t) = 1\u2212 JC(Vs, Vt), where Vs is the set of vocabulary in source s domain, and Vt is the corresponding set for target t domain and JC(A,B) = |A\u2229B||A\u222aB| is the Jaccard coefficient, measuring the similarity of two sets.", 
        "277": "The distance dV is the high it means that they are not shared with many words.", 
        "278": "Overall, the distance between old and new dataset are still far and the number of overlapped are small, but better than live user case.", 
        "279": "5 Conclusion  In this paper, we have addressed two types of data shift common in SLU applications: 1. transferring from synthetic data to live user data (a deployment shift), and 2. transferring from stale data to current data (a temporal shift).", 
        "280": "Our method is based on domain adaptation, treating the flawed training dataset as a source domain and the evaluation dataset as a target domain.", 
        "281": "We use and build on several recent advances in neural domain adaptation such as adversarial training and domain separation network, proposing a new effective adversarial training scheme based on randomized predictions.", 
        "282": "In both supervised and unsupervised adaptation scenarios, our approach yields clear improvement over strong baselines."
    }, 
    "document_id": "P17-1119.pdf.json"
}
