{
    "abstract_sentences": {
        "1": "Cloze-style reading comprehension is a representative problem in mining relationship between document and query.", 
        "2": "In this paper, we present a simple but novel model called attention-over-attention reader for better solving cloze-style reading comprehension task.", 
        "3": "The proposed model aims to place another attention mechanism over the document-level attention and induces \u201cattended attention\u201d for final answer predictions.", 
        "4": "One advantage of our model is that it is simpler than related works while giving excellent performance.", 
        "5": "In addition to the primary model, we also propose an N-best re-ranking strategy to double check the validity of the candidates and further improve the performance.", 
        "6": "Experimental results show that the proposed methods significantly outperform various state-ofthe-art systems by a large margin in public datasets, such as CNN and Children\u2019s Book Test."
    }, 
    "body_sentences": {
        "1": "  Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 593\u2013602 Vancouver, Canada, July 30 - August 4, 2017. c\u00a92017 Association for Computational Linguistics\nhttps://doi.org/10.18653/v1/P17-1055  1 Introduction  To read and comprehend the human languages are challenging tasks for the machines, which requires that the understanding of natural languages and the ability to do reasoning over various clues.", 
        "2": "Reading comprehension is a general problem in the real world, which aims to read and comprehend a given article or context, and answer the questions based on it.", 
        "3": "Recently, the cloze-style reading comprehension problem has become a popular task in the community.", 
        "4": "The cloze-style query (Taylor, 1953) is a problem that to fill in an appropriate word in the given sentences while taking the context information into account.", 
        "5": "To teach the machine to do cloze-style reading\ncomprehensions, large-scale training data is necessary for learning relationships between the given document and query.", 
        "6": "To create large-scale training data for neural networks, Hermann et al.", 
        "7": "(2015) released the CNN/Daily Mail news dataset, where the document is formed by the news articles and the queries are extracted from the summary of the news.", 
        "8": "Hill et al.", 
        "9": "(2015) released the Children\u2019s Book Test dataset afterwards, where the training samples are generated from consecutive 20 sentences from books, and the query is formed by 21st sentence.", 
        "10": "Following these datasets, a vast variety of neural network approaches have been proposed (Kadlec et al., 2016; Cui et al., 2016; Chen et al., 2016; Dhingra et al., 2016; Sordoni et al., 2016; Trischler et al., 2016; Seo et al., 2016; Xiong et al., 2016), and most of them stem from the attention-based neural network (Bahdanau et al., 2014), which has become a stereotype in most of the NLP tasks and is well-known by its capability of learning the \u201cimportance\u201d distribution over the inputs.", 
        "11": "In this paper, we present a novel neural network architecture, called attention-over-attention model.", 
        "12": "As we can understand the meaning literally, our model aims to place another attention mechanism over the existing document-level attention.", 
        "13": "Unlike the previous works, that are using heuristic merging functions (Cui et al., 2016), or setting various pre-defined non-trainable terms (Trischler et al., 2016), our model could automatically generate an \u201cattended attention\u201d over various document-level attentions, and make a mutual look not only from query-to-document but also document-to-query, which will benefit from the interactive information.", 
        "14": "To sum up, the main contributions of our work are listed as follows.", 
        "15": "\u2022 To our knowledge, this is the first time that\n593\nthe mechanism of nesting another attention over the existing attentions is proposed, i.e.", 
        "16": "attention-over-attention mechanism.", 
        "17": "\u2022 Unlike the previous works on introducing complex architectures or many non-trainable hyper-parameters to the model, our model is much more simple but outperforms various state-of-the-art systems by a large margin.", 
        "18": "\u2022 We also propose an N-best re-ranking strategy to re-score the candidates in various aspects and further improve the performance.", 
        "19": "The following of the paper will be organized as follows.", 
        "20": "In Section 2, we will give a brief introduction to the cloze-style reading comprehension task as well as related public datasets.", 
        "21": "Then the proposed attention-over-attention reader will be presented in detail in Section 3 and N-best reranking strategy in Section 4.", 
        "22": "The experimental results and analysis will be given in Section 5 and Section 6.", 
        "23": "Related work will be discussed in Section 7.", 
        "24": "Finally, we will give a conclusion of this paper and envisions on future work.", 
        "25": "2 Cloze-style Reading Comprehension  In this section, we will give a brief introduction to the cloze-style reading comprehension task at the beginning.", 
        "26": "And then, several existing public datasets will be described in detail.", 
        "27": "2.1 Task Description  Formally, a general Cloze-style reading comprehension problem can be illustrated as a triple:\n\u3008D,Q,A\u3009\nThe triple consists of a documentD, a queryQ and the answer to the queryA.", 
        "28": "Note that the answer is usually a single word in the document, which requires the human to exploit context information in both document and query.", 
        "29": "The type of the answer word varies from predicting a preposition given a fixed collocation to identifying a named entity from a factual illustration.", 
        "30": "2.2 Existing Public Datasets  Large-scale training data is essential for training neural networks.", 
        "31": "Several public datasets for the cloze-style reading comprehension has been released.", 
        "32": "Here, we introduce two representative and widely-used datasets.", 
        "33": "\u2022 CNN / Daily Mail Hermann et al.", 
        "34": "(2015) have firstly published two datasets: CNN and Daily Mail news data 1.", 
        "35": "They construct these datasets with web-crawled CNN and Daily Mail news data.", 
        "36": "One of the characteristics of these datasets is that the news article is often associated with a summary.", 
        "37": "So they first regard the main body of the news article as the Document, and the Query is formed by the summary of the article, where one entity word is replaced by a special placeholder to indicate the missing word.", 
        "38": "The replaced entity word will be the Answer of the Query.", 
        "39": "Apart from releasing the dataset, they also proposed a methodology that anonymizes the named entity tokens in the data, and these tokens are also re-shuffle in each sample.", 
        "40": "The motivation is that the news articles are containing limited named entities, which are usually celebrities, and the world knowledge can be learned from the dataset.", 
        "41": "So this methodology aims to exploit general relationships between anonymized named entities within a single document rather than the common knowledge.", 
        "42": "The following research on these datasets showed that the entity word anonymization is not as effective as expected (Chen et al., 2016).", 
        "43": "\u2022 Children\u2019s Book Test There was also a dataset called the Children\u2019s Book Test (CBTest) released by Hill et al.", 
        "44": "(2015), which is built on the children\u2019s book story through Project Gutenberg 2.", 
        "45": "Different from the CNN/Daily Mail datasets, there is no summary available in the children\u2019s book.", 
        "46": "So they proposed another way to extract query from the original data.", 
        "47": "The document is composed of 20 consecutive sentences in the story, and the 21st sentence is regarded as the query, where one word is blanked with a special placeholder.", 
        "48": "In the CBTest datasets, there are four types of sub-datasets available which are classified by the part-of-speech and named entity tag of the answer word, containing Named Entities (NE), Common Nouns (CN), Verbs and Prepositions.", 
        "49": "In their studies, they have found that the answering of verbs and prepositions are relatively less dependent on the content of document, and the humans can even do preposi-\n1The pre-processed CNN and Daily Mail datasets are available at http://cs.nyu.edu/\u02dckcho/DMQA/\n2The CBTest datasets are available at http: //www.thespermwhale.com/jaseweston/babi/ CBTest.tgz\ntion blank-filling without the presence of the document.", 
        "50": "The studies shown by Hill et al.", 
        "51": "(2015), answering verbs and prepositions are less dependent with the presence of document.", 
        "52": "Thus, most of the related works are focusing on solving NE and CN types.", 
        "53": "3 Attention-over-Attention Reader  In this section, we will give a detailed introduction to the proposed Attention-over-Attention Reader (AoA Reader).", 
        "54": "Our model is primarily motivated by Kadlec et al., (2016), which aims to directly estimate the answer from the document-level attention instead of calculating blended representations of the document.", 
        "55": "As previous studies by Cui et al.", 
        "56": "(2016) showed that the further investigation of query representation is necessary, and it should be paid more attention to utilizing the information of query.", 
        "57": "In this paper, we propose a novel work that placing another attention over the primary attentions, to indicate the \u201cimportance\u201d of each attentions.", 
        "58": "Now, we will give a formal description of our proposed model.", 
        "59": "When a cloze-style training triple \u3008D,Q,A\u3009 is given, the proposed model will be constructed in the following steps.", 
        "60": "\u2022 Contextual Embedding We first transform every word in the document D and queryQ into one-hot representations and then convert them into continuous representations with a shared embedding matrix We.", 
        "61": "By sharing word embedding, both the document and query can participate in the learning of embedding and both of them will benefit from this mechanism.", 
        "62": "After that, we use two bi-directional RNNs to get contextual representations of the document and query individually, where the representation of each word is formed by concatenating the forward and backward hidden states.", 
        "63": "After making a trade-off between model performance and training complexity, we choose the Gated Recurrent Unit (GRU) (Cho et al., 2014) as recurrent unit implementation.", 
        "64": "e(x) =We \u00b7 x, where x \u2208 D,Q (1) \u2212\u2212\u2212\u2192 hs(x) = \u2212\u2212\u2212\u2192 GRU(e(x)) (2)\n\u2190\u2212\u2212\u2212 hs(x) = \u2190\u2212\u2212\u2212 GRU(e(x)) (3)\nhs(x) = [ \u2212\u2212\u2212\u2192 hs(x); \u2190\u2212\u2212\u2212 hs(x)] (4)\nWe take hdoc \u2208 R|D|\u22172d and hquery \u2208 R|Q|\u22172d to denote the contextual representations of document and query, where d is the dimension of GRU (oneway).", 
        "65": "\u2022 Pair-wise Matching Score After obtaining the contextual embeddings of the document hdoc and query hquery, we calculate a pair-wise matching matrix, which indicates the pair-wise matching degree of one document word and one query word.", 
        "66": "Formally, when given ith word of the document and jth word of query, we can compute a matching score by their dot product.", 
        "67": "M(i, j) = hdoc(i) T \u00b7 hquery(j) (5)\nIn this way, we can calculate every pair-wise matching score between each document and query word, forming a matrix M \u2208 R|D|\u2217|Q|, where the value of ith row and jth column is filled by M(i, j).", 
        "68": "\u2022 Individual Attentions After getting the pair-wise matching matrixM , we apply a column-wise softmax function to get probability distributions in each column, where each column is an individual document-level attention when considering a single query word.", 
        "69": "We denote \u03b1(t) \u2208 R|D| as the document-level attention regarding query word at time t, which can be seen as a query-to-document attention.", 
        "70": "\u03b1(t) = softmax(M(1, t), ...,M(|D|, t)) (6) \u03b1 = [\u03b1(1), \u03b1(2), ..., \u03b1(|Q|)] (7)\n\u2022 Attention-over-Attention Different from Cui et al.", 
        "71": "(2016), instead of using naive heuristics (such as summing or averaging) to combine these individual attentions into a final attention, we introduce another attention mechanism to automatically decide the importance of each individual attention.", 
        "72": "First, we calculate a reversed attention, that is, for every document word at time t, we calculate the \u201cimportance\u201d distribution on the query, to indicate which query words are more important given a single document word.", 
        "73": "We apply a row-wise softmax function to the pair-wise matching matrix M to get query-level attentions.", 
        "74": "We denote \u03b2(t) \u2208 R|Q| as the query-level attention regarding document word at time t, which can be seen as a\ndocument-to-query attention.", 
        "75": "\u03b2(t) = softmax(M(t, 1), ...,M(t, |Q|)) (8)\nSo far, we have obtained both query-todocument attention \u03b1 and document-to-query attention \u03b2.", 
        "76": "Our motivation is to exploit mutual information between the document and query.", 
        "77": "However, most of the previous works are only relying on query-to-document attention, that is, only calculate one document-level attention when considering the whole query.", 
        "78": "Then we average all the \u03b2(t) to get an averaged query-level attention \u03b2.", 
        "79": "Note that, we do not apply another softmax to the \u03b2, because averaging individual attentions do not break the normalizing condition.", 
        "80": "\u03b2 = 1\nn\n|D|\u2211\nt=1\n\u03b2(t) (9)\nFinally, we calculate dot product of \u03b1 and \u03b2 to get the \u201cattended document-level attention\u201d s \u2208 R|D|, i.e.", 
        "81": "the attention-over-attention mechanism.", 
        "82": "Intuitively, this operation is calculating a weighted sum of each individual document-level attention \u03b1(t) when looking at query word at time t. In\nthis way, the contributions by each query word can be learned explicitly, and the final decision (document-level attention) is made through the voted result by the importance of each query word.", 
        "83": "s = \u03b1T\u03b2 (10)\n\u2022 Final Predictions Following Kadlec et al.", 
        "84": "(2016), we use sum attention mechanism to get aggregated results.", 
        "85": "Note that the final output should be reflected in the vocabulary space V , rather than document-level attention |D|, which will make a significant difference in the performance, though Kadlec et al.", 
        "86": "(2016) did not illustrate this clearly.", 
        "87": "P (w|D,Q) = \u2211\ni\u2208I(w,D) si, w \u2208 V (11)\nwhere I(w,D) indicate the positions that word w appears in the document D. As the training objectives, we seek to maximize the log-likelihood of the correct answer.", 
        "88": "L = \u2211\ni\nlog(p(x)) , x \u2208 A (12)\nThe proposed neural network architecture is depicted in Figure 1.", 
        "89": "Note that, as our model mainly adds limited steps of calculations to the AS Reader (Kadlec et al., 2016) and does not employ any additional weights, the computational complexity is similar to the AS Reader.", 
        "90": "4 N-best Re-ranking Strategy  Intuitively, when we do cloze-style reading comprehensions, we often refill the candidate into the blank of the query to double-check its appropriateness, fluency and grammar to see if the candidate we choose is the most suitable one.", 
        "91": "If we do find some problems in the candidate we choose, we will choose the second possible candidate and do some checking again.", 
        "92": "To mimic the process of double-checking, we propose to use N-best re-ranking strategy after generating answers from our neural networks.", 
        "93": "The procedure can be illustrated as follows.", 
        "94": "\u2022 N-best Decoding Instead of only picking the candidate that has the highest possibility as answer, we can also extract follow-up candidates in the decoding process, which forms an N-best list.", 
        "95": "\u2022 Refill Candidate into Query As a characteristic of the cloze-style problem, each candidate can be refilled into the blank of the query to form a complete sentence.", 
        "96": "This allows us to check the candidate according to its context.", 
        "97": "\u2022 Feature Scoring The candidate sentences can be scored in many aspects.", 
        "98": "In this paper, we exploit three features to score the N-best list.", 
        "99": "\u2022 Global N-gram LM: This is a fundamental metric in scoring sentence, which aims to evaluate its fluency.", 
        "100": "This model is trained on the document part of training data.", 
        "101": "\u2022 Local N-gram LM: Different from global LM, the local LM aims to explore the information with the given document, so the statistics are obtained from the test-time document.", 
        "102": "It should be noted that the local LM is trained sample-by-sample, it is not trained on the entire test set, which is not legal in the real test case.", 
        "103": "This model is useful when there are many unknown words in the test sample.", 
        "104": "\u2022 Word-class LM: Similar to global LM, the word-class LM is also trained on the document part of training data, but the words are converted to its word class ID.", 
        "105": "The word class can be obtained by using clustering methods.", 
        "106": "In this paper, we simply utilized the mkcls tool for generating 1000 word classes (Josef Och, 1999).", 
        "107": "\u2022 Weight Tuning To tune the weights among these features, we adopt the K-best MIRA algorithm (Cherry and Foster, 2012) to automatically optimize the weights on the validation set, which is widely used in statistical machine translation tuning procedure.", 
        "108": "\u2022 Re-scoring and Re-ranking After getting the weights of each feature, we calculate the weighted sum of each feature in the Nbest sentences and then choose the candidate that has the lowest cost as the final answer.", 
        "109": "5 Experiments    5.1 Experimental Setups  The general settings of our neural network model are listed below in detail.", 
        "110": "\u2022 Embedding Layer: The embedding weights are randomly initialized with the uniformed distribution in the interval [\u22120.05, 0.05].", 
        "111": "For regularization purpose, we adopted l2regularization to 0.0001 and dropout rate of 0.1 (Srivastava et al., 2014).", 
        "112": "Also, it should be noted that we do not exploit any pretrained embedding models.", 
        "113": "\u2022 Hidden Layer: Internal weights of GRUs are initialized with random orthogonal matrices (Saxe et al., 2013).", 
        "114": "\u2022 Optimization: We adopted ADAM optimizer for weight updating (Kingma and Ba, 2014), with an initial learning rate of 0.001.", 
        "115": "As the GRU units still suffer from the gradient exploding issues, we set the gradient clipping threshold to 5 (Pascanu et al., 2013).", 
        "116": "We used batched training strategy of 32 samples.", 
        "117": "Dimensions of embedding and hidden layer for each task are listed in Table 3.", 
        "118": "In re-ranking step, we generate 5-best list from the baseline neural network model, as we did not observe a significant variance when changing the N-best list size.", 
        "119": "All language model features are trained on the training proportion of each dataset, with 8-gram wordbased setting and Kneser-Ney smoothing (Kneser\nand Ney, 1995) trained by SRILM toolkit (Stolcke, 2002).", 
        "120": "The results are reported with the best model, which is selected by the performance of validation set.", 
        "121": "The ensemble model is made up of four best models, which are trained using different random seed.", 
        "122": "Implementation is done with Theano (Theano Development Team, 2016) and Keras (Chollet, 2015), and all models are trained on Tesla K40 GPU.", 
        "123": "5.2 Overall Results  Our experiments are carried out on public datasets: CNN news datasets (Hermann et al., 2015) and CBTest NE/CN datasets (Hill et al., 2015).", 
        "124": "The statistics of these datasets are listed in Table 1, and the experimental results are given in Table 2.", 
        "125": "As we can see that, our AoA Reader outperforms state-of-the-art systems by a large margin, where 2.3% and 2.0% absolute improvements over EpiReader in CBTest NE and CN test sets, which demonstrate the effectiveness of our model.", 
        "126": "Also by adding additional features in the re-ranking step, there is another significant boost 2.0% to 3.7% over AoA Reader in CBTest NE/CN test sets.", 
        "127": "We have also found that our single model could stay on par with the previous best ensemble system, and even we have an absolute improvement of 0.9% beyond the best ensemble model (Iterative Attention) in the CBTest NE validation set.", 
        "128": "When it comes to ensemble model, our AoA Reader also shows significant improvements over previous best ensemble models by a large margin and set up a new state-of-the-art system.", 
        "129": "To investigate the effectiveness of employing attention-over-attention mechanism, we also compared our model to CAS Reader, which used predefined merging heuristics, such as sum or avg etc.", 
        "130": "Instead of using pre-defined merging heuristics, and letting the model explicitly learn the weights between individual attentions results in a significant boost in the performance, where 4.1% and 3.7% improvements can be made in CNN validation and test set against CAS Reader.", 
        "131": "5.3 Effectiveness of Re-ranking Strategy  As we have seen that the re-ranking approach is effective in cloze-style reading comprehension task, we will give a detailed ablations in this section to show the contributions by each feature.", 
        "132": "To have a thorough investigation in the re-ranking step, we listed the detailed improvements while adding each feature mentioned in Section 4.", 
        "133": "From the results in Table 4, we found that the NE and CN category both benefit a lot from the re-ranking features, but the proportions are quite different.", 
        "134": "Generally speaking, in NE category, the performance is mainly boosted by the LMlocal feature.", 
        "135": "However, on the contrary, the CN category benefits from LMglobal and LMwc rather than the LMlocal.", 
        "136": "Also, we listed the weights of each feature in Table 5.", 
        "137": "The LMglobal and LMwc are all trained by training set, which can be seen as Global Feature.", 
        "138": "However, the LMlocal is only trained within the respective document part of test sample, which can be seen as Local Feature.", 
        "139": "\u03b7 = LMglobal + LMwc\nLMlocal (13)\nWe calculated the ratio between the global and local features and found that the NE category is much more dependent on local features than CN category.", 
        "140": "Because it is much more likely to meet a new named entity than a common noun in the test phase, so adding the local LM provides much more information than that of common noun.", 
        "141": "However, on the contrary, answering common noun requires less local information, which can be learned in the training data relatively.", 
        "142": "6 Quantitative Analysis  In this section, we will give a quantitative analysis to our AoA Reader.", 
        "143": "The following analyses are carried out on CBTest NE dataset.", 
        "144": "First, we investigate the relations between the length of the document and corresponding accuracy.", 
        "145": "The result is depicted in Figure 2.", 
        "146": "As we can see that the AoA Reader shows consistent improvements over AS Reader on the different length of the document.", 
        "147": "Especially, when the length of document exceeds 700, the improvements become larger, indicating that the AoA Reader is more capable of handling long documents.", 
        "148": "Furthermore, we also investigate if the model tends to choose a high-frequency candidate than a lower one, which is shown in Figure 3.", 
        "149": "Not surprisingly, we found that both models do a good job when the correct answer appears more frequent in the document than the other candidates.", 
        "150": "This is because that the correct answer that has the highest frequency among the candidates takes up over 40% of the test set (1071 out of 2500).", 
        "151": "But interestingly we have also found that, when the frequency rank of correct answer exceeds 7 (less frequent among candidates), these models also give a relatively high performance.", 
        "152": "Empirically, we think that these models tend to choose extreme cases in terms of candidate frequency (either too high or too low).", 
        "153": "One possible reason is that it is\nhard for the model to choose a candidate that has a neutral frequency as the correct answer, because of its ambiguity (neutral choices are hard to made).", 
        "154": "7 Related Work  Cloze-style reading comprehension tasks have been widely investigated in recent studies.", 
        "155": "We will take a brief revisit to the related works.", 
        "156": "Hermann et al.", 
        "157": "(2015) have proposed a method for obtaining large quantities of \u3008D,Q,A\u3009 triples through news articles and its summary.", 
        "158": "Along with the release of cloze-style reading comprehension dataset, they also proposed an attention-based neural network to handle this task.", 
        "159": "Experimental results showed that the proposed neural network is effective than traditional baselines.", 
        "160": "Hill et al.", 
        "161": "(2015) released another dataset, which stems from the children\u2019s books.", 
        "162": "Different from Hermann et al.", 
        "163": "(2015)\u2019s work, the document and query are all generated from the raw story without any summary, which is much more general than previous work.", 
        "164": "To handle the reading comprehension task, they proposed a window-based memory network, and self-supervision heuristics is also applied to learn hard-attention.", 
        "165": "Unlike previous works, that using blended representations of document and query to estimate the answer, Kadlec et al.", 
        "166": "(2016) proposed a simple model that directly pick the answer from the document, which is motivated by the Pointer Network (Vinyals et al., 2015).", 
        "167": "A restriction of this model is that the answer should be a single word and appear in the document.", 
        "168": "Results on various public datasets showed that the proposed model is effective than previous works.", 
        "169": "Liu et al.", 
        "170": "(2016) proposed to exploit reading comprehension models to other tasks.", 
        "171": "They first applied the reading comprehension model into Chinese zero pronoun resolution task with automatically generated large-scale pseudo training data.", 
        "172": "The experimental results on OntoNotes 5.0 data showed that their method significantly outperforms various state-of-the-art systems.", 
        "173": "Our work is primarily inspired by Cui et al.", 
        "174": "(2016) and Kadlec et al.", 
        "175": "(2016) , where the latter model is widely applied to many follow-up works (Sordoni et al., 2016; Trischler et al., 2016; Cui et al., 2016).", 
        "176": "Unlike the CAS Reader (Cui et al., 2016), we do not assume any heuristics to our model, such as using merge functions: sum, avg etc.", 
        "177": "We used a mechanism called \u201cattention-\nover-attention\u201d to explicitly calculate the weights between different individual document-level attentions, and get the final attention by computing the weighted sum of them.", 
        "178": "Also, we find that our model is typically general and simple than the recently proposed model, and brings significant improvements over these cutting edge systems.", 
        "179": "8 Conclusion  We present a novel neural architecture, called attention-over-attention reader, to tackle the clozestyle reading comprehension task.", 
        "180": "The proposed AoA Reader aims to compute the attentions not only for the document but also the query side, which will benefit from the mutual information.", 
        "181": "Then a weighted sum of attention is carried out to get an attended attention over the document for the final predictions.", 
        "182": "Among several public datasets, our model could give consistent and significant improvements over various state-of-theart systems by a large margin.", 
        "183": "The future work will be carried out in the following aspects.", 
        "184": "We believe that our model is general and may apply to other tasks as well, so firstly we are going to fully investigate the usage of this architecture in other tasks.", 
        "185": "Also, we are interested to see that if the machine really \u201ccomprehend\u201d our language by utilizing neural networks approaches, but not only serve as a \u201cdocument-level\u201d language model.", 
        "186": "In this context, we are planning to investigate the problems that need comprehensive reasoning over several sentences.", 
        "187": "Acknowledgments  We would like to thank all three anonymous reviewers for their thorough reviewing and providing thoughtful comments to improve our paper.", 
        "188": "This work was supported by the National 863 Leading Technology Research Project via grant 2015AA015409."
    }, 
    "document_id": "P17-1055.pdf.json"
}
