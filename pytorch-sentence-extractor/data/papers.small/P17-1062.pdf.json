{
    "abstract_sentences": {
        "1": "End-to-end learning of recurrent neural networks (RNNs) is an attractive solution for dialog systems; however, current techniques are data-intensive and require thousands of dialogs to learn simple behaviors.", 
        "2": "We introduce Hybrid Code Networks (HCNs), which combine an RNN with domain-specific knowledge encoded as software and system action templates.", 
        "3": "Compared to existing end-toend approaches, HCNs considerably reduce the amount of training data required, while retaining the key benefit of inferring a latent representation of dialog state.", 
        "4": "In addition, HCNs can be optimized with supervised learning, reinforcement learning, or a mixture of both.", 
        "5": "HCNs attain stateof-the-art performance on the bAbI dialog dataset (Bordes and Weston, 2016), and outperform two commercially deployed customer-facing dialog systems."
    }, 
    "body_sentences": {
        "1": "  Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 665\u2013677 Vancouver, Canada, July 30 - August 4, 2017. c\u00a92017 Association for Computational Linguistics\nhttps://doi.org/10.18653/v1/P17-1062  1 Introduction  Task-oriented dialog systems help a user to accomplish some goal using natural language, such as making a restaurant reservation, getting technical support, or placing a phonecall.", 
        "2": "Historically, these dialog systems have been built as a pipeline, with modules for language understanding, state tracking, action selection, and language generation.", 
        "3": "However, dependencies between modules introduce considerable complexity \u2013 for example, it is often unclear how to define the dialog state and what history to maintain, yet action selection relies exclusively on the state for input.", 
        "4": "Moreover, training each module requires specialized labels.", 
        "5": "\u2217Currently at JPMorgan Chase\nRecently, end-to-end approaches have trained recurrent neural networks (RNNs) directly on text transcripts of dialogs.", 
        "6": "A key benefit is that the RNN infers a latent representation of state, obviating the need for state labels.", 
        "7": "However, end-to-end methods lack a general mechanism for injecting domain knowledge and constraints.", 
        "8": "For example, simple operations like sorting a list of database results or updating a dictionary of entities can expressed in a few lines of software, yet may take thousands of dialogs to learn.", 
        "9": "Moreover, in some practical settings, programmed constraints are essential \u2013 for example, a banking dialog system would require that a user is logged in before they can retrieve account information.", 
        "10": "This paper presents a model for end-to-end learning, called Hybrid Code Networks (HCNs) which addresses these problems.", 
        "11": "In addition to learning an RNN, HCNs also allow a developer to express domain knowledge via software and action templates.", 
        "12": "Experiments show that, compared to existing recurrent end-to-end techniques, HCNs achieve the same performance with considerably less training data, while retaining the key benefit of end-to-end trainability.", 
        "13": "Moreover, the neural network can be trained with supervised learning or reinforcement learning, by changing the gradient update applied.", 
        "14": "This paper is organized as follows.", 
        "15": "Section 2 describes the model, and Section 3 compares the model to related work.", 
        "16": "Section 4 applies HCNs to the bAbI dialog dataset (Bordes and Weston, 2016).", 
        "17": "Section 5 then applies the method to real customer support domains at our company.", 
        "18": "Section 6 illustrates how HCNs can be optimized with reinforcement learning, and Section 7 concludes.", 
        "19": "665  2 Model description  At a high level, the four components of a Hybrid Code Network are a recurrent neural network; domain-specific software; domain-specific action templates; and a conventional entity extraction module for identifying entity mentions in text.", 
        "20": "Both the RNN and the developer code maintain state.", 
        "21": "Each action template can be a textual communicative action or an API call.", 
        "22": "The HCN model is summarized in Figure 1.", 
        "23": "The cycle begins when the user provides an utterance, as text (step 1).", 
        "24": "The utterance is featurized in several ways.", 
        "25": "First, a bag of words vector is formed (step 2).", 
        "26": "Second, an utterance embedding is formed, using a pre-built utterance embedding model (step 3).", 
        "27": "Third, an entity extraction module identifies entity mentions (step 4) \u2013 for example, identifying \u201cJennifer Jones\u201d as a <name> entity.", 
        "28": "The text and entity mentions are then passed to \u201cEntity tracking\u201d code provided by the developer (step 5), which grounds and maintains entities \u2013 for example, mapping the text \u201cJennifer Jones\u201d to a specific row in a database.", 
        "29": "This code can optionally return an \u201caction mask\u201d, indicating actions which are permitted at the current timestep, as a bit vector.", 
        "30": "For example, if a target phone number has not yet been identified, the API action to place a phone call may be masked.", 
        "31": "It can also optionally return \u201ccontext features\u201d which are features the developer thinks will be useful for distinguish-\ning among actions, such as which entities are currently present and which are absent.", 
        "32": "The feature components from steps 1-5 are concatenated to form a feature vector (step 6).", 
        "33": "This vector is passed to an RNN, such as a long shortterm memory (LSTM) (Hochreiter and Schmidhuber, 1997) or gated recurrent unit (GRU) (Chung et al., 2014).", 
        "34": "The RNN computes a hidden state (vector), which is retained for the next timestep (step 8), and passed to a dense layer with a softmax activation, with output dimension equal to the number of distinct system action templates (step 9).1 Thus the output of step 9 is a distribution over action templates.", 
        "35": "Next, the action mask is applied as an element-wise multiplication, and the result is normalized back to a probability distribution (step 10) \u2013 this forces non-permitted actions to take on probability zero.", 
        "36": "From the resulting distribution (step 11), an action is selected (step 12).", 
        "37": "When RL is active, exploration is required, so in this case an action is sampled from the distribution; when RL is not active, the best action should be chosen, and so the action with the highest probability is always selected.", 
        "38": "The selected action is next passed to \u201cEntity output\u201d developer code that can substitute in entities (step 13) and produce a fully-formed action \u2013 for example, mapping the template \u201c<city>,\n1Implementation details for the RNN such as size, loss, etc.", 
        "39": "are given with each experiment in Sections 4-6.\nright?\u201d to \u201cSeattle, right?\u201d.", 
        "40": "In step 14, control branches depending on the type of the action: if it is an API action, the corresponding API call in the developer code is invoked (step 15) \u2013 for example, to render rich content to the user.", 
        "41": "APIs can act as sensors and return features relevant to the dialog, so these can be added to the feature vector in the next timestep (step 16).", 
        "42": "If the action is text, it is rendered to the user (step 17), and cycle then repeats.", 
        "43": "The action taken is provided as a feature to the RNN in the next timestep (step 18).", 
        "44": "3 Related work  Broadly there are two lines of work applying machine learning to dialog control.", 
        "45": "The first decomposes a dialog system into a pipeline, typically including language understanding, dialog state tracking, action selection policy, and language generation (Levin et al., 2000; Singh et al., 2002; Williams and Young, 2007; Williams, 2008; Hori et al., 2009; Lee et al., 2009; Griol et al., 2008; Young et al., 2013; Li et al., 2014).", 
        "46": "Specifically related to HCNs, past work has implemented the policy as feed-forward neural networks (Wen et al., 2016), trained with supervised learning followed by reinforcement learning (Su et al., 2016).", 
        "47": "In these works, the policy has not been recurrent \u2013 i.e., the policy depends on the state tracker to summarize observable dialog history into state features, which requires design and specialized labeling.", 
        "48": "By contrast, HCNs use an RNN which automatically infers a representation of state.", 
        "49": "For learning efficiency, HCNs use an external lightweight process for tracking entity values, but the policy is not strictly dependent on it: as an illustration, in Section 5 below, we demonstrate an HCNbased dialog system which has no external state tracker.", 
        "50": "If there is context which is not apparent in the text in the dialog, such as database status, this can be encoded as a context feature to the RNN.", 
        "51": "The second, more recent line of work applies recurrent neural networks (RNNs) to learn \u201cendto-end\u201d models, which map from an observable dialog history directly to a sequence of output words (Sordoni et al., 2015; Shang et al., 2015; Vinyals and Le, 2015; Yao et al., 2015; Serban et al., 2016; Li et al., 2016a,c; Luan et al., 2016; Xu et al., 2016; Li et al., 2016b; Mei et al., 2016; Lowe et al., 2017; Serban et al., 2017).", 
        "52": "These systems can be applied to task-oriented domains by adding special \u201cAPI call\u201d actions, enumerating\ndatabase output as a sequence of tokens (Bordes and Weston, 2016), then learning an RNN using Memory Networks (Sukhbaatar et al., 2015), gated memory networks (Liu and Perez, 2016), query reduction networks (Seo et al., 2016), and copyaugmented networks (Eric and Manning, 2017).", 
        "53": "In each of these architectures, the RNN learns to manipulate entity values, for example by saving them in a memory.", 
        "54": "Output is produced by generating a sequence of tokens (or ranking all possible surface forms), which can also draw from this memory.", 
        "55": "HCNs also use an RNN to accumulate dialog state and choose actions.", 
        "56": "However, HCNs differ in that they use developer-provided action templates, which can contain entity references, such as \u201c<city>, right?\u201d.", 
        "57": "This design reduce learning complexity, and also enable the software to limit which actions are available via an action mask, at the expense of developer effort.", 
        "58": "To further reduce learning complexity in a practical system, entities are tracked separately, outside the the RNN, which also allows them to be substituted into action templates.", 
        "59": "Also, past end-to-end recurrent models have been trained using supervised learning, whereas we show how HCNs can also be trained with reinforcement learning.", 
        "60": "4 Supervised learning evaluation I  In this section we compare HCNs to existing approaches on the public \u201cbAbI dialog\u201d dataset (Bordes and Weston, 2016).", 
        "61": "This dataset includes two end-to-end dialog learning tasks, in the restaurant domain, called task5 and task6.2 Task5 consists of synthetic, simulated dialog data, with highly regular user behavior and constrained vocabulary.", 
        "62": "Dialogs include a database access action which retrieves relevant restaurants from a database, with results included in the dialog transcript.", 
        "63": "We test on the \u201cOOV\u201d variant of Task5, which includes entity values not observed in the training set.", 
        "64": "Task6 draws on human-computer dialog data from the second dialog state tracking challenge (DSTC2), where usability subjects (crowd-workers) interacted with several variants of a spoken dialog system (Henderson et al., 2014a).", 
        "65": "Since the database from DSTC2 was not provided, database calls have been inferred from the data and inserted into the dialog transcript.", 
        "66": "Example dialogs are provided in the Appendix Sections A.2 and A.3.", 
        "67": "To apply HCNs, we wrote simple domain2Tasks 1-4 are sub-tasks of Task5.", 
        "68": "specific software, as follows.", 
        "69": "First, for entity extraction (step 4 in Figure 1), we used a simple string match, with a pre-defined list of entity names \u2013 i.e., the list of restaurants available in the database.", 
        "70": "Second, in the context update (step 5), we wrote simple logic for tracking entities: when an entity is recognized in the user input, it is retained by the software, over-writing any previously stored value.", 
        "71": "For example, if the price \u201ccheap\u201d is recognized in the first turn, it is retained as price=cheap.", 
        "72": "If \u201cexpensive\u201d is then recognized in the third turn, it over-writes \u201ccheap\u201d so the code now holds price=expensive.", 
        "73": "Third, system actions were templatized: for example, system actions of the form \u201cprezzo is a nice restaurant in the west of town in the moderate price range\u201d all map to the template \u201c<name> is a nice restaurant in the <location> of town in the <price> price range\u201d.", 
        "74": "This results in 16 templates for Task5 and 58 for Task6.3 Fourth, when database results are received into the entity state, they are sorted by rating.", 
        "75": "Finally, an action mask was created which encoded common-sense dependencies.", 
        "76": "These are implemented as simple if-then rules based on the presence of entity values: for example, only allow an API call if pre-conditions are met; only offer a restaurant if database results have already been received; do not ask for an entity if it is already known; etc.", 
        "77": "For Task6, we noticed that the system can say that no restaurants match the current query without consulting the database (for an example dialog, see Section A.3 in the Appendix).", 
        "78": "In a practical system this information would be retrieved from the database and not encoded in the RNN.", 
        "79": "So, we mined the training data and built a table of search queries known to yield no results.", 
        "80": "We also added context features that indicated the state of the database \u2013 for example, whether there were any restaurants matching the current query.", 
        "81": "The complete set of context features is given in Appendix Section A.4.", 
        "82": "Altogether this code consisted of about 250 lines of Python.", 
        "83": "We then trained an HCN on the training set, employing the domain-specific software described above.", 
        "84": "We selected an LSTM for the recurrent layer (Hochreiter and Schmidhuber, 1997), with the AdaDelta optimizer (Zeiler, 2012).", 
        "85": "We used the development set to tune the number of hid-\n3A handful of actions in Task6 seemed spurious; for these, we replaced them with a special \u201cUNK\u201d action in the training set, and masked this action at test time.", 
        "86": "den units (128), and the number of epochs (12).", 
        "87": "Utterance embeddings were formed by averaging word embeddings, using a publicly available 300- dimensional word embedding model trained using word2vec on web data (Mikolov et al., 2013).4 The word embeddings were static and not updated during LSTM training.", 
        "88": "In training, each dialog formed one minibatch, and updates were done on full rollouts (i.e., non-truncated back propagation through time).", 
        "89": "The training loss was categorical cross-entropy.", 
        "90": "Further low-level implementation details are in the Appendix Section A.1.", 
        "91": "We ran experiments with four variants of our model: with and without the utterance embeddings, and with and without the action mask (Figure 1, steps 3 and 6 respectively).", 
        "92": "Following past work, we report average turn accuracy \u2013 i.e., for each turn in each dialog, present the (true) history of user and system actions to the network and obtain the network\u2019s prediction as a string of characters.", 
        "93": "The turn is correct if the string matches the reference exactly, and incorrect if not.", 
        "94": "We also report dialog accuracy, which indicates if all turns in a dialog are correct.", 
        "95": "We compare to four past end-to-end approaches (Bordes and Weston, 2016; Liu and Perez, 2016; Eric and Manning, 2017; Seo et al., 2016).", 
        "96": "We emphasize that past approaches have applied purely sequence-to-sequence models, or (as a baseline) purely programmed rules (Bordes and Weston, 2016).", 
        "97": "By contrast, Hybrid Code Networks are a hybrid of hand-coded rules and learned models.", 
        "98": "Results are shown in Table 1.", 
        "99": "Since Task5 is synthetic data generated using rules, it is possible to obtain perfect accuracy using rules (line 1).", 
        "100": "The addition of domain knowledge greatly simplifies the learning task and enables HCNs to also attain perfect accuracy.", 
        "101": "On Task6, rules alone fare poorly, whereas HCNs outperform past learned models.", 
        "102": "We next examined learning curves, training with increasing numbers of dialogs.", 
        "103": "To guard against bias in the ordering of the training set, we averaged over 5 runs, randomly permuting the order of the training dialogs in each run.", 
        "104": "Results are in Figure 2.", 
        "105": "In Task5, the action mask and utterance embeddings substantially reduce the number of training dialogs required (note the horizontal axis scale is logarithmic).", 
        "106": "For Task6, the bene-\n4Google News 100B model from https://github.", 
        "107": "com/3Top/word2vec-api\nfits of the utterance embeddings are less clear.", 
        "108": "An error analysis showed that there are several systematic differences between the training and testing sets.", 
        "109": "Indeed, DSTC2 intentionally used different dialog policies for the training and test sets, whereas our goal is to mimic the policy in the training set.", 
        "110": "Nonetheless, these tasks are the best public benchmark we are aware of, and HCNs exceed performance of existing sequence-to-sequence models.", 
        "111": "In addition, they match performance of past models using an order of magnitude less data (200 vs. 1618 dialogs), which is crucial in practical settings where collecting realistic dialogs for a new domain can be expensive.", 
        "112": "5 Supervised learning evaluation II  We now turn to comparing with purely handcrafted approaches.", 
        "113": "To do this, we obtained logs from our company\u2019s text-based customer support dialog system, which uses a sophisticated rulebased dialog manager.", 
        "114": "Data from this system is attractive for evaluation because it is used by real customers \u2013 not usability subjects \u2013 and because its rule-based dialog manager was developed by customer support professionals at our company, and not the authors.", 
        "115": "This data is not publicly available, but we are unaware of suitable humancomputer dialog data in the public domain which uses rules.", 
        "116": "Customers start using the dialog system by entering a brief description of their problem, such\nas \u201cI need to update my operating system\u201d.", 
        "117": "They are then routed to one of several hundred domains, where each domain attempts to resolve a particular problem.", 
        "118": "In this study, we collected humancomputer transcripts for the high-traffic domains \u201creset password\u201d and \u201ccannot access account\u201d.", 
        "119": "We labeled the dialog data as follows.", 
        "120": "First, we enumerated unique system actions observed in the data.", 
        "121": "Then, for each dialog, starting from the beginning, we examined each system action, and determined whether it was \u201ccorrect\u201d.", 
        "122": "Here, correct means that it was the most appropriate action among the set of existing system actions, given the history of that dialog.", 
        "123": "If multiple actions were arguably appropriate, we broke ties in favor of the existing rule-based dialog manager.", 
        "124": "Example dialogs are provided in the Appendix Sections A.5 and A.6.", 
        "125": "If a system action was labeled as correct, we left it as-is and continued to the next system action.", 
        "126": "If the system action was not correct, we replaced it with the correct system action, and discarded the rest of the dialog, since we do not know how the user would have replied to this new system action.", 
        "127": "The resulting dataset contained a mixture of complete and partial dialogs, containing only correct system actions.", 
        "128": "We partitioned this set into training and test dialogs.", 
        "129": "Basic statistics of the data are shown in Table 2.", 
        "130": "In this domain, no entities were relevant to the control flow, and there was no obvious mask logic since any question could follow any question.", 
        "131": "Therefore, we wrote no domain-specific software for this instance of the HCN, and relied purely on the recurrent neural network to drive the conversation.", 
        "132": "The architecture and training of the RNN was the same as in Section 4, except that here we did not have enough data for a validation set, so we instead trained until we either achieved 100% accuracy on the training set or reached 200 epochs.", 
        "133": "To evaluate, we observe that conventional measures like average dialog accuracy unfairly penalize the system used to collect the dialogs \u2013 in our case, the rule-based system.", 
        "134": "If the system used for collection makes an error at turn t, the labeled dialog only includes the sub-dialog up to turn t, and the system being evaluated off-line is only evaluated on that sub-dialog.", 
        "135": "In other words, in our case, reporting dialog accuracy would favor the HCN because it would be evaluated on fewer turns than the rule-based system.", 
        "136": "We therefore\nuse a comparative measure that examines which method produces longer continuous sequences of correct system actions, starting from the beginning of the dialog.", 
        "137": "Specifically, we report \u2206P = C(HCN-win)\u2212C(rule-win) C(all) , where C(HCN-win) is the number of test dialogs where the rule-based approach output a wrong action before the HCN; C(rule-win) is the number of test dialogs where the HCN output a wrong action before the rulebased approach; and C(all) is the number of dialogs in the test set.", 
        "138": "When \u2206P > 0, there are more dialogs in which HCNs produce longer continuous sequences of correct actions starting from the beginning of the dialog.", 
        "139": "We run all experiments 5 times, each time shuffling the order of the training set.", 
        "140": "Results are in Figure 3.", 
        "141": "HCNs exceed performance of the existing rule-based system after about 30 dialogs.", 
        "142": "In these domains, we have a further source of knowledge: the rule-based dialog managers themselves can be used to generate example \u201csunnyday\u201d dialogs, where the user provides purely expected inputs.", 
        "143": "From each rule-based controller, synthetic dialogs were sampled to cover each expected user response at least once, and added to the set of labeled real dialogs.", 
        "144": "This resulted in 75 dialogs for the \u201cForgot password\u201d domain, and 325 for the \u201cCan\u2019t access account\u201d domain.", 
        "145": "Training was repeated as described above.", 
        "146": "Results are also included in Figure 3, with the suffix \u201csampled\u201d.", 
        "147": "In the \u201cCan\u2019t access account\u201d domain, the sampled dialogs yield a large improvement, probably because the flow chart for this domain is large, so the sampled dialogs increase coverage.", 
        "148": "The gain in the \u201cforgot password\u201d domain is present but smaller.", 
        "149": "In summary, HCNs can out-perform\n\u0394P\nproduction-grade rule-based systems with a reasonable number of labeled dialogs, and adding synthetic \u201csunny-day\u201d dialogs improves performance further.", 
        "150": "Moreover, unlike existing pipelined approaches to dialog management that rely on an explicit state tracker, this HCN used no explicit state tracker, highlighting an advantage of the model.", 
        "151": "6 Reinforcement learning illustration  In the previous sections, supervised learning (SL) was applied to train the LSTM to mimic dialogs provided by the system developer.", 
        "152": "Once a system operates at scale, interacting with a large number of users, it is desirable for the system to continue to learn autonomously using reinforcement learning (RL).", 
        "153": "With RL, each turn receives a measurement of goodness called a reward; the agent explores different sequences of actions in different situations, and makes adjustments so as to maximize the expected discounted sum of rewards, which is called the return, denoted G.\nFor optimization, we selected a policy gradient approach (Williams, 1992), which has been successfully applied to dialog systems (Jurc\u030c\u0131\u0301c\u030cek et al., 2011), robotics (Kohl and Stone, 2004), and the board game Go (Silver et al., 2016).", 
        "154": "In policy gradient-based RL, a model \u03c0 is parameterized by w and outputs a distribution from which actions are sampled at each timestep.", 
        "155": "At the end of a trajectory \u2013 in our case, dialog \u2013 the return G for\nthat trajectory is computed, and the gradients of the probabilities of the actions taken with respect to the model weights are computed.", 
        "156": "The weights are then adjusted by taking a gradient step proportional to the return:\nw\u2190 w+\u03b1( \u2211\nt\nOw log \u03c0(at|ht;w))(G\u2212b) (1)\nwhere \u03b1 is a learning rate; at is the action taken at timestep t; ht is the dialog history at time t; G is the return of the dialog; OxF denotes the Jacobian of F with respect to x; b is a baseline described below; and \u03c0(a|h;w) is the LSTM \u2013 i.e., a stochastic policy which outputs a distribution over a given a dialog history h, parameterized by weights w. The baseline b is an estimate of the average return of the current policy, estimated on the last 100 dialogs using weighted importance sampling.5 Intuitively, \u201cbetter\u201d dialogs receive a positive gradient step, making the actions selected more likely; and \u201cworse\u201d dialogs receive a negative gradient step, making the actions selected less likely.", 
        "157": "SL and RL correspond to different methods of updating weights, so both can be applied to the same network.", 
        "158": "However, there is no guarantee that the optimal RL policy will agree with the SL training set; therefore, after each RL gradient step, we\n5The choice of baseline does not affect the long-term convergence of the algorithm (i.e., the bias), but can dramatically affect the speed of convergence (i.e., the variance) (Williams, 1992).", 
        "159": "check whether the updated policy reconstructs the training set.", 
        "160": "If not, we re-run SL gradient steps on the training set until the model reproduces the training set.", 
        "161": "Note that this approach allows new training dialogs to be added at any time during RL optimization.", 
        "162": "We illustrate RL optimization on a simulated dialog task in the name dialing domain.", 
        "163": "In this system, a contact\u2019s name may have synonyms (\u201cMichael\u201d may also be called \u201cMike\u201d), and a contact may have more than one phone number, such as \u201cwork\u201d or \u201cmobile\u201d, which may in turn have synonyms like \u201ccell\u201d for \u201cmobile\u201d.", 
        "164": "This domain has a database of names and phone numbers taken from the Microsoft personnel directory, 5 entity types \u2013 firstname, nickname, lastname, phonenumber, and phonetype \u2013 and 14 actions, including 2 API call actions.", 
        "165": "Simple entity logic was coded, which retains the most recent copy of recognized entities.", 
        "166": "A simple action mask suppresses impossible actions, such as placing a phonecall before a phone number has been retrieved from the database.", 
        "167": "Example dialogs are provided in Appendix Section A.7.", 
        "168": "To perform optimization, we created a simulated user.", 
        "169": "At the start of a dialog, the simulated user randomly selected a name and phone type, including names and phone types not covered by the dialog system.", 
        "170": "When speaking, the simulated user can use the canonical name or a nickname; usually answers questions but can ignore the system; can provide additional information not requested; and can give up.", 
        "171": "The simulated user was parameterized by around 10 probabilities, set by hand.", 
        "172": "We defined the reward as being 1 for successfully completing the task, and 0 otherwise.", 
        "173": "A discount of 0.95 was used to incentivize the system to complete dialogs faster rather than slower, yielding return 0 for failed dialogs, and G = 0.95T\u22121 for successful dialogs, where T is the number of system turns in the dialog.", 
        "174": "Finally, we created a set of 21 labeled dialogs, which will be used for supervised learning.", 
        "175": "For the RNN in the HCN, we again used an LSTM with AdaDelta, this time with 32 hidden units.", 
        "176": "RL policy updates are made after each dialog.", 
        "177": "Since a simulated user was employed, we did not have real user utterances, and instead relied on context features, omitting bag-of-words and utterance embedding features.", 
        "178": "We first evaluate RL by randomly initializing an\nLSTM, and begin RL optimization.", 
        "179": "After 10 RL updates, we freeze the policy, and run 500 dialogs with the user simulation to measure task completion.", 
        "180": "We repeat all of this for 100 runs, and report average performance.", 
        "181": "In addition, we also report results by initializing the LSTM using supervised learning on the training set, consisting of 1, 2, 5, or 10 dialogs sampled randomly from the training set, then running RL as described above.", 
        "182": "Results are in Figure 4.", 
        "183": "Although RL alone can find a good policy, pre-training with just a handful of labeled dialogs improves learning speed dramatically.", 
        "184": "Additional experiments, not shown for space, found that ablating the action mask slowed training, agreeing with Williams (2008).", 
        "185": "Finally, we conduct a further experiment where we sample 10 training dialogs, then add one to the training set just before RL dialog 0, 100, 200, ... , 900.", 
        "186": "Results are shown in Figure 4.", 
        "187": "This shows that SL dialogs can be introduced as RL is in progress \u2013 i.e., that it is possible to interleave RL and SL.", 
        "188": "This is an attractive property for practical systems: if a dialog error is spotted by a developer while RL is in progress, it is natural to add a training dialog to the training set.", 
        "189": "7 Conclusion  This paper has introduced Hybrid Code Networks for end-to-end learning of task-oriented dialog\nsystems.", 
        "190": "HCNs support a separation of concerns where procedural knowledge and constraints can be expressed in software, and the control flow is learned.", 
        "191": "Compared to existing end-to-end approaches, HCNs afford more developer control and require less training data, at the expense of a small amount of developer effort.", 
        "192": "Results in this paper have explored three different dialog domains.", 
        "193": "On a public benchmark in the restaurants domain, HCNs exceeded performance of purely learned models.", 
        "194": "Results in two troubleshooting domains exceeded performance of a commercially deployed rule-based system.", 
        "195": "Finally, in a name-dialing domain, results from dialog simulation show that HCNs can also be optimized with a mixture of reinforcement and supervised learning.", 
        "196": "In future work, we plan to extend HCNs by incorporating lines of existing work, such as integrating the entity extraction step into the neural network (Dhingra et al., 2017), adding richer utterance embeddings (Socher et al., 2013), and supporting text generation (Sordoni et al., 2015).", 
        "197": "We will also explore using HCNs with automatic speech recognition (ASR) input, for example by forming features from n-grams of the ASR n-best results (Henderson et al., 2014b).", 
        "198": "Of course, we also plan to deploy the model in a live dialog system.", 
        "199": "More broadly, HCNs are a general model for stateful control, and we would be interested to explore applications beyond dialog systems \u2013 for example, in NLP medical settings or humanrobot NL interaction tasks, providing domain constraints are important for safety; and in resourcepoor settings, providing domain knowledge can amplify limited data.", 
        "200": "A Supplemental Material  A.1 Model implementation details The RNN was specified using Keras version 0.3.3, with back-end computation in Theano version 0.8.0.dev0 (Theano Development Team, 2016; Chollet, 2015).", 
        "201": "The Keras model specification is given below.", 
        "202": "The input variable obs includes all features from Figure 1 step 6 except for the previous action (step 18) and the action mask (step 6, top-most vector).", 
        "203": "# Given: # obs_size, action_size, nb_hidden\ng = Graph() g.add_input(\nname=\u2019obs\u2019, input_shape=(None, obs_size)\n) g.add_input(\nname=\u2019prev_action\u2019, input_shape=(None, action_size)\n) g.add_input(\nname=\u2019avail_actions\u2019, input_shape=(None, action_size)\n) g.add_node(\nLSTM( n_hidden, return_sequences=True, activation=\u2019tanh\u2019, ), name=\u2019h1\u2019, inputs=[ \u2019obs\u2019, \u2019prev_action\u2019, \u2019avail_actions\u2019\n] ) g.add_node(\nTimeDistributedDense( action_size,\nactivation=\u2019softmax\u2019, ), name=\u2019h2\u2019, input=\u2019h1\u2019\n) g.add_node( Activation(\nactivation=normalize, ), name=\u2019action\u2019, inputs=[\u2019h2\u2019,\u2019avail_actions\u2019], merge_mode=\u2019mul\u2019, create_output=True\n) g.compile( optimizer=Adadelta(clipnorm=1.", 
        "204": "), sample_weight_modes={\n\u2019action\u2019: \u2019temporal\u2019 }, loss={\n\u2019action\u2019:\u2019categorical_crossentropy\u2019 }\n)\nModel sizes are given in Table 3.", 
        "205": "Example dialogs are given below for each of the 5 dialog systems.", 
        "206": "For space and readability, the entity tags that appear in the user and system sides of the dialogs have been removed \u2013 for example, Call <name>Joan</name> is shown as Call Joan.", 
        "207": "A.2 bAbI Task5 example dialog\ngood morning hello what can i help you with today i\u2019d like to book a table with italian food i\u2019m on it [silence] where should it be in paris how many people would be in your party for six people please which price range are looking for in a cheap price range please ok let me look into some options for you [silence] api_call italian paris six cheap [database results returned] [silence] what do you think of this option: resto madrid cheap spanish 8stars no this does not work for me sure let me find an other option for you [silence] what do you think of this option: resto madrid cheap spanish 6stars do you have something else sure let me find an other option for you [silence] what do you think of this option: resto madrid cheap spanish 1stars it\u2019s perfect great let me do the reservation may i have the phone number of the restaurant here it is resto madrid cheap spanish 1stars phone\nbAbI Task5 bAbI Task6 Reset password Account access Dialer Utterance embed.", 
        "208": "300 300 300 300 0 Bag of words 85 523 1124 278 0 Context features 4 14 0 0 17\nobs_size 389 837 1424 578 17 action_size 16 58 7 16 14 nb_hidden 128 128 128 128 32\nA.3 bAbI Task6 example dialog In the system turn marked [*], the system provided venue information without first making an API call.", 
        "209": "Hello , welcome to the Cambridge restaurant system .", 
        "210": "You can ask for restaurants by area , price range or food type .", 
        "211": "How may I help you ?", 
        "212": "im looking for canapes food in any price range I am sorry but there is no canapes restaurant that matches your request [*] how about european api_call european R_location R_price [database results returned] [silence] michaelhouse cafe is a great restaurant serving european food and it is in the expensive price range food an What part of town do you have in mind?", 
        "213": "any any part of town michaelhouse cafe serves european food .", 
        "214": "may i have the address and phone number please The phone number of michaelhouse cafe is michaelhouse cafe phone thank you good bye you are welcome\nA.4 Task5 and Task6 context features Context features used in Section 4 are in Table 4.", 
        "215": "A.5 Forgot password example dialog Some system actions have been shortened for space.", 
        "216": "How do I recover my password Okay, you don\u2019t need to remember your password, we can reset it.", 
        "217": "Would you like to try that?", 
        "218": "Yes To reset your password, please see this URL ... Was that helpful?", 
        "219": "A.6 Account access example dialog\nSome system actions have been shortened for space.", 
        "220": "cannot sign in to my email Please check caps lock is off, and that your email is spelled correctly.", 
        "221": "Are you able to access your account now?", 
        "222": "no If you still can\u2019t sign in, please go the the following page and check that the email server is running ok... Is everything up and running?", 
        "223": "yes You need to reset your password - here\u2019s how ... Did this solve your problem?", 
        "224": "still cannot get in Did you receive the security code?", 
        "225": "yes Check you entered the right numbers.", 
        "226": "Did this solve your problem?", 
        "227": "no Have you seen a message that your profile is temporarily blocked?", 
        "228": "just your message of update on sept 15 Did you turn on two-step verification recently?", 
        "229": "whats that?", 
        "230": "Sorry, I can\u2019t help.", 
        "231": "Rephrase your question, or click below to talk to a person.", 
        "232": "A.7 Name dialing example dialogs\nHow can I help you?", 
        "233": "Call Joe There\u2019s more than one person named Joe.", 
        "234": "Can you say their full name?", 
        "235": "Call Joe Adamson SavePhonetypeavail() Calling Joe Adamson, work PlaceCall()\nHow can I help you?", 
        "236": "Call Sally on her home\nSorry, I don\u2019t have a home number for Sally Smith.", 
        "237": "I only have a work phone.", 
        "238": "Do you want to call that number?", 
        "239": "no Oh, sorry about that.", 
        "240": "Goodbye."
    }, 
    "document_id": "P17-1062.pdf.json"
}
