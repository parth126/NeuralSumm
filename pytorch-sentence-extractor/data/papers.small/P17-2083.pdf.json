{
    "abstract_sentences": {
        "1": "We propose a novel generative neural network architecture for Dialogue Act classification.", 
        "2": "Building upon the Recurrent Neural Network framework, our model incorporates a new attentional technique and a label-to-label connection for sequence learning, akin to Hidden Markov Models.", 
        "3": "Our experiments show that both of these innovations enable our model to outperform strong baselines for dialogue-act classification on the MapTask and Switchboard corpora.", 
        "4": "In addition, we analyse empirically the effectiveness of each of these innovations."
    }, 
    "body_sentences": {
        "1": "  Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 524\u2013529 Vancouver, Canada, July 30 - August 4, 2017. c\u00a92017 Association for Computational Linguistics\nhttps://doi.org/10.18653/v1/P17-2083  1 Introduction  Dialogue Act (DA) classification is a sequenceto-sequence learning task where a sequence of utterances is mapped into a sequence of DAs.", 
        "2": "Some works in DA classification treat each utterance as an independent instance (Julia et al., 2010; Gamba\u0308ck et al., 2011), which leads to ignoring important long-range dependencies in the dialogue history.", 
        "3": "Other works have captured inter-utterance relationships using models such as Hidden Markov Models (HMMs) (Stolcke et al., 2000; Surendran and Levow, 2006) or Recurrent Neural Networks (RNNs) (Kalchbrenner and Blunsom, 2013; Ji et al., 2016), where RNNs have been particularly successful.", 
        "4": "In this paper, we present a generative model of utterances and dialogue acts which conditions on the relevant part of the dialogue history.", 
        "5": "To this effect, we use the attention mechanism (Bahdanau et al., 2014) developed originally for sequence-tosequence models, which has proven effective in Machine Translation (Bahdanau et al., 2014; Luong et al., 2015) and DA classification (Shen and\nLee, 2016).", 
        "6": "The intuition is that different parts of an input sequence have different levels of importance with respect to the objective, and this mechanism enables the selection of the important parts.", 
        "7": "However, the traditional attention mechanism suffers from the attention-bias problem (Wang et al., 2016), where the attention mechanism tends to favor the inputs at the end of a sequence.", 
        "8": "To address this problem, we propose a gated attention mechanism, where the attention signal is represented as a gate over the input vector.", 
        "9": "In addition, when generating a dialogue act, we capture its direct dependence on the previous dialogue act \u2014 a reasonable source of information, which, surprisingly, has not been explored in the RNN literature for DA classification.", 
        "10": "Our experiments show that our model significantly outperforms variants that do not have our innovations, i.e., the gated attention mechanism and direct label-to-label dependency.", 
        "11": "2 Model Description  Assume that we have a training dataset D comprising a collection of dialogues, where each dialogue consists of a sequence of utterances {yt}Tt=1 and the corresponding sequence of dialogue acts {zt}Tt=1.", 
        "12": "Each utterance yt is a sequence of tokens, and its n-th token is denoted yt,n.", 
        "13": "We propose a generative neural model for dialogue P\u0398(y1:T , z1:T ), which specifies a joint probability distribution over a sequence of utterances y1:T and the corresponding sequence of dialogue acts z1:T .", 
        "14": "This generative model is then trained discriminatively by maximising the conditional log-likelihood\u2211\n(z1:T ,y1:T )\u2208D logP\u0398(z1:T |y1:T ):\narg max \u0398\n\u2211\n(y1:T ,z1:T )\u2208D log P\u0398(y1:T , z1:T )\u2211 z\u20321:T P\u0398(y1:T , z \u2032 1:T )\n524\nwhere \u0398 represents all neural network parameters.", 
        "15": "Discriminative training is employed in order to match the use of the model for predicting dialogue acts during test time, using arg maxz\u20321:T P\u0398(z \u2032 1:T |y1:T ).", 
        "16": "The generative story of our model is as follows: (1) generate the dialogue act of the current dialogue turn conditioned on the previous dialogue act and the previous utterance P\u0398(zt|zt\u22121,yt\u22121); and (2) generate the current utterance conditioned on the previous utterance and the current dialogue act P\u0398(yt|zt,yt\u22121).", 
        "17": "In other words, P\u0398(z1:T ,y1:T ) is decomposed as:\nT\u220f\nt=1\nP\u0398(zt|zt\u22121,yt\u22121)P\u0398(yt|zt,yt\u22121).", 
        "18": "(1)\nFurthermore, each utterance is generated by a sequential process whereby each token yt,n is conditioned on all the previously generated tokens yt,<n, as well as the external conditioning context consisting of the dialogue act zt and the previous turn\u2019s utterance yt\u22121, i.e.,\nP\u0398(yt|zt,yt\u22121) = |yt|\u220f\nn=1\nP\u0398(yt,n|yt,<n, zt,yt\u22121).", 
        "19": "(2)\nImportantly, the decomposition of the joint distribution in Equation 1 allows dynamic programming for exact decoding (\u00a72.2).", 
        "20": "One possible extension of our framework is to investigate a higher-order Markov model, although one needs to be conscious about the trade-off between the increase in the computational complexity of training/decoding with higher-order Markov models versus the potential gain in classification quality.", 
        "21": "We now turn our attention to the neural architecture used to realise the components of our probabilistic model (Figure 1).", 
        "22": "We define the neural\nmodel for the conditional probability of the next dialogue act as follows:\nP\u0398(zt|zt\u22121,yt\u22121) = softmax(W (zt\u22121)cz ct + b (zt\u22121) z ),\n(3)\nwhere ct is the context vector summarising the information from the previous utterance yt\u22121, and W (zt\u22121) cz and b (zt\u22121) z are the softmax parameter gated on the previous dialogue act zt\u22121.", 
        "23": "Due to gating, the number of parameters of the model may increase significantly; therefore, we have also explored a variant where only the bias term b(zt\u22121)z is gated.", 
        "24": "We define the neural model for generating the tokens of the current utterance as follows:\nP\u0398(yt,n|yt,<n, zt,yt\u22121) = softmax(W (zt)hy ht,n\u22121 + Wcct + by), (4)\nwhere the weight matrix W (zt)hy is gated based on zt, ct summarises the previous utterance, and ht,n\u22121 is the state of an utterance-level RNN summarising all the previously generated tokens:\nht,n\u22121 = f (ht,n\u22122,Eyt,n\u22121), (5)\nwhere Eyt,n\u22121 provides the embedding of the token yt,n\u22121 from the embedding table E , and f can be any non-linear function, i.e., the simple sigmoid applied to elements of a vector, or the more complex Long-Short-TermMemory unit (LSTM) (Graves, 2013; Hochreiter and Schmidhuber, 1997), or the Gated-RecurrentUnit (GRU) (Chung et al., 2014; Cho et al., 2014).", 
        "25": "In what follows, we elaborate on how to best summarise the information from the previous utterance in ct, and how to decode for the best sequence of dialogue acts given a trend model.", 
        "26": "2.1 The Gated Attention Mechanism  Given a sequence of words in an utterance {y1, .", 
        "27": ".", 
        "28": ".", 
        "29": ", yn}, we would like to compress its information in c, which is then used in the conditioning contexts of other components of the model.", 
        "30": "Typically, the last hidden state of the utterance-level RNN is taken to be the summary vector: c = hn.", 
        "31": "However, it has been shown that attending to all RNN states is more effective.", 
        "32": "The traditional attention mechanism (Bahdanau et al., 2014) employs a probability vector a over the words of the input utterance to summarise it.", 
        "33": "The attention elements in a are typically calculated from the current input yn, and the previous hidden state hn\u22121:\n\u03b1n = g(hn\u22121,Eyn) , an = e\u03b1n\u2211n\nn\u2032=1 e \u03b1n\u2032\n,\nwhere g is a non-linear function.", 
        "34": "Once the attention is defined, the representation of the input is constructed as\nc = \u2211\nn\nanhn.", 
        "35": "(6)\nThe problem with this traditional attention model is that the final hidden state is a function of all the inputs, hence it is usually more \u201cinformative\u201d than the earlier hidden states due to semantic accumulation (Wang et al., 2016).", 
        "36": "Thus, most of the attention signal is assigned to the hidden states toward the end of a sequence.", 
        "37": "In DA classification, this may not be desirable, since an important token with respect to a dialogue act can appear anywhere in an utterance.", 
        "38": "We call this the attention bias problem.", 
        "39": "We propose a novel gated attention mechanism, which is inspired by the gating mechanism in LSTMs, to fix the attention bias problem.", 
        "40": "Similar to the forget gate of LSTMs, we use the available information to calculate an attention gate that learns whether to allow the whole input signal to pass through or to forget all or a part of the input signal:\nan = g(hn\u22121,Eyn) (7) xn = an Eyn (8) hn = f (hn\u22121,xn) (9)\nwhere represents element-wise multiplication.", 
        "41": "After filtering the important signal from the input token, the information from our tokens is accumulated in the last hidden state of the RNN, which\nwe take as the summary vector c = hn.", 
        "42": "Note that since the gated attention is applied to the input before the RNN calculations, it is not affected by the attention bias.", 
        "43": "2.2 Inference: Viterbi Decoding  For prediction, we choose the sequence of dialogue acts with the highest posterior probability:\narg max z\u20321:T\nP\u0398(z \u2032 1:T |y1:T )=arg max\nz\u20321:T P\u0398(z\n\u2032 1:T ,y1:T )\nSince the joint probability is decomposed further according to Equation 1, we can make use of dynamic programming to find the highest probability sequence of dialogue acts.", 
        "44": "Specifically, the model endows each latent variable zt with a unary potential P\u0398(yt|zt,yt\u22121) and binary potential P\u0398(zt|zt\u22121,yt\u22121) functions.", 
        "45": "P\u0398(yt|zt,yt\u22121) and P\u0398(zt|zt\u22121,yt\u22121) are akin to the emission and transition functions of an HMM, and are calculated using Equations 2 and 3 respectively.", 
        "46": "Furthermore, the model has been carefully designed so that the hidden states in the RNNs encoding the utterances to form the context vector ct (the representation of the previous utterance) are not affected by the sequence of dialogue acts, which is crucial to making the inference amenable to dynamic programming.", 
        "47": "The resulting inference algorithm is akin to the Viterbi algorithm for HMMs.", 
        "48": "3 Experiments  Datasets.", 
        "49": "We conduct our experiments on the MapTask and Switchboard corpora.", 
        "50": "The MapTask Dialog Act corpus (Anderson et al., 1991) consists of 128 conversations and more than 27000 utterances in an instruction-giving scenario.", 
        "51": "There are 13 DA types in this corpus.", 
        "52": "For the experiments, the available data is split into three parts, train/test/validation with 103, 13 and 12 conversations respectively.", 
        "53": "The Switchboard Dialog Act corpus (Jurafsky et al., 1997) consists of 1155 transcribed telephone conversations with around 205000 utterances.", 
        "54": "In contrast with the MapTask conversations, which are task-oriented, the Switchboard corpus consists mostly of general topic conversations.", 
        "55": "The Switchboard tag set has 42 DAs.1\n1The original size of the tag set for Switchboard is 226, which was then collapsed into 42\nBaselines.", 
        "56": "On MapTask, to the best of our knowledge, there is no standard data split, thus, we make the comparison against our implementation of strong baselines such as HMM-trigram (Stolcke et al., 2000) and instance-based random forest classifier (1/2/3-gram features).", 
        "57": "Ji et al.\u2019s (2016) results for this corpus are obtained by running their publicly available code with the same hyper parameters as those used by our models.", 
        "58": "We also report the results of Julia et al.", 
        "59": "(2010)2 and Surendran et al.", 
        "60": "(2006).", 
        "61": "However, the experimental setup of these two works differs from ours, hence their results are not directly comparable to ours.", 
        "62": "On Switchboard, we compare our results with strong baselines using the experimental setup from Kalchbrenner and Blunsom (2013) and Stolcke et al.", 
        "63": "(2000).3\nOur Model Configurations.", 
        "64": "We experiment with several variants of our model to explore the effectiveness of our two improvements: the HMM-like connection and the gated attention mechanism.", 
        "65": "For the HMM connection, we consider three choices: gating all parameters (Equation 3), gating only the bias, and no connection.", 
        "66": "For the attention, we consider three choices: our new gated attention mechanism, the traditional attention, and no attention.", 
        "67": "Thus, in total, we explore nine model variants.", 
        "68": "All the model variants are implemented with the CNN package4 and trained with Adagrad (Duchi et al., 2011) using dropout (Srivastava et al., 2014).", 
        "69": "They share the same word-embedding size (128) and hidden vector size (64).5\n2Julia et al.", 
        "70": "(2010) employed both text transcription and audio signal.", 
        "71": "Here, we report the results obtained with the transcription.", 
        "72": "3There have been other works with different experimental setups (Gamba\u0308ck et al., 2011; Webb and Ferguson, 2010) that obtained accuracies ranging from 77.85% to 80.72%.", 
        "73": "However, these results are not directly comparable to ours.", 
        "74": "4https://github.com/clab/cnn-v1.", 
        "75": "5The experiments were executed on an Intel Xeon E52667 CPU with 16GB of RAM.", 
        "76": "The training time for each MapTask model is less than a day, the training time for each Switchboard model takes up to four weeks.", 
        "77": "Results and Analysis.", 
        "78": "Table 1 shows the classification accuracy of the nine variants of our model on the MapTask corpus.", 
        "79": "The classification accuracy of the two best variants of our model and the baselines appears in Tables 2 and 3 for MapTask and Switchboard respectively.", 
        "80": "The bold numbers in each table show the best accuracy achieved by the systems.", 
        "81": "As seen in these tables, our best models outperform strong baselines for both corpora.6\nTable 1 shows that adding the attention mechanism is beneficial, as the traditional attention models always outperform their non-attention counterparts.", 
        "82": "The gated attention configurations, in turn, outperform those with the traditional attention mechanism by 0.49%-1.21%.", 
        "83": "Interestingly, the accuracy of Shen and Lee\u2019s (2016) classifier, which employs an attention mechanism, is lower than that obtained by Kalchbrenner and Blunsom (2013), whose mechanism does not use attention.", 
        "84": "We believe that the difference in performance is not due to the attention mechanism being ineffective, but because Shen and Lee (2016) treat the classification of each utterance independently.", 
        "85": "In contrast, Kalchbrenner and Blunsom (2013) take\n6Ji et al.", 
        "86": "(2016) reported an accuracy of 77.0% on the Switchboard corpus, but their paper does not provide enough information about the experimental setup to replicate this result (hyper-parameters, train/test/development split).", 
        "87": "Thus, we ran the paper\u2019s publicly available code with our experimental settings, and report the result in our comparison.", 
        "88": "the sequential nature of dialog acts into account, and run an RNN across the conversation, which conditions the generation of a dialogue act on the dialogue acts and utterances in all the previous dialogue turns.", 
        "89": "As seen in Table 1, the performance gain from the HMM connection is larger than the gain from the attention mechanism.", 
        "90": "Without the attention mechanism, the HMM connection brings an increase of 3.63% with the gated bias HMM configuration and 2.58% with the fully gated HMM configuration.", 
        "91": "With the use of traditional attention, the improvement is 3.01% for the bias HMM configuration and 3.47% for the gated HMM configuration.", 
        "92": "Finally with the gated attention in place, the two HMM configurations improve the accuracy by 3.73%.", 
        "93": "We used McNemar\u2019s test to determine the statistical significance between the predictions of different models, and found that our model with both innovations (HMM connections and gated attention) is statistically significantly better than the variant without these innovations with \u03b1 < 0.01.", 
        "94": "4 Conclusions  In this work, we have proposed a new gated attention mechanism and a novel HMM-like connection in a generative model of utterances and dialogue acts.", 
        "95": "Our experiments show that these two innovations significantly improve the accuracy of DA classification on the MapTask and Switchboard corpora.", 
        "96": "In the future, we plan to apply these two innovations to other sequence-tosequence learning tasks.", 
        "97": "Furthermore, DA classification itself can be seen as a preprocessing step in a dialogue system\u2019s pipeline.", 
        "98": "Thus, we also plan to investigate the effect of improvements in DA classification on the downstream components of a dialogue system."
    }, 
    "document_id": "P17-2083.pdf.json"
}
