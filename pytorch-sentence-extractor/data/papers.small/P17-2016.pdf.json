{
    "abstract_sentences": {
        "1": "We provide several methods for sentencealignment of texts with different complexity levels.", 
        "2": "Using the best of them, we sentence-align the Newsela corpora, thus providing large training materials for automatic text simplification (ATS) systems.", 
        "3": "We show that using this dataset, even the standard phrase-based statistical machine translation models for ATS can outperform the state-of-the-art ATS systems."
    }, 
    "body_sentences": {
        "1": "  Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 97\u2013102 Vancouver, Canada, July 30 - August 4, 2017. c\u00a92017 Association for Computational Linguistics\nhttps://doi.org/10.18653/v1/P17-2016  1 Introduction  Automated text simplification (ATS) tries to automatically transform (syntactically, lexically and/or semantically) complex sentences into their simpler variants without significantly altering the original meaning.", 
        "2": "It has attracted much attention recently as it could make texts more accessible to wider audiences (Alu\u0131\u0301sio and Gasperin, 2010; Saggion et al., 2015), and used as a pre-processing step, improve performances of various NLP tasks and systems (Vickrey and Koller, 2008; Evans, 2011; S\u030ctajner and Popovic\u0301, 2016).", 
        "3": "However, the state-of-the-art ATS systems still do not reach satisfying performances and require some human post-editing (S\u030ctajner and Popovic\u0301, 2016).", 
        "4": "While the best supervised approaches generally lead to grammatical output with preserved original meaning, they are overcautious, making almost no changes to the input sentences (Specia, 2010; S\u030ctajner et al., 2015), probably due to the limited size or bad quality of parallel TS corpora used for training.", 
        "5": "The largest existing sentence-aligned TS dataset for English is the English Wikipedia \u2013 Simple English Wikipedia\n(EW\u2013SEW) dataset, which contains 160-280,000 sentence pairs, depending on whether we want to model only traditional sentence rewritings or also to model content reduction and stronger paraphrasing (Hwang et al., 2015).", 
        "6": "For Spanish, the largest existing parallel TS corpus contains only 1,000 sentence pairs thus impeding the use of fully supervised approaches.", 
        "7": "The best unsupervised lexical simplification (LS) systems for English which leverage word-embeddings (Glavas\u030c and S\u030ctajner, 2015; Paetzold and Specia, 2016) seem to perform more lexical substitutions but at the cost of having less grammatical output and more often changed meaning.", 
        "8": "However, there have been no direct comparisons of supervised and unsupervised state-of-the-art approaches so far.", 
        "9": "The Newsela corpora1 offers over 2,000 original news articles in English and around 250 in Spanish, manually simplified to 3\u20134 different complexity levels following strict guidelines (Xu et al., 2015).", 
        "10": "Although it was suggested that it has better quality than the EW\u2013SEW corpus (Xu et al., 2015), Newsela has not yet been used for training end-to-end ATS systems, due to the lack of its sentence (and paragraph) alignments.", 
        "11": "Such alignments, between various text complexity levels, would offer large training datasets for modelling different levels of simplification, i.e.", 
        "12": "\u2018mild\u2019 simplifications (using the alignments from the neighbouring levels) and \u2018heavy\u2019 simplifications (using the alignments of level pairs: 0\u20133, 0\u20134, 1\u20134).", 
        "13": "Contributions.", 
        "14": "We: (1) provide several methods for paragraph- and sentence alignment of parallel texts, and for assessing similarity level between pairs of text snippets, as freely avail-\n1Freely available: https://newsela.com/data/\n97\nable software;2 (2) compare the performances of lexically- and semantically-based alignment methods across various text complexity levels; (3) test the hypothesis that the original order of information is preserved during manual simplification (Bott and Saggion, 2011) by offering customized MST-LIS alignment strategy (Section 3.1); and (4) show that the new sentence-alignments lead to the state-of-the-art ATS systems even in a basic phrase-based statistical machine translation (PBSMT) approach to text simplifications.", 
        "15": "2 Related Work  The current state-of-the-art systems for automatic sentence-alignment of original and manually simplified texts are the GSWN method (Hwang et al., 2015) used for sentence-alignment of original and simple English Wikipedia, and the HMMbased method (Bott and Saggion, 2011) used for sentence-alignment of the Spanish Simplext corpus (Saggion et al., 2015).", 
        "16": "The HMM-based method can be applied to any language as it does not require any languagespecific resources.", 
        "17": "It is based on two hypotheses: (H1) that the original order of information is preserved, and (H2) that every \u2018simple\u2019 sentence has at least one corresponding \u2018original\u2019 sentence (it can have more than one in the case of \u2018n-1\u2019 or \u2018nm\u2019 alignments).", 
        "18": "As Simple Wikipedia does not represent direct simplification of the \u2018original\u2019 Wikipedia articles (\u2018simple\u2019 articles were written independently of the \u2018original\u2019 ones), GSWN method does not assume H1 or H2.", 
        "19": "The main limitations of this method are that it only allows for \u20181-1\u2019 sentence alignments \u2013 which is very restricting for TS as it does not allow for sentence splitting (\u20181-n\u2019), and summarisation and compression (\u2018n-1\u2019 and \u2018n-m\u2019) alignments \u2013 and it is language-dependent as it requires English Wiktionary.", 
        "20": "Unlike the GSWN method, all the methods we apply are language-independent, resource-light and allow for \u20181-n\u2019, \u2018n-1\u2019, and \u2018n-m\u2019 alignments.", 
        "21": "Similar to the HMM-method, our methods assume the hypothesis H2.", 
        "22": "We provide them in both variants, using the hypothesis H1 and without it (Section 3.1).", 
        "23": "2https://github.com/neosyon/ SimpTextAlign  3 Approach  Having a set of \u2018simple\u2019 text snippets S and a set of \u2018complex\u2019 text snippets C, we offer two strategies (Section 3.1) to obtain the alignments (si, cj), where si \u2208 S, cj \u2208 C. Each alignment strategy, in turn, can use one of the three methods (Section 3.2) to calculate similarity scores between text snippets (either paragraphs or sentences).", 
        "24": "3.1 Alignment strategies  Most Similar Text (MST): Given one of the similarity methods (Section 3.2), MST compares similarity scores of all possible pairs (si, cj), and aligns each si \u2208 S with the closest one in C. MST with Longest Increasing Sequence (MSTLIS): MST-LIS uses the hypothesis H1.", 
        "25": "It first uses the MST strategy, and then postprocess the output by extracting \u2013 from all obtained alignments \u2013 only those alignments li \u2208 L, which contain the longest increasing sequence of offsets jk in C. In order to allow for \u20181\u2013n\u2019 alignments (i.e.", 
        "26": "sentence splitting), we allow for repeated offsets of C (\u2018complex\u2019 text snippets) in L. The \u2018simple\u2019 text snippets not contained in L are included in the set U of unaligned snippets.", 
        "27": "Finally, we align each um \u2208 U by restricting the search space in C to those offsets of \u2018complex\u2019 text snippets that correspond to the previous and the next aligned \u2018simple\u2019 snippets.", 
        "28": "For instance, if L = {(s1, c4), (s3, c7)} and U = {s2}, then the search space for the alignments of s2 is reduced to {c4...c7}.", 
        "29": "We denote this strategy with an \u2018*\u2019 in the results (Table 2), e.g.", 
        "30": "C3G*.", 
        "31": "3.2 Similarity Methods  C3G: We employ the Character N -Gram (CNG) (Mcnamee and Mayfield, 2004) similarity model (for n = 3) with log TF-IDF weighting (Salton and McGill, 1986) and compare vectors using the cosine similarity.", 
        "32": "WAVG: We use the continuous skip-gram model (Mikolov et al., 2013b) of the TensorFlow toolkit3 to process the whole English Wikipedia and generate continuous representations of its words.4 For each text snippet, we average its word vectors to obtain a single representation of its content as this setting has shown good results\n3https://www.tensorflow.org/ 4We use 300-dimensional vectors, context windows of size 10, and 20 negative words for each sample, in all our continuous word-based models.", 
        "33": "in other NLP tasks (e.g.", 
        "34": "for selecting out-of-thelist words (Mikolov et al., 2013a)).", 
        "35": "Finally, the similarity between text snippets is estimated using the cosine similarity.", 
        "36": "CWASA: We employ the Continuous Word Alignment-based Similarity Analysis (CWASA) model (Franco-Salvador et al., 2016), which finds the optimal word alignment by computing cosine similarity between continuous representations of all words (instead of averaging word vectors as in the case of WAVG).", 
        "37": "It was originally proposed for plagiarism detection with excellent results, especially for longer text snippets.", 
        "38": "4 Manual Evaluation  To compare the performances of different alignment methods, we randomly selected 10 original texts (Level 0) and their corresponding simpler versions at Levels 1, 3 and 4.", 
        "39": "Instead of creating a \u2018gold standard\u2019 and then automatically evaluating the performances, we asked two annotators to rate each pair of automatically aligned paragraphs and sentences \u2013 by each of the possible six alignment methods and the HMM-based method (Bott and Saggion, 2011) \u2013 for three pairs of text complexity levels (0\u20131, 0\u20134, and 3\u20134) on a 0\u20132 scale, where: 0 \u2013 no semantic overlap in the content; 1 \u2013 partial semantic overlap (partial matches); 2 \u2013 same semantic content (good matches).", 
        "40": "This resulted in a total of 1526 paragraph- and 1086 sentence-alignments for the 0\u20131 pairs, and 1218 paragraph- and 1266 sentence-alignments for the 0\u20134 and 3\u20134 pairs.", 
        "41": "In the context of TS, both good- and partial matches\nare important.", 
        "42": "While full semantic overlap models full paraphrases (\u20181-1\u2019 alignments), partial overlap models sentence splitting (\u201c1-n\u201d alignments), deleting irrelevant sentence parts, adding explanations, or summarizing (\u2018n-m\u2019 alignments).", 
        "43": "Several examples of full and partial matches from the EW\u2013SEW dataset (Hwang et al., 2015) are given in Table 1.", 
        "44": "We expect that the automatic-alignment task is the easiest between the 0\u20131 text complexity levels, and much more difficult between the 0-4 levels (Level 4 is obtained after four stages of simplification and thus contains stronger paraphrases and less lexical overlap with Level 0 than Level 1 has).", 
        "45": "We also explore whether the task is equally difficult whenever we align two neighbouring levels, or the difficulty of the task depends on the level complexity (0\u20131 vs. 3\u20134).", 
        "46": "The obtained interannotator agreement, weighted Cohen\u2019s \u03ba (on 400 double-annotated instances) was between 0.71 and 0.74 depending on the task and levels.", 
        "47": "The results of the manual analysis (Table 2) showed that: (1) all applied methods significantly (p < 0.001) outperformed the HMM method on both paragraph- and sentence-alignment tasks;5 (2) the methods which do not assume hypothesis H1 (C3G, CWASA, and WAVG) led to (not significantly) higher percentage of correct alignments than their counterparts which do assume\n5Although some of our methods share the same percentage of good+partial matches with the HMM method on the paragraph-alignment 0\u20131 task, there is still significant difference in the obtained scores (in some cases, our methods led to good matches whereas the HMM only led to partial matches).", 
        "48": "H1 (C3G*, CWASA*, WAVG*); (3) the difference in the performances of the lexical approach (C3G) and semantic approaches (CWASA and WAVG) was significant only in the 0\u20134 sentencealignment task, where CWASA performed significantly worse (p < 0.001) than the other two methods, and in the 0\u20134 paragraph-alignment task, where WAVG performed significantly worse than C3G; (4) the 2-step C3G alignment-method (C3G-2s), which first aligns paragraphs using the best paragraph-alignment method (C3G) and then within each paragraph align sentences with the best sentence-alignment method (C3G), led to more good+partial alignments than the \u2018direct\u2019 sentence-alignment C3G method.", 
        "49": "5 Extrinsic Evaluation  Finally, we test our new English Newsela (C3G2s) sentence-alignments (both for the neighbouring levels \u2013 neighb.", 
        "50": "and for all levels \u2013 all) and Newsela sentence-alignments for neighboring levels obtained with HMM-method6 (Bott and Saggion, 2011) in the ATS task using standard PBSMT models7 in the Moses toolkit (Koehn et al., 2007).", 
        "51": "We vary the training dataset and the corpus used to build language models (LMs), while keeping always the same 2,000 sentence pairs for tuning (Xu et al., 2016) and the first 70 sentence\n6Given that the performance of the HMM-method was poor for non-neighboring levels (Table 2).", 
        "52": "7GIZA++ implementation of the IBM word alignment model 4 (Och and Ney, 2003), refinement and phraseextraction heuristics (Koehn et al., 2003), the minimum error rate training (Och, 2003) for tuning, and 5-gram LMs with Kneser-Ney smoothing trained with SRILM (Stolcke, 2002).", 
        "53": "pairs of their test set8 for our human evaluation.", 
        "54": "Using that particular test set allow us to compare our (PBSMT) systems with the output of the stateof-the-art syntax-based MT (SBMT) system for TS (Xu et al., 2016) which is not freely available.", 
        "55": "We compare: (1) the performance of the standard PBSMT model which uses only the already available EW\u2013SEW dataset (Hwang et al., 2015) with the performances of the same PBSMT models but this time using the combination of the EW\u2013SEW dataset and our newly-created Newsela datasets; (2) the latter PBSMT models (which use both EW\u2013SEW and new Newsela datasets) against the state-of-the-art supervised ATS system (Xu et al., 2016), and one of the recently proposed unsupervised lexical simplification systems, the LightLS system (Glavas\u030c and S\u030ctajner, 2015).9\nWe perform three types of human evaluation on the outputs of all systems.", 
        "56": "First, we count the total number of changes made by each system (Total), counting the change of a whole phrase (e.g.", 
        "57": "\u201cbecome defunct\u201d \u2192 \u201cwas dissolved\u201d) as one change.", 
        "58": "We mark as Correct those changes that preserve the original meaning and grammaticality of the sentence (assessed by two native English speakers) and, at the same time, make the sentence easier to understand (assessed by two non-native fluent English speakers).10 Second, three native English speakers rate the grammaticality (G) and meaning preservation (M) of each sentence with at least one change on a 1\u20135 Likert scale (1 \u2013 very bad; 5 \u2013 very good).", 
        "59": "Third, the three nonnative fluent English speakers were shown original (reference) sentences and target (output) sentences (one pair at the time) and asked whether the target sentence is: +2 \u2013 much simpler; +1 \u2013 somewhat simpler; 0 \u2013 equally difficult; -1 \u2013 somewhat more difficult; -2 \u2013 much more difficult, than the reference sentence.", 
        "60": "While the correctness of changes takes into account the influence of each individual change on grammaticality, meaning and simplicity of a sentence, the Scores (G and M) and Rank (S) take into account the mutual influence of all changes within a sentence.", 
        "61": "Adding our sentence-aligned Newsela corpus\n8Both freely available from: https://github.com/ cocoxu/simplification/\n9We use the output of the original SBMT (Xu et al., 2016) and LightLS (Glavas\u030c and S\u030ctajner, 2015) systems, obtained from the authors.", 
        "62": "10Those cases in which the two annotators did not agree are additionally evaluated by a third annotator to obtain majority.", 
        "63": "(either neighb.", 
        "64": "C3G-2l or all C3G-2l) to the currently best sentence-aligned Wiki corpus (Hwang et al., 2015) in a standard PBSMT setup significantly11 improves grammaticality (G) and meaning preservation (M), and increases the percentage of correct changes (Table 3).", 
        "65": "It also significantly outperforms the state-of-the-art ATS systems by simplicity rankings (S), meaning preservation (M), and number of correct changes (Correct), while achieving almost equally good grammaticality (G).", 
        "66": "The level of simplification applied in the training dataset (Newsela neighb.", 
        "67": "C3G-2s vs. Newsela all C3G-2s) significantly influences G and M scores.", 
        "68": "The use of the HMM-method for aligning Newsela (instead of ours) lead to significantly worse simplifications by all five criteria.", 
        "69": "11Wilcoxon\u2019s signed rank test, p < 0.001.", 
        "70": "An example of the outputs of different ATS systems is presented in Table 4.", 
        "71": "6 Conclusions  We provided several methods for paragraphand sentence-alignment from parallel TS corpora, made the software publicly available, and showed that the use of the new sentence-aligned (freely available) Newsela dataset leads to state-of-the-art ATS systems even in a basic PBSMT setup.", 
        "72": "We also showed that lexically-based C3G method is superior to semantically-based methods (CWASA and WAVG) in aligning paraphraphs and sentences with \u2018heavy\u2019 simplifications (0\u20134 alignments), and that 2-step sentence alignment (aligning first paragraphs and then sentences within the paragraphs) lead to more correct alignments than the \u2018direct\u2019 sentence alignment.", 
        "73": "Acknowledgments  This work has been partially supported by the SFB 884 on the Political Economy of Reforms at the University of Mannheim (project C4), funded by the German Research Foundation (DFG), and also by the SomEMBED TIN2015-71147-C2-1-P MINECO research project."
    }, 
    "document_id": "P17-2016.pdf.json"
}
