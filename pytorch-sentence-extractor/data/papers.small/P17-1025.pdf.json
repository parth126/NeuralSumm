{
    "abstract_sentences": {
        "1": "Learning commonsense knowledge from natural language text is nontrivial due to reporting bias: people rarely state the obvious, e.g., \u201cMy house is bigger than me.\u201d However, while rarely stated explicitly, this trivial everyday knowledge does influence the way people talk about the world, which provides indirect clues to reason about the world.", 
        "2": "For example, a statement like, \u201cTyler entered his house\u201d implies that his house is bigger than Tyler.", 
        "3": "In this paper, we present an approach to infer relative physical knowledge of actions and objects along five dimensions (e.g., size, weight, and strength) from unstructured natural language text.", 
        "4": "We frame knowledge acquisition as joint inference over two closely related problems: learning (1) relative physical knowledge of object pairs and (2) physical implications of actions when applied to those object pairs.", 
        "5": "Empirical results demonstrate that it is possible to extract knowledge of actions and objects from language and that joint inference over different types of knowledge improves performance."
    }, 
    "body_sentences": {
        "1": "  Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 266\u2013276 Vancouver, Canada, July 30 - August 4, 2017. c\u00a92017 Association for Computational Linguistics\nhttps://doi.org/10.18653/v1/P17-1025\nIn this paper, we present an approach to infer relative physical knowledge of actions and objects along five dimensions (e.g., size, weight, and strength) from unstructured natural language text.", 
        "2": "We frame knowledge acquisition as joint inference over two closely related problems: learning (1) relative physical knowledge of object pairs and (2) physical implications of actions when applied to those object pairs.", 
        "3": "Empirical results demonstrate that it is possible to extract knowledge of actions and objects from language and that joint inference over different types of knowledge improves performance.", 
        "4": "1 Introduction  Reading and reasoning about natural language text often requires trivial knowledge about everyday physical actions and objects.", 
        "5": "For example, given a sentence \u201cShanice could fit the trophy into the suitcase,\u201d we can trivially infer that the trophy must be smaller than the suitcase even though it is not stated explicitly.", 
        "6": "This reasoning requires knowledge about the action \u201cfit\u201d\u2014in particular, typical preconditions that need to be satisfied in order to perform the action.", 
        "7": "In addition, reasoning\nNatural language clues\n\u201cShe barged into the stable.\u201d\nabout the applicability of various physical actions in a given situation often requires background knowledge about objects in the world, for example, that people are usually smaller than houses, that cars generally move faster than humans walk, or that a brick probably is heavier than a feather.", 
        "8": "In fact, the potential use of such knowledge about everyday actions and objects can go beyond language understanding and reasoning.", 
        "9": "Many open challenges in computer vision and robotics may also benefit from such knowledge, as shown\n266\nin recent work that requires visual reasoning and entailment (Izadinia et al., 2015; Zhu et al., 2014).", 
        "10": "Ideally, an AI system should acquire such knowledge through direct physical interactions with the world.", 
        "11": "However, such a physically interactive system does not seem feasible in the foreseeable future.", 
        "12": "In this paper, we present an approach to acquire trivial physical knowledge from unstructured natural language text as an alternative knowledge source.", 
        "13": "In particular, we focus on acquiring relative physical knowledge of actions and objects organized along five dimensions: size, weight, strength, rigidness, and speed.", 
        "14": "Figure 1 illustrates example knowledge of (1) relative physical relations of object pairs and (2) physical implications of actions when applied to those object pairs.", 
        "15": "While natural language text is a rich source to obtain broad knowledge about the world, compiling trivial commonsense knowledge from unstructured text is a nontrivial feat.", 
        "16": "The central challenge lies in reporting bias: people rarely states the obvious (Gordon and Van Durme, 2013; Sorower et al., 2011; Misra et al., 2016; Zhang et al., 2017), since it goes against Grice\u2019s conversational maxim on the quantity of information (Grice, 1975).", 
        "17": "In this work, we demonstrate that it is possible to overcome reporting bias and still extract the unspoken knowledge from language.", 
        "18": "The key insight is this: there is consistency in the way people describe how they interact with the world, which provides vital clues to reverse engineer the common knowledge shared among people.", 
        "19": "More concretely, we frame knowledge acquisition as joint inference over two closely related puzzles: inferring relative physical knowledge about object pairs while simultaneously reasoning about physical implications of actions.", 
        "20": "Importantly, four of five dimensions of knowledge in our study\u2014weight, strength, rigidness, and speed\u2014are either not visual or not easily recognizable by image recognition using currently available computer vision techniques.", 
        "21": "Thus, our work provides unique value to complement recent attempts to acquire commonsense knowledge from web images (Izadinia et al., 2015; Bagherinezhad et al., 2016; Sadeghi et al., 2015).", 
        "22": "In sum, our contributions are threefold:\n\u2022 We introduce a new task in the domain of commonsense knowledge extraction from language, focusing on the physical implica-\ntions of actions and the relative physical relations among objects, organized along five dimensions.", 
        "23": "\u2022 We propose a model that can infer relations\nover grounded object pairs together with first order relations implied by physical verbs.", 
        "24": "\u2022 We develop a new dataset VERBPHYSICS\nthat compiles crowdsourced knowledge of actions and objects.1\nThe rest of the paper is organized as follows.", 
        "25": "We first provide the formal definition of knowledge we aim to learn in Section 2.", 
        "26": "We then describe our data collection in Section 3 and present our inference model in Section 4.", 
        "27": "Empirical results are given in Section 5 and discussed in Section 6.", 
        "28": "We review related work in Section 7 and conclude in Section 8.", 
        "29": "2 Representation of Relative Physical Knowledge    2.1 Knowledge Dimensions  We consider five dimensions of relative physical knowledge in this work: size, weight, strength, rigidness, and speed.", 
        "30": "\u201cStrength\u201d in our work refers to the physical durability of an object (e.g., \u201cdiamond\u201d is stronger than \u201cglass\u201d), while \u201crigidness\u201d refers to the physical flexibility of an object (e.g., \u201cglass\u201d is more rigid than a \u201cwire\u201d).", 
        "31": "When considered in verb implications, size, weight, strength, and rigidness concern individual-level semantics; the relative properties implied by verbs in these dimensions are true in general.", 
        "32": "On the other hand, speed concerns stage-level semantics; its implied relations hold only during a window surrounding the verb.2  2.2 Relative physical knowledge  Let us first consider the problem of representing relative physical knowledge between two objects.", 
        "33": "We can write a single piece of knowledge like \u201cA person is larger than a basketball\u201d as\nperson >size basketball\nAny propositional statement can have exceptions and counterexamples.", 
        "34": "Moreover, we need to cope\n1https://uwnlp.github.io/verbphysics/ 2We thank reviewer two for pointing us to this terminology and for the illustrative example: \u201cWhen a person throws a ball, the ball is faster than the person (stage-level) but it\u2019s not true in general that balls are faster than people (individuallevel).\u201d\nwith uncertainties involved in knowledge acquisition.", 
        "35": "Therefore, we assume each piece of knowledge is associated with a probability distribution.", 
        "36": "More formally, given objects x and y, we define a random variable Oax,y whose range is {>, <,'} with respect to a knowledge dimension a \u2208 {SIZE,WEIGHT,STRENGTH,RIGIDNESS,SPEED} so that:\nP(Oax,y = r), r \u2208 {>, <,'}.", 
        "37": "This immediately provides two simple properties:\nP(Ox,y = >) = P(Oy,x = <) P(Ox,x = ') = 1  2.3 Physical Implications of Verbs  Next we consider representing relative physical implications of actions applied over two objects.", 
        "38": "For example, consider an action frame \u201cx threw y.\u201d In general, following implications are likely to be true:\n\u201cx threw y\u201d =\u21d2 x >size y \u201cx threw y\u201d =\u21d2 x >weight y \u201cx threw y\u201d =\u21d2 x <speed y\nAgain, in order to cope with exceptions and uncertainties, we assume a probability distribution associated with each implication.", 
        "39": "More formally, we define a random variable F av to denote the implication of the action verb v when applied over its arguments x and y with respect to a knowledge dimension a so that:\nP(F sizethrew = >) := P(\u201cx threw y\u201d\u21d2 x >size y) P(Fwgtthrew = >) := P(\u201cx threw y\u201d\u21d2 x >wgt y)\nwhere the range of F sizethrew is {>, <,'}.", 
        "40": "Intuitively, F sizethrew represents the likely first order relation implied by \u201cthrow\u201d over ungrounded (i.e., variable) object pairs.", 
        "41": "The above definition assumes that there is only a single implication relation for any given verb with respect to a specific knowledge dimension.", 
        "42": "This is generally not true, since a verb, especially a common action verb, can often invoke a number of different frames according to frame semantics (Fillmore, 1976).", 
        "43": "Thus, given a number of different frame relations v1...vT associated with a verb v, we define random variables F with respect to a specific frame relation vt, i.e., F avt .", 
        "44": "We use this notation going forward.", 
        "45": "Frame Perspective on Verb Implications: Figure 2 illustrates the frame-centric view of physical implication knowledge we aim to learn.", 
        "46": "Importantly, the key insight of our work is inspired by Fillmore\u2019s original manuscript on frame semantics (Fillmore, 1976).", 
        "47": "Fillmore has argued that \u201cframes\u201d\u2014the contexts in which utterances are situated\u2014should be considered as a third primitive of describing a language, along with a grammar and lexicon.", 
        "48": "While existing frame annotations such as FrameNet (Baker et al., 1998), PropBank (Palmer et al., 2005), and VerbNet (Kipper et al., 2000) provide rich frame knowledge associated\nwith a predicate, none of them provide the exact kind of physical implications we consider in our paper.", 
        "49": "Thus, our work can potentially contribute to these resources by investigating new approaches to automatically recover richer frame knowledge from language.", 
        "50": "In addition, our work is motivated by the formal semantics of Dowty (1991), as the task of learning verb implications is essentially that of extracting lexical entailments for verbs.", 
        "51": "3 Data and Crowdsourced Knowledge  Action Verbs: We pick 50 classes of Levin verbs from both \u201calternation classes\u201d and \u201cverb classes\u201d (Levin, 1993), which corresponds to about 1100 unique verbs.", 
        "52": "We sort this list by frequency of occurrence in our frame patterns in the Google Syntax Ngrams corpus (Goldberg and Orwant, 2013) and pick the top 100 verbs.", 
        "53": "Action Frames: Figure 2 illustrates examples of action frame relations.", 
        "54": "Because we consider implications over pairwise argument relations for each frame, there are sometimes multiple frame relations we consider for a single frame.", 
        "55": "To enumerate action frame relations for each verb, we use syntactic patterns based on dependency parse by extracting the core components (subject, verb, direct object, prepositional object) of an action, then map the subject to an agent, the direct object to a theme, and the prepositional object to a goal.3 For those frames that involve an argument in a prepositional phrase, we create a separate frame for each preposition based on the statistics observed in the Google Syntax Ngram corpus.", 
        "56": "Because the syntax ngram corpus provides only tree snippets without context, this way of enumerating potential frame patterns tend to overgenerate.", 
        "57": "Thus we refine our prepositions for each frame by taking either the intersection or union with the top 5 Google Surface Ngrams (Michel et al., 2011), depending on whether the frame was under- or over-generating.", 
        "58": "We also add an additional crowdsourcing step where we ask crowd workers to judge whether a frame pattern with a particular verb and preposition could plausibly be found in a sentence.", 
        "59": "This process results in 813 frame templates, an average of 8.13 per verb.", 
        "60": "3Future research could use an SRL parser instead.", 
        "61": "We use dependency parse to benefit from the Google Syntax Ngram dataset that provides language statistics over an extremely large corpus, which does not exist for SRL.", 
        "62": "Object Pairs: To provide a source of ground truth relations between objects, we select the object pairs that occur in the 813 frame templates with positive pointwise mutual information (PMI) across the Google Syntax Ngram corpus.", 
        "63": "After replacing a small set of \u201chuman\u201d nouns with a generic HUMAN object, filtering out nouns labeled as abstract by WordNet (Miller, 1995), and distilling all surface forms to their lemmas (also with WordNet), the result is 3656 object pairs.", 
        "64": "3.1 Crowdsourcing Knowledge  We collect human judgements of the frame knowledge implications to use as a small set of seed knowledge (5%), a development set (45%), and a test set (50%).", 
        "65": "Crowd workers are given with a frame template such as \u201cx threw y,\u201d and then asked to list a few plausible objects (including people and animals) for the missing slots (e.g., x and y).4\n4This step is to prime them for thinking about the particular template; we do not use the objects they provided.", 
        "66": "We then ask them to rate the general relationship that the arguments of the frame exhibit with respect to all knowledge dimensions (size, weight, etc.).", 
        "67": "For each knowledge dimension, or attribute, a, workers select an answer from (1) x >a y, (2) x <a y, (3) x 'a y, or (4) no general relation.", 
        "68": "We conduct a similar crowdsourcing step for the set of object pairs.", 
        "69": "We ask crowd workers to compare each of the 3656 object pairs along the five knowledge dimensions we consider, selecting an answer from the same options above as with frames.", 
        "70": "We reserve 50% of the data as a test set, and split the remainder up either 5% / 45% or 20% / 30% (seed / development) to investigate the effects of different seed knowledge sizes on the model.", 
        "71": "Statistics for the dataset are provided in Table 1.", 
        "72": "About 90% of the frames as well as object pairs had 2/3 agreement between workers.", 
        "73": "After removing frame/attribute combinations and object pairs that received less than 2/3 agreement, or were selected by at least 2/3 workers to have no relation, we end up with roughly 400\u2013600 usable frames and 2100\u20132500 usable object pairs per attribute.", 
        "74": "4 Model  We model knowledge acquisition as probabilistic inference over a factor graph of knowledge.", 
        "75": "As shown in Figure 3, the graph consists of multiple substrates (page-wide boxes) corresponding to different knowledge dimensions (shown only three of them \u2014strength, size, weight\u2014for brevity).", 
        "76": "Each substrate consists of two types of sub-graphs: verb subgraphs and object subgraphs, which are connected through factors that quantify action\u2013object compatibilities.", 
        "77": "Connecting across substrates are factors that model inter-dependencies across different knowledge dimensions.", 
        "78": "In what follows, we describe each graph component.", 
        "79": "4.1 Nodes  The factor graph contains two types of nodes in order to capture two classes of knowledge.", 
        "80": "The first type of nodes are object pair nodes.", 
        "81": "Each object pair node is a random variable Oax,y which captures the relative strength of an attribute a between objects x and y.", 
        "82": "The second type of nodes are frame nodes.", 
        "83": "Each frame node is a random variable F avt .", 
        "84": "This corresponds to the verb v used in a particular type of frame t, and captures the implied knowledge the\nframe vt holds along an attribute a.", 
        "85": "All random variables take on the values {>, <,'}.", 
        "86": "For an object pair node Oax,y, the value represents the belief about the relation between x and y along the attribute a.", 
        "87": "For a frame node F avt , the value represents the belief about the relation along the attribute a between any two objects that might be used in the frame vt.\nWe denote the sets of all object pair and frame random variables O and F , respectively.", 
        "88": "4.2 Action\u2013Object Compatibility  The key aspect of our work is to reason about two types of knowledge simultaneously: relative knowledge of grounded object pairs, and implications of actions related to those objects.", 
        "89": "Thus we connect the verb subgraphs and object subgraphs through selectional preference factors \u03c8s between two such nodes Oax,y and F a vt if we find evidence from text that suggests objects x and y are used in the frame vt.", 
        "90": "These factors encourage both random variables to agree on the same value.", 
        "91": "As an example, consider a node Osizep,b which represents the relative size of a person and a basketball, and a node F sizethrewdobj which represents the relative size implied by an \u201cx threw y\u201d frame.", 
        "92": "If we find significant evidence in text that \u201c[person] threw [basketball]\u201d occurs, we would add a selectional preference factor to connect Osizep,b with F sizethrewdobj and encourage them towards the same value.", 
        "93": "This means that if it is discovered that people are larger than basketballs (the value >), then we would expect the frame \u201cx threw y\u201d to entail x >size y (also the value >).", 
        "94": "4.3 Semantic Similarities  Some frames have relatively sparse text evidences to support their corresponding knowledge acquisition.", 
        "95": "Thus, we include several types of factors based on semantic similarities as described below.", 
        "96": "Cross-Verb Frame Similarity: We add a group of factors \u03c8v between two verbs v and u (to connect a specific frame of v with a corresponding frame of u) based on the verb-level similarities.", 
        "97": "Within-Verb Frame Similarity: Within each verb v, which consists of a set of frame relations v1, ...vT , we also include frame-level similarity factors \u03c8f between vi and vj .", 
        "98": "This gives us more evidence over a broader range of frames when textual evidence might be sparse.", 
        "99": "f a o v\ns\nObject Similarity: As with verbs, we add factors \u03c8o that encourage similar pairs of objects to take the same value.", 
        "100": "Given that each node represents a pair of objects, finding that x and y are similar yields two main cases in how to add factors (aside from the trivial case where the variable Oax,y is given a unary factor to encourage the value ').", 
        "101": "1.", 
        "102": "If nodes Ox,z and Oy,z exist, we expect objects x and y to both have a similar relation to z.", 
        "103": "We add a factor that encourages Ox,z and Oy,z to take the same value.", 
        "104": "The same is true if nodes Oz,x and Oz,y exist.", 
        "105": "2.", 
        "106": "On the other hand, if nodesOx,z andOz,y exist, we expect these two nodes to reach the opposite decision.", 
        "107": "In this case, we add a factor that encourages one node to take the value > if the other prefers the value <, and vice versa.", 
        "108": "(For the case of ', if one prefers that value, then both should.)", 
        "109": "4.4 Cross-Knowledge Correlation  Some knowledge dimensions, such as size and weight, have a significant correlation in their implied relations.", 
        "110": "For two such attributes a and b, if the same frame F avi and F b vi exists in both graphs,\nwe add a factor \u03c8a between them to push them towards taking the same value.", 
        "111": "4.5 Seed Knowledge  In order to kick off learning, we provide a small set of seed knowledge among the random variables in {O,F} with seed factors \u03c8seed.", 
        "112": "These unary seed factors push the belief for its associated random variable strongly towards the seed label.", 
        "113": "4.6 Potential Functions  Unary Factors: For all frame and object pair random variables in the training set, we train a maximum entropy classifier to predict the value of the variable.", 
        "114": "We then use the probabilities of the classifier as potentials for seed factors given to all random variables in their class (frame or object pair).", 
        "115": "Each log-linear classifier is trained separately per attribute on a featurized vector of the variable:\nP(r|Xa) \u221d ewa\u00b7f(Xa)\nThe feature function is defined differently according to the node type:\nf(Oap,q) := \u3008g(p), g(q)\u3009 f(F avt) := \u3008h(t), g(v), g(t)\u3009\nHere g(x) is the GloVe word embedding (Pennington et al., 2014) for the word x (t is the frame relation\u2019s preposition, and g(t) is simply set to the zero vector if there is no preposition) and h(t) is a one-hot vector of the frame relation type.", 
        "116": "We use GloVe vectors of 100 dimensions for verbs and 50 dimensions for objects and prepositions (the dimensions picked based on development set).", 
        "117": "Binary Factors: In the case of all other factors, we use a \u201csoft 1\u201d agreement matrix with strong signal down the diagonals:\n \n> ' < > 0.7 0.1 0.2 ' 0.15 0.7 0.15 < 0.2 0.1 0.7\n   4.7 Inference  After our full graph is constructed, we use belief propagation to infer the assignments of frames and object pairs not in our training data.", 
        "118": "Each message \u00b5 is a vector where each element is the probability that a random variable takes on each value x \u2208 {>, <,'}.", 
        "119": "A message passed from a random variable v to a neighboring factor f about the value x is the product of the messages from its other neighboring factors about x:\n\u00b5v\u2192f (x) \u221d \u220f\nf \u2032\u2208N(v)\\{f} \u00b5f \u2032\u2192v(x)\nA message passed from a factor f with potential \u03c8 to a random variable v about its value x is a marginalized belief about v taking value x from the other neighboring random variables combined\nwith its potential: \u00b5f\u2192v(x) \u221d \u2211\nx:x[v]=x\n\u03c8(x) \u220f\nv\u2032\u2208N(f)\\{v} \u00b5v\u2032\u2192f (x[v\n\u2032])\nAfter stopping belief propagation, the marginals for a node can be computed and used as a decision for that random variable.", 
        "120": "The marginal for v taking value x is the product of its surrounding factors\u2019 messages:\nv(x) \u221d \u220f\nf\u2208N(v) \u00b5f\u2192v(x)  5 Experimental Results  Factor Graph Construction: We first need to pick a set of frames and objects to determine our set of random variables.", 
        "121": "The frames are simply the subset of the frames that were crowdsourced in the given configuration (e.g., seed + dev), with \u201csoft 1\u201d unary seed factors (the gold label indexed row of the binary factor matrix) given only to those in the seed set.", 
        "122": "The same selection criteria and seed factors are applied to the crowdsourced object pairs.", 
        "123": "For lexical similarity factors (\u03c8v, \u03c8o), we pick connections based on the cosine similarity scores of GloVe vectors thresholded above a value chosen based on development set performance.", 
        "124": "Attribute similarity factors (\u03c8a) are chosen based on sets of frames that reach largely the same decisions on the seed data (95%).", 
        "125": "Frame similarity factors (\u03c8f ) are added to pairs of frames with linguistically similar constructions.", 
        "126": "Finally, selectional preference\nAttr\napprox max width\nFrame gloss Score Example model predictions (frame) (dev set) Ex\n___ opened ___ size1 PERSON set ___ upon ___ wgt2 ___ stood on ___ str3 PERSON arrived on ___ rgd4 ___ put up ___ spd5\n'> <\nclose\njust wrong + easy for humans to judge\nbad data; nonsensical comparison\ncould go either way (interesting physics things going on here)\nsome polysemy / either way possible\nPERSON drove ___ for ___ size6 PERSON stopped ___with ___ wgt7\n___ lived at ___ str8 ___ snipped off ___ rgd9 ___ caught ___ spd10\n'> <\nFigure 4: Example model predictions on dev set frames.", 
        "127": "The model\u2019s confidence is shown by the bars on the right.", 
        "128": "The correct relation is highlighted in orange (6\u201310 are failure cases for the model).", 
        "129": "If there are two blanks, the relation is between them.", 
        "130": "If there is only one blank, the relation\nis between PERSON and the blank.", 
        "131": "Note that ' receives miniscule weight because it is never the correct value for frames in the seed set.", 
        "132": "factors (\u03c8s) are picked by using a threshold (also tuned on the development set) of pointwise mutual information (PMI) between the frames and the object pairs\u2019 occurrences in the Google Syntax Ngram corpus.", 
        "133": "For each task, we consider the set of factors to include in each model a hyperparameter, which is also tuned on the development set.", 
        "134": "Baselines: Baselines include making a RANDOM choice, picking between >, <, and '), picking the MAJORITY label, and a maximum entropy classifier based on the embedding representations (EMB-MAXENT) defined in Section 4.6.", 
        "135": "Inferring Knowledge of Actions: Our first experiment is to predict knowledge implied by new frames.", 
        "136": "In this task, 5% of the frames are available as seed knowledge.", 
        "137": "We experiment with two different sets of seed knowledge for the object pair data: OUR MODEL (A) uses only 5% of the object pair data as seed, and OUR MODEL (B) uses 20%.", 
        "138": "The full results for the baseline methods and our model are given in the upper half of Table 2.", 
        "139": "Our model outperforms the baselines on all attributes except for the speed, which has a highly skewed label distribution to allow the majority baseline to\nperform well.", 
        "140": "Ablations are given in Table 3, and sample correct predictions from the development set are shown in examples 1\u20135 of Figure 4.", 
        "141": "Inferring Knowledge of Objects: Our second experiment is to predict the correct relations of new object pairs.", 
        "142": "The data for this task is the inverse of before: 5% of the object pairs are available as seed knowledge, and we experiment with both 5% (OUR MODEL (A)) and 20% (OUR MODEL (B)) frames given as seed data.", 
        "143": "Again, both are independently tuned on the development data.", 
        "144": "Results for this task are presented in the lower half of Table 2.", 
        "145": "While OUR MODEL (A) is competitive with the strongest baseline, introducing the additional frame data allows OUR MODEL (B) to reach the highest accuracy.", 
        "146": "6 Discussion  Metaphorical Language: While our frame patterns are intended to capture action verbs, our templates also match senses of those verbs that can be used with abstract or metaphorical arguments, rather than directly physical ones.", 
        "147": "One example from the development set is \u201cx contained y.\u201d While x and y can be real objects, more abstract senses of \u201ccontained\u201d could involve y as a \u201cforest fire\u201d or even a \u201crevolution.\u201d In these instances, x >size y is plausible as an abstract notion: if some entity can contain a revolution, we might think that entity as \u201clarger\u201d or \u201cstronger\u201d than the revolution.", 
        "148": "Error analysis: Examples 6\u201310 in Figure 4 highlight failure cases for the model.", 
        "149": "Example\n6 shows a case where the comparison is nonsensical because \u201cfor\u201d would naturally be followed by a purpose (\u201cHe drove the car for work.\u201d) or a duration (\u201cShe drove the car for hours.\u201d) rather than a concrete object whose size is measurable.", 
        "150": "Example 7 highlights an underspecified frame.", 
        "151": "One crowd worker provided the example, \u201cPERSON stopped the fly with {the jar / a swatter},\u201d where fly <weight {jar, swatter}.", 
        "152": "However, two crowd workers provided examples like \u201cPERSON stopped their car with the brake,\u201d where clearly car >weight brake.", 
        "153": "This example illustrates complex underlying physics we do not model: a brake\u2014the pedal itself\u2014is used to stop a car, but it does so by applying significant force through a separate system.", 
        "154": "The next two examples are cases where the model nearly predicts correctly (8, e.g., \u201cShe lived at the office.\u201d) and is just clearly wrong (9, e.g., \u201cHe snipped off a locket of hair\u201d).", 
        "155": "Example 10 demonstrates a case of polysemy where the model picks the wrong side.", 
        "156": "In the phrase, \u201cShe caught the runner in first,\u201d, it is correct that she >speed runner.", 
        "157": "However, the sense chosen by the crowd workers is that of, \u201cShe caught the baseball,\u201d where indeed she <speed baseball.", 
        "158": "7 Related work  Several works straddle the gap between IE, knowledge base completion, and learning commonsense knowledge from text.", 
        "159": "Earlier works in these areas use large amounts of text to try to extract general statements like \u201cA THING CAN BE READABLE\u201d (Gordon et al., 2010) and frequencies of events (Gordon and Schubert, 2012).", 
        "160": "Our work focuses on specific domains of knowledge rather than general statements or occurrence statistics, and develops a frame-centric approach to circumvent reporting bias.", 
        "161": "Other work uses a knowledge base and scores unseen tuples based on similarity to existing ones (Angeli and Manning, 2013; Li et al., 2016).", 
        "162": "Relatedly, previous work uses natural language inference to infer new facts from a dataset of commonsense facts that can be extracted from unstructured text (Angeli and Manning, 2014).", 
        "163": "In contrast, we focus on a small number of specific types of knowledge without access to an existing database of knowledge.", 
        "164": "A number of recent works combine multimodal input to learn visual attributes (Bruni et al., 2012; Silberer et al., 2013), extract commonsense\nknowledge from web images (Tandon et al., 2016), and overcome reporting bias (Misra et al., 2016).", 
        "165": "In contrast, we focus on natural language evidence to reason about attributes that are both in (size) and out (weight, rigidness, etc.)", 
        "166": "of the scope of computer vision.", 
        "167": "Yet other works mine numerical attributes of objects (Narisawa et al., 2013; Takamura and Tsujii, 2015; Davidov and Rappoport, 2010) and comparative knowledge from the web (Tandon et al., 2014).", 
        "168": "Our work uniquely learns verb-centric lexical entailment knowledge.", 
        "169": "A handful of works have attempted to learn the types of knowledge we address in this work.", 
        "170": "One recent work tried to directly predict several binary attributes (such \u201cis large\u201d and \u201cis yellow\u201d) from on off-the-shelf word embeddings, noting that accuracy was very low (Rubinstein et al., 2015).", 
        "171": "Another line of work addressed grounding verbs in the context of robotic tasks.", 
        "172": "One paper in this line acquires verb meanings by observing state changes in the environment (She and Chai, 2016).", 
        "173": "Another work in this line does a deep investigation of eleven verbs, modeling their physical effect via annotated images along eighteen attributes (Gao et al., 2016).", 
        "174": "These works are encouraging investigations into multimodal groundings of a small set of verbs.", 
        "175": "Our work instead grounds into a fixed set of attributes but leverages language on a broader scale to learn about more verbs in more diverse set of frames.", 
        "176": "8 Conclusion  We presented a novel take on verb-centric frame semantics to learn implied physical knowledge latent in verbs.", 
        "177": "Empirical results confirm that by modeling changes in physical attributes entailed by verbs together with objects that exhibit these properties, we are able to better infer new knowledge in both domains.", 
        "178": "Acknowledgements  This research is supported in part by the National Science Foundation Graduate Research Fellowship, DARPA CwC program through ARO (W911NF-15-1-0543), the NSF grant (IIS1524371), and gifts by Google and Facebook.", 
        "179": "The authors thank the anonymous reviewers for their thorough and insightful comments."
    }, 
    "document_id": "P17-1025.pdf.json"
}
