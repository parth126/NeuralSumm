\documentclass[sigconf]{acmart}

\usepackage{booktabs} % For formal tables
\usepackage{url}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{amsmath}
\usepackage{threeparttable}
\usepackage{amssymb}
\DeclareCaptionType{InfoBox}
\usepackage{tikz}


\usetikzlibrary{fadings}


\tikzset{fading text/.style={}}


\definecolor{blue1}{RGB}{139,157,195}


\definecolor{blue2}{RGB}{247,247,247}




\newcommand\fadingtext[2][]{%
	
	
	\begin{tikzfadingfrompicture}[name = fading letter]
		
		
		\node[color=black, inner xsep = 0pt, outer xsep = 0pt] {#2};
		
		
	\end{tikzfadingfrompicture}%
	
	
	\begin{tikzpicture}[baseline = (textnode.base)]
	
	
	\node[inner sep = 0pt, outer sep = 0pt, #1] (textnode) {#2}; 
	
	
	\shade[path fading = fading letter, fading text, #1,fit fading = false]
	
	
	(textnode.south west) rectangle (textnode.north east);% 
	
	
	\end{tikzpicture}% 
	
	
}
% Copyright
%\setcopyright{none}
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}



% These commands are optional
%\acmBooktitle{Transactions of the ACM Woodstock conference}


\begin{document}
\title{Attention based Sentence Extraction from Scientific Articles using Pseudo-Labeled data}
%\titlenote{Produces the permission block, and
%  copyright information}
%\subtitle{Extended Abstract}
%\subtitlenote{The full version of the author's guide is available as
%  \texttt{acmart.pdf} document}


\author{XXX}
\affiliation{%
  \institution{YYY}
  \streetaddress{ZZZ}
}
\email{abc@zzz.com}


\author{XXX}
\affiliation{%
	\institution{YYY}
	\streetaddress{ZZZ}
}
\email{abc@zzz.com}

\author{XXX}
\affiliation{%
	\institution{YYY}
	\streetaddress{ZZZ}
}
\email{abc@zzz.com}


\begin{abstract}
In this work, we present a weakly supervised sentence extraction technique for identifying important sentences in scientific papers that are worthy of inclusion in the abstract. We propose a method for determining the focus of a given paper using topic models and use it to create document-level context. We also propose an attention based sentence encoding model that jointly learns to identify important content as well as the cue phrases that are indicative of summary worthy sentences. We use a collection of articles publicly available through ACL anthology for our experiments. Our system achieves a performance that is better, in terms of several ROUGE metrics, as compared to several state of art extractive techniques. It also generate more coherent summaries and preserves the overall structure of the document.
\end{abstract}

%
% The code below should be generated by the tool at
% http://dl.acm.org/ccs.cfm
% Please copy and paste the code instead of the example below.
%

\keywords{Summarization, Attention, LSTM, Topic model}


\maketitle

\input{sigir-main.tex}

\bibliographystyle{ACM-Reference-Format}
\bibliography{sigir.bib}
\end{document}
